<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="OCaml Labs Group">
  <title>OCaml Labs Weekly Reports</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" href="github-pandoc.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header>
<h1 class="title">OCaml Labs Weekly Reports</h1>
<h2 class="author">OCaml Labs Group</h2>
</header>
<nav id="TOC">
<ul>
<li><a href="#weekly-notes-for-2017">Weekly notes for 2017</a><ul>
<li><a href="#week-43">Week 43</a></li>
<li><a href="#week-42">Week 42</a></li>
<li><a href="#week-41">Week 41</a></li>
<li><a href="#week-40">Week 40</a></li>
<li><a href="#week-39">Week 39</a></li>
<li><a href="#week-38">Week 38</a></li>
<li><a href="#week-37">Week 37</a></li>
<li><a href="#week-36">Week 36</a></li>
<li><a href="#week-35">Week 35</a></li>
<li><a href="#week-34">Week 34</a></li>
<li><a href="#week-33">Week 33</a></li>
<li><a href="#week-32">Week 32</a></li>
<li><a href="#week-31">Week 31</a></li>
<li><a href="#week-30">Week 30</a></li>
<li><a href="#week-29">Week 29</a></li>
<li><a href="#week-28">Week 28</a></li>
<li><a href="#week-27">Week 27</a></li>
<li><a href="#week-26">Week 26</a></li>
<li><a href="#week-25">Week 25</a></li>
<li><a href="#week-24">Week 24</a></li>
<li><a href="#week-23">Week 23</a></li>
<li><a href="#week-22">Week 22</a></li>
<li><a href="#week-21">Week 21</a></li>
<li><a href="#week-20">Week 20</a></li>
</ul></li>
<li><a href="#ocaml">OCaml</a></li>
<li><a href="#opam">opam</a><ul>
<li><a href="#week-19">Week 19</a></li>
</ul></li>
<li><a href="#platform">Platform</a></li>
<li><a href="#ocaml-1">OCaml</a></li>
<li><a href="#opam-1">opam</a><ul>
<li><a href="#week-18">Week 18</a></li>
</ul></li>
<li><a href="#opam-2">opam</a></li>
<li><a href="#ocaml-2">OCaml</a><ul>
<li><a href="#week-17">Week 17</a></li>
</ul></li>
<li><a href="#opam-3">opam</a><ul>
<li><a href="#farfadet-3">Farfadet</a></li>
<li><a href="#week-16">Week 16</a></li>
</ul></li>
<li><a href="#opam-4">opam</a></li>
<li><a href="#ocaml-3">OCaml</a><ul>
<li><a href="#week-15">Week 15</a></li>
</ul></li>
<li><a href="#misc">Misc</a></li>
<li><a href="#ocaml-4">OCaml</a><ul>
<li><a href="#week-14">Week 14</a></li>
</ul></li>
<li><a href="#ocaml-5">OCaml</a><ul>
<li><a href="#week-13">Week 13</a></li>
</ul></li>
<li><a href="#ocaml-6">OCaml</a><ul>
<li><a href="#week-12">Week 12</a></li>
<li><a href="#week-11">Week 11</a></li>
<li><a href="#week-10">Week 10</a></li>
<li><a href="#week-9">Week 9</a></li>
<li><a href="#week-8">Week 8</a></li>
<li><a href="#week-7">Week 7</a></li>
<li><a href="#week-6">Week 6</a></li>
<li><a href="#week-5">Week 5</a></li>
<li><a href="#week-4">Week 4</a></li>
<li><a href="#week-3">Week 3</a></li>
<li><a href="#week-2">Week 2</a></li>
<li><a href="#week-1">Week 1</a></li>
</ul></li>
<li><a href="#weekly-notes-for-2016">Weekly notes for 2016</a><ul>
<li><a href="#week-51">Week 51</a></li>
<li><a href="#week-50">Week 50</a></li>
<li><a href="#week-49">Week 49</a></li>
<li><a href="#week-48">Week 48</a></li>
<li><a href="#week-47">Week 47</a></li>
<li><a href="#week-46">Week 46</a></li>
<li><a href="#week-45">Week 45</a></li>
<li><a href="#week-44">Week 44</a></li>
<li><a href="#week-43-1">Week 43</a></li>
<li><a href="#week-42-1">Week 42</a></li>
<li><a href="#week-41-1">Week 41</a></li>
<li><a href="#week-40-1">Week 40</a></li>
<li><a href="#week-39-1">Week 39</a></li>
<li><a href="#week-33-1">Week 33</a></li>
<li><a href="#week-32-1">Week 32</a></li>
<li><a href="#week-31-1">Week 31</a></li>
<li><a href="#week-30-1">Week 30</a></li>
<li><a href="#week-29-1">Week 29</a></li>
<li><a href="#week-28-1">Week 28</a></li>
<li><a href="#week-27-1">Week 27</a></li>
<li><a href="#week-26-1">Week 26</a></li>
<li><a href="#week-25-1">Week 25</a></li>
<li><a href="#week-24-1">Week 24</a></li>
<li><a href="#week-23-1">Week 23</a></li>
<li><a href="#week-22-1">Week 22</a></li>
<li><a href="#week-21-1">Week 21</a></li>
<li><a href="#week-20-1">Week 20</a></li>
<li><a href="#week-19-1">Week 19</a></li>
<li><a href="#week-17-1">Week 17</a></li>
<li><a href="#week-16-1">Week 16</a></li>
</ul></li>
<li><a href="#summary-of-activity-by-author">Summary of activity by author</a><ul>
<li><a href="#author-olivier-nicole">Author Olivier Nicole</a></li>
<li><a href="#author-liang-wang">Author Liang Wang</a></li>
<li><a href="#author-romain-calascibetta">Author Romain Calascibetta</a></li>
<li><a href="#farfadet-20">Farfadet</a></li>
<li><a href="#author-david-allsopp">Author David Allsopp</a></li>
</ul></li>
<li><a href="#ocaml-7">OCaml</a></li>
<li><a href="#ocaml-8">OCaml</a></li>
<li><a href="#misc-1">Misc</a></li>
<li><a href="#ocaml-9">OCaml</a></li>
<li><a href="#opam-5">opam</a></li>
<li><a href="#ocaml-10">OCaml</a></li>
<li><a href="#opam-6">opam</a></li>
<li><a href="#opam-7">opam</a></li>
<li><a href="#ocaml-11">OCaml</a></li>
<li><a href="#platform-1">Platform</a></li>
<li><a href="#ocaml-12">OCaml</a></li>
<li><a href="#opam-8">opam</a></li>
<li><a href="#ocaml-13">OCaml</a></li>
<li><a href="#opam-9">opam</a><ul>
<li><a href="#author-enguerrand-decorne">Author Enguerrand Decorne</a></li>
<li><a href="#author-gabriel-de-perthuis">Author Gabriel de Perthuis</a></li>
<li><a href="#author-stephen-dolan">Author Stephen Dolan</a></li>
<li><a href="#author-philip-dexter">Author Philip Dexter</a></li>
<li><a href="#author-ciaran-lawlor">Author Ciaran Lawlor</a></li>
<li><a href="#author-sander-spies">Author Sander Spies</a></li>
<li><a href="#author-maxime-lesourd">Author Maxime Lesourd</a></li>
<li><a href="#author-qi-li">Author Qi Li</a></li>
<li><a href="#author-frédéric-bour">Author Frédéric Bour</a></li>
<li><a href="#author-joel-jakubovic">Author Joel Jakubovic</a></li>
<li><a href="#author-gemma-gordon">Author Gemma Gordon</a></li>
<li><a href="#author-takayuki-imada">Author Takayuki Imada</a></li>
<li><a href="#author-kc-sivaramakrishnan">Author KC Sivaramakrishnan</a></li>
</ul></li>
</ul>
</nav>
<p>These weekly notes are rough scribings of activities that happen on a weekly basis. They are intended to be an internal journal for Lab members rather than something consumed by the outside world. If you have any queries about the contents, please contact Gemma Gordon, KC Sivaramakrishnan or Anil Madhavapeddy.</p>
<h2 id="weekly-notes-for-2017">Weekly notes for 2017</h2>
<h3 id="week-43">Week 43</h3>
<h4 id="romain-calascibetta">Romain Calascibetta</h4>
<h4 id="ocaml-git">OCaml Git</h4>
<p>Focus on the test of OCaml Git (the common part). So, I put some constraints to prove the equality of the type Value.t between 2 implementation of the Git repository with the same Hash module.</p>
<p>I added some conveniences functions again (like Git.Ref.exists or Reference.head_contents).</p>
<p>I fixed 2 bugs: - one about the semantic of <code>Mem.read_inflated</code> which differ from the <code>FS.read_inflated</code>, the first one put the header and the last one not. But we expect the last semantic. - A deep bug about the abstract serialization of a value</p>
<p>Then, I test the Git.Pack.make function and add a returned value which is a protected variable to get the IDX tree - only available when we consume all of the stream.</p>
<p>I implemented the push function for the Sync_http module (so the Smart HTTP protocol) but not test it yet. And finally put some /easy-to-use/ functions on the provided CoHTTP implementation of the Smart HTTP protocol (for Camelus).</p>
<p>Louis reported to me a bug about fetch, I will fix it.</p>
<h3 id="week-42">Week 42</h3>
<h4 id="romain-calascibetta-1">Romain Calascibetta</h4>
<h4 id="decompress">Decompress</h4>
<p>Find a way to provide a JS API of Decompress with a mutable state.</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">type</span> inflator = { <span class="kw">mutable</span> contents : (B<span class="kw">.</span>st, B<span class="kw">.</span>st) Inflate<span class="kw">.</span>t }</code></pre></div>
<p>So, the code is specialized to manipulate only a bytes (but still ok where the JS world does not provide an equivalent of Bigarray - in performance).</p>
<h4 id="digestif">Digestif</h4>
<p>Find a new way to test the C implementation and the OCaml implementation with travis.</p>
<p>Fixed a bug about the RIPEMD160 implementation in OCaml.</p>
<p>Put some other tests (from the BLAKE2{b,s} reference implementation, and the RIPEMD160).</p>
<p>Benchmark on the C implementation and the OCaml implementation with <code>core_bench</code>. However, I did not compare with <code>ocp-sha</code>, firstly because I lost my time to make a package for ocp-sha (Louis provides only a Makefile). And because ocp-sha was thinked to hash a file (not a stream or a buffer) and tricks on to be fast - however, I can not say ocp-sha is faster than digestif when ocp-sha uses some syscall like lseek.</p>
<p>So, if we want to compare digestif and ocp-sha, it's about program which take a file but it's not very relevant when ocp-sha map the file and digestif could compute a stream of this file.</p>
<p>Finally, make a release.</p>
<h4 id="ocaml-git-1">OCaml Git</h4>
<p>Try to move the test implementation on the new API. Nothing change a lot, I missed some conveniences accessors and use infix operator of Lwt_result instead Lwt.</p>
<h3 id="week-41">Week 41</h3>
<h4 id="romain-calascibetta-2">Romain Calascibetta</h4>
<h4 id="decompress-1">Decompress</h4>
<p>I released the new 0.7 version of decompress. I currently work on a good API about javascript. I found some API in the npm repository but these API seems to be imperative - and it's not the case decompress.</p>
<p>NOTE: I think, it's imperative because it's just a FFI with zlib directly (without convenience computation).</p>
<h4 id="digestif-1">Digestif</h4>
<p>I just finish to implement the BLAKE2S function and test it and merge it. I currently look about benchmark with Louis and provide something to test and compare with ocp-sha.</p>
<p>About the test, I just look what is it exactly and we have lot of litterature to test SHA-*, BLAKE2{b,s} and RIPEMD160 implementation. So, I will integrate all.</p>
<h4 id="callipyge">Callipyge</h4>
<p>cfcs catched a bug about Callipyge, it does not work. So, I think, I will re-implement it from the reference implementation.</p>
<h4 id="ocaml-git-2">OCaml Git</h4>
<p>I just implemented the fetch command on the HTTP protocol. Now, I can start to implement the push command on the HTTP protocol. Louis asks me about the current implementation of my PR and he tried to test it.</p>
<p>Obviously, I did not work yet on the polishement of opam file and we need to pin digestif and a specific version of angstrom (which has my fix). Then, he compiled ocaml-git without error but it's not easy, I started to figure about opam file.</p>
<p>Again, I fixed some bugs specifically about reference (between absolute path of the reference and relative path) and the PACK decoder which handles an empty PACK file now.</p>
<p>I cleaned the smart decoder and delete the redundant code and understand what is specifically the diff between the Smart protocol and the Smart HTTP protocol - because, in the Git documentation, we don't have any explanation about that.</p>
<h3 id="week-40">Week 40</h3>
<h4 id="romain-calascibetta-3">Romain Calascibetta</h4>
<h4 id="decompress-2">Decompress</h4>
<p>From the last complete afl fuzzer (which add the level and the windows bits argument), all looks fine. I catched a bug but it seems this bug is come from afl (and not decompress) which described by the issue #8.</p>
<p>I talk with Mindy about that, she already know this bug and ask me to try the fuzzer with an other version of afl-persistent.</p>
<p>So, I wait the end of the fuzzer to make a release as I said but nothing to declare about bugs in decompress for the moment!</p>
<h4 id="digestif-2">Digestif</h4>
<p>So, the implementation of BLAKE2s appeared in the PR #14, it should works from some local tests. <span class="citation" data-cites="cfcs">@cfcs</span> ask me to add some tests from the reference implementation of BLAKE2s, some tests about RIPEMD160 and others useful inputs. However, he found a <em>bug</em> about the build system. Indeed, the test can not be automated easily if we want to test with the C implementation and the OCaml implementation. He suggere in the PR #16 to test the OCaml implementation.</p>
<p>So, I will figure about this when jbuilder#136 is done.</p>
<p>Then, <span class="citation" data-cites="samoht">@samoht</span> found a way to provide a mli library and use it to link with a library (like ocaml-git). Then, the git library need to be linked with <code>digestif.c</code> or <code>digestif.ocaml</code> to provide the implementation.</p>
<p>This PR waits the jbuilder#136 issue again.</p>
<h4 id="farfadet">Farfadet</h4>
<p>Update to the new API of Faraday and add a constraint in the opam repository.</p>
<h4 id="typebeat">TypeBeat</h4>
<p>Update to the new API of Angstrom.</p>
<h4 id="ocaml-git-3">OCaml Git</h4>
<p>I added the fold function (come from the Irmin implementation) to traverse a Git repository and complete an accumulator (specially to generate a list of entries to pack then). So, it's a function provided in the minimal API - the implementation is the same between the file-system back-end and the memory back-end to avoid any semantic diff between back-end and this function.</p>
<p>Then, I tested the <code>git-bomb</code> repository with ocaml-git. I fixed some bugs about the URI and we can clone, read, write in this repository without memory leak. I generated a dot file of this git repository then. So, no problem about this repo for ocaml-git!</p>
<p>I added the ogit-cat-file and the ogit-http-ls binary as ogit did previously and clear some module like the Revision module and the Sync module to use the minimal interface instead the file-system back-end.</p>
<h3 id="week-39">Week 39</h3>
<h4 id="romain-calascibetta-4">Romain Calascibetta</h4>
<h4 id="decompress-3">Decompress</h4>
<p>Simple afl test finished, I will start a complex test which test level, window size and others parameters of decompress.</p>
<h4 id="digestif-3">Digestif</h4>
<p>I push a mlilib branch to explain to thomas what is the problem to have a <code>digestif</code> library which contains only the mli file.</p>
<h4 id="ocaml-git-4">OCaml Git</h4>
<p>So from the last discussion we show a problem about the minimal API and how to store a PACK file for the memory back-end and the file-system back-end.</p>
<p>From a discussion with <span class="citation" data-cites="samoht">@samoht</span>, we decide to abstract the PACK file for the shared interface as a stream. In the file-system back-end, we took the stream, do some computation (like if the PACK file is a /thin/ PACK file or not) and, produce the IDX file and save it in the .git/objects/pack/ directory.</p>
<p>This is a big change from the previous API which populate the git repository with /loose/ files.</p>
<p>From this big change, I reorganize the PACK engine which takes care about how to handle available PACK files of the git repository in the file-system back-end. I optimized the memory consumption when we need to undelta-ify an object.</p>
<p>The process now is more clear and documented: * Firstly, we load only the IDX file to know which Git objects are available in which PACK file * Then, when the user request a Git project stored in a PACK file, we start to compute some informations - like the biggest object, the max depth, how many bytes we need to store hunks, etc.</p>
<p>From these informations, we grow the state-defined buffer to allow to undelta-ify any object from the specific PACK file without any allocation.</p>
<p>However, we continue to have a <em>memory leak</em> (it's not but the memory consumption is not predictable at this point) we the pack file need an external ressource (so, a thin pack). * Finally, we can do a second pass to know if the pack file is a thin pack or not (and grow the state-defined buffer in consequence)</p>
<p>In memory back-end, we continue to populate from the pack stream, the git repository. We don't have yet an abstraction of the pack file in the memory back-end.</p>
<p>However, and it's the purpose of the new API, because we abstract a PACK file received by the external world as a stream, we let the back-end to choose the best way to store the pack file (in memory, it will be a [Cstruct.t] and in file-system, it's a file).</p>
<p>I switched the [Sync_http] protocol to use this abstraction and now it's more easy to handle a PACK file in the protocol - because, now, the back-end handles the pack file and not the protocol.</p>
<p>I will switch the [Sync] protocol too but it will be easy.</p>
<p>Finally, for the file-system back-end, when it receives a PACK file, it tries to know if the pack file is thin or not. In the first case, we generate a new non-thin pack file (as git) and in the second case, we just generate the IDX file and move from the temporary directory the pack file to the git repository.</p>
<p>However, about all, I catched a bug about the CRC-32 checksum and try now to fix the bug. I did not push my change because I want to fix this weird bug because.</p>
<h3 id="week-38">Week 38</h3>
<h4 id="romain-calascibetta-5">Romain Calascibetta</h4>
<h4 id="decompress-4">Decompress</h4>
<p>I launched the afl test and fixed the bug founded. It's about a special case of decompress when it deflates a data. Indeed, when we deflates a input lowest than 12 bytes, we launched a specific algorithm which does not need some assumptions to work.</p>
<p>The bug appears in this case and I fixed it easily. Then, I relaunched the afl test and, now from 4 days, alf did not catch an error yet.</p>
<h4 id="digestif-4">Digestif</h4>
<p><span class="citation" data-cites="hannesm">@hannesm</span> showed me a code which is freely licensed (public domain) about the implementation of the RIPEMD160 hash algorithm. So, I integrated this code in Digestif, passed all tests and merge it in master. It's ready for a next release.</p>
<p>However, <span class="citation" data-cites="cfcs">@cfcs</span> asked me to implemente the BLAKE2s hash algorithm. So, when I finish this implementation, I will do a benchmark and release it.</p>
<p>In fact, at the same time, I asked to Louis some benchmark to compare with <code>ocp-sha</code>. I did not look the implementation but I keep it in my TODO list of Digestif.</p>
<h4 id="ocaml-git-5">OCaml Git</h4>
<p>Polishing and debugging. In fact, the <code>git</code> core library did not change a lot but I figure about the API all the time. I worked to provide the git-unix implementation, a git-http implementation which uses <code>cohttp</code> (but it can use <code>cohttp-js</code>) and reorganize the project under the <span class="citation" data-cites="samoht">@samoht</span>'s advise.</p>
<p>In the details, I integrated <code>read_inflated</code> and <code>write_inflated</code> as a part of the shared API between the memory back-end and the file-system back-end.</p>
<p>I linted the API of the web abstraction needed by the git-http implementation - I think about cohttp/httpaf. The point is, git-http uses the cohttp-lwt implementation but not the cohttp-lwt-unix implementation. git-unix/ogit-http-clone uses the cohttp-lwt-unix but we can use with the memory back-end (which restricted with the minimal interface) the cohttp-js implementation.</p>
<p>Finally, sync_http, the main module which implements the Smart HTTP protocol (encode/decode) does not need <code>cohttp</code> but a implementation which respects the interface <code>s.web</code>.</p>
<p>Finally, I found 2 bugs about the sync_http implementation: * The first is a <em>sattelite</em> bug. I mean, it's about how to use cohttp with the Smart HTTP protocol. Indeed, the POST request which <em>negociates</em> with the server need to not be chunked. * The second bug it's about a missing implementation of the side-band but it's not so big.</p>
<h3 id="week-37">Week 37</h3>
<h4 id="takayuki-imada">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished writing a report document to summarise my research work in OCaml Labs.</li>
<li>I will do something needed to close my research at the lab such as termination of using servers.</li>
</ul>
<h4 id="romain-calascibetta-6">Romain Calascibetta</h4>
<h4 id="decompress-5">Decompress</h4>
<p>I just started to test decompress with afl, we found 41 tests cases where decompress fails. So we can start to fix bugs. See the PR:</p>
<p>https://github.com/mirage/decompress/pull/35</p>
<h4 id="angstrom">Angstrom</h4>
<p>When I tried to produce a dot file for a git repository, I found a bug in Angstrom available in this issue:</p>
<p>https://github.com/inhabitedtype/angstrom/pull/104</p>
<h4 id="digestif-5">Digestif</h4>
<p>I just finished the implementation of the RIPEMD160 hash algorithm (asked by <span class="citation" data-cites="vbmithr">@vbmithr</span>) in C and in OCaml. The implementation is available in this PR:</p>
<p>https://github.com/mirage/digestif/pull/12</p>
<p><span class="citation" data-cites="hannesm">@hannesm</span> points a problem about the license, so I wait a response from Antoon Bosselaers to use freely the C implementation.</p>
<h4 id="ocaml-git-6">OCaml Git</h4>
<p>The PR#227 continues. I move the core library to <code>jbuilder</code>, implement a top-level and a program which produce a dot file of a Git repository - to test the current implementation.</p>
<p>With these, I found some bugs and fixed all - bugs from the PR when I polished warnings.</p>
<p>I found a segfault (which show me the bug in Angstrom) in ocaml+4.03.0. It's about a non-exhaustive pattern-matching on exceptions. Then, Angstrom raises an <code>Index out of bounds</code> and, because the pattern-matching is not exhaustive, we have an undefined behaviour (instead an exception from the OCaml runtime) and we finish to a segfault with a block with the tag 1002 (which should not appear after 3.11).</p>
<p>I met Pierre Chambart and we discussed about that. When I handle the exhaustiveness of the pattern-matching, all is ok in ocaml+4.03.0 and in 4.04.0, OCaml raises a runtime exception about the exhaustiveness of the pattern-matching.</p>
<p>Finally, I put an new issue in OCaml about warnings and the PPX, see #MPR7624.</p>
<h4 id="type-beat">type-beat</h4>
<p>I updated type-beat to use the last version of Angstrom.</p>
<h3 id="week-36">Week 36</h3>
<h4 id="takayuki-imada-1">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished performance evaluation of my MQTT broker, and found that my MQTT broker employing Netmap can handle 10,000 clients publishing 10,000 different topics with just 25% CPU utilization whereas a MQTT broker written in C (Mosquitto) indicated over 80% CPU utilization to handle the same clients.</li>
<li>Could not saturate the maximum MQTT broker performance due to the lack of resource shortage in the client side. But I found that my MQTT broker with Netmap can handle 15,000 clients with 43% CPU utilization.</li>
<li>I will write a report document to summarise my research work in OCaml Labs next week.</li>
</ul>
<h3 id="week-35">Week 35</h3>
<h4 id="takayuki-imada-2">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Have fixed a bug on TCP connection close which I found in the last week.</li>
<li>Resumed performance evaluation of my MQTT broker.</li>
</ul>
<h3 id="week-34">Week 34</h3>
<h4 id="takayuki-imada-3">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished learning how to use Gatling + its MQTT-plugin for performance harness and confirmed they can issue a bunch of MQTT client requests as I expected (10,000 publishers and 1 subscriber).</li>
<li>Found a bug of my MQTT broker through the performance harness test. I also found out the bug is related to TCP connection close in handling MQTT disconnect requests, so I will fix it next week.</li>
</ul>
<h3 id="week-33">Week 33</h3>
<h4 id="takayuki-imada-4">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Found a bug of higher CPU utilization (~90%) in hadling a incoming packet from MQTT publishers, and fixed it.</li>
<li>Confirmed the MQTT broker can operate as expected. Good result.</li>
<li>Started investigation of what kind of performance harness for MQTT brokers I can use to check the performance of the MQTT broker I implemented</li>
<li>Decided to use Gatling + its MQTT-plugin because I can easily modify them to change a workload definition depending on a scenario. I'm now learning and checking how to use it.</li>
</ul>
<h4 id="liang-wang">Liang Wang</h4>
<ul>
<li>Refactor the CBLAS interface, the number of functions is significantly reduced by providing a generic interface for S/D/C/Z types.</li>
<li>Optimise the core functions in Ndarray. I did some experiments trying to unifying matrix and ndarray types. It is doable but the current concern is then performance. Some operations like broadcast is faster in Matrix module than in Ndarray module.</li>
<li>Tune the interface between Actor and Owl, did some distributed learning experiments.</li>
</ul>
<h3 id="week-32">Week 32</h3>
<h4 id="takayuki-imada-5">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished writing code for the packet forwarding database.</li>
<li>I'll start functionality check for the whole application I implemented.</li>
</ul>
<h4 id="liang-wang-1">Liang Wang</h4>
<ul>
<li>Refactor neural network module using functor, the new neural network module supports both single and double precision.</li>
<li>Replace Owl's old optimisation engine with the one in neural module.</li>
</ul>
<h3 id="week-31">Week 31</h3>
<h4 id="takayuki-imada-6">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished implementing a packets parser for 9 MQTT control packets.</li>
<li>but need to implement packet forwarding database and a handler for it. I will do that next week.</li>
</ul>
<h4 id="liang-wang-2">Liang Wang</h4>
<ul>
<li>Enhance neural network modules, try to recreate Google's Inception for image classification.</li>
</ul>
<h3 id="week-30">Week 30</h3>
<h4 id="kc-sivaramakrishnan">KC Sivaramakrishnan</h4>
<ul>
<li>working on the multicore barriers to optimise the stop-the-world phase. Aiming to stay aligned with OCaml's current barrier model to ease upstreaming.</li>
<li>submitted end-of-year report for 1851 fellowship with Alan Mycroft's approval</li>
<li>submitted paper with Oleg about features of Eff using delimcc, and KC has one with multicore</li>
<li>discussion with Daniel Hillerstrom about ICFP tutorial for algebraic effects</li>
<li>this week: working on amd64 %r14 register usage for exception handling in multicore ocaml. Hard to measure these microbenchmarks on a macro scale, so need an opam-bench-repo for realistic use.</li>
</ul>
<h4 id="qi-li">Qi Li</h4>
<ul>
<li>developping the bridge</li>
<li>adopted the idea of vpnkit: core part listening on a unix socket, unikernels, each responsible for a network interface, forwarding packets back and forth to the core part</li>
<li>provided two preliminary endpoints to configure the bridge: <code>/connect</code> and <code>/disconnect</code>, both accept a pair of container names, the bridge will resolve these names using a system resolver and translate them into ipv4 packets filter based on the resolved ip addresses</li>
<li>the configuration service is using a vnetif-based tcpip stack, pitfall got stuck in and out later after hours of debugging: <code>use_async_readers:true</code>, should've read the <code>README.md</code> : (</li>
<li>control rules also include the limited name resolving rights, only <code>connected</code> components could resolve the name of each other</li>
</ul>
<h4 id="takayuki-imada-7">Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Investigated which MQTT control packet I must implement, and found that I must 14 MQTT control packets to support the lowest QoS level.</li>
<li>Started implementing packet handlers for the 14 MQTT control packets.</li>
</ul>
<h4 id="sander-spies">Sander Spies</h4>
<p>gist tool: - autocomplete is now accessible via ctrl+space in the gist tool - moved to promise based communication with the webworker</p>
<h4 id="liang-wang-3">Liang Wang</h4>
<ul>
<li>I migrated the examples and performance tests in Owl to the newly introduced zoo system.</li>
<li>The indexing and slicing functions in Owl still needs enhancement. I also started studying the extension points in OCaml.</li>
</ul>
<h3 id="week-29">Week 29</h3>
<h4 id="takayuki-imada-8">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Found i) that the performance degradation occurs at the Ip.allocates_frame and Cstruct.concat and ii) LLC miss mainly affected it.</li>
<li>This LLC miss is highly related to repeated memory allocation for new packets to be sent. It can be reduced by using pre-allocated memory region provided by Netmap</li>
<li>But ... using the memory region does not have the backward compatibility in the IP layer, and I found it difficult to complete discussion on the compatibility and implement it by the end of my stay in Cambridge.</li>
<li>So I will not look into further performance improvement, and will move to implementation of a MQTT broker application.</li>
</ul>
<h4 id="liang-wang-4">Liang Wang</h4>
<ul>
<li>I spent most of my time last week in enhancing the neural network module. The code in neural_graph module has been refactored and feedforward module will become obsoleted in the future version.</li>
</ul>
<h3 id="week-28">Week 28</h3>
<h4 id="takayuki-imada-9">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Conducted serval experiments to understand which part of the code is delayed, and found that udp.write and netif.writev functions on the sender side were delayed.</li>
<li>I will have further investigation on why this happens.</li>
</ul>
<h4 id="sander-spies-1">Sander Spies</h4>
<ul>
<li>Worked on the OCaml-webworker</li>
</ul>
<h4 id="romain-calascibetta-7">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac">ocaml-git / sirodepac</h4>
<h5 id="about-fetch-a-repository">About fetch a repository</h5>
<p>So, first, I re-implement a negotiation engine about fetch. It follows the current non-optimal implementation of Git. I saw the paper about the bloom filter to optimize the negotiation but I don't have a time to implement this.</p>
<p>The good point is the modularization of the fetch compute in ocaml-git. Indeed, we can change the negotiation engine by another engine easily.</p>
<p>About the PACK file received, with Thomas Gazagnaire, we catch a weird compute from Git. In fact, when we receive a <em>thin-pack</em> (which contains some externals references), Git took it and make a new canonical PACK file (which does not contain any external reference). Then, Git saves it in the store.</p>
<p>It's weird because if we store directly the <em>thin-pack</em> and avoid the next compute, all works. So, Thomas and me decide to let the choice to avoid the next compute and store directly the <em>thin-pack</em> or generate a new canonical PACK file. This is prove my implementation of the encoder of the PACK file.</p>
<h5 id="about-push-to-a-repository">About push to a repository</h5>
<p>I continue to focus my work on the push command. When I try to understand what Git does, I saw a little DSL about set of commits (we can see this DSL with <code>git parse-rev</code>). This DSL is a key of which commit we need to send to the server. So, I implement this and some other stuff about reference.</p>
<p>Then, I implement the smart protocol about the push command but I did not yet test the command. I think, it's done today or tomorrow :) !</p>
<h4 id="liang-wang-5">Liang Wang</h4>
<ul>
<li>I have been experimenting how to share small code snippets to extend Owl's numerical functionality. I implemented a &quot;zoo&quot; directive to let user share code snippets through gist.</li>
</ul>
<h3 id="week-27">Week 27</h3>
<h4 id="kc-sivaramakrishnan-1">KC Sivaramakrishnan</h4>
<ul>
<li>Published a new blog post: kcsrk.info/multicore/gc/2017/07/06/multicore-ocaml-gc/ which was discussed on HN: https://news.ycombinator.com/item?id=14780159</li>
<li>Submitted a grant proposal with Martin Kleppman et al. on set based CRDTs. Working on a Irmin based backend for this.</li>
<li>Multicore OCaml debugging.</li>
<li>Preparing for an SRG seminar on Multicore OCaml GC.</li>
<li>Preparations for ICFP talks / workshops / events / tutorials.</li>
</ul>
<h4 id="takayuki-imada-10">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Trying to identify what factor affects the performance degradation. I found that GC related statistics under the solo5 with Netmap environment under single/concurrent send-recv pair(s) has not changed.</li>
<li>Started implementing an OCaml module for rdtsc() which is used to measure the execution time of a OCaml function on Solo5/ukvm.</li>
</ul>
<h4 id="romain-calascibetta-8">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-1">ocaml-git / sirodepac</h4>
<h5 id="about-the-mini-encoder">About the mini-encoder</h5>
<p>As I said previously, I re-implement a mini encoder to provide an API « à la Faraday » but this API was constrained by the memory. In fact, Faraday is a encoder which one has no limit to save what you want to encode. The internal buffer can growth and, if we don't have an other concurrency thread to consume the internal buffer of the Faraday state, we will have a problem with the memory consumption for some cases (like when we want to digest a huge blob).</p>
<p>So, in the previous week, I finished the implementation and now, all is good. The mini encoder works perfectly.</p>
<h5 id="about-the-smart-protocol">About the Smart protocol</h5>
<p>In previous week, I spoke about the Smart protocol with Git to clone/fetch/push a PACK file and test my implementation. I said than the current implementation of the Smart protocol in ocaml-git does not provide a good API to play with it - it's like some common operation but you can manipulate in the details what is going on the exchange with a Git daemon.</p>
<p>So, I decided to re-implement the Smart protocol in other way and I finished the implementation with a close user-friendly operation with my PACK decoder.</p>
<p>More precisely, I catch a memory bug when we try to clone a big repository. Indeed, in a specific (but common) context, we need to undelta-ify some objects stored in the PACK file received. The big problem is, for each delta-ification, we need to save a list of hunk to re-construct the requested object.</p>
<p>So, previously, for each hunk, I allocate a little string and keep all as long as we deserialize the object. At the end, I use these hunks to reconstruct the current object. However, the base of the requested object can be delta-ified too. Finally, we can have 50 level of delta-ification and to reconstruct the final object, we need to keep all hunks at each level of each base object. And, we literally use a lot of memory for that.</p>
<p>So, I decided to undelta-ify the object against an heuristic described in the technical document of git. The point is, the base of an object must be before the object (inside the PACK file). So, I can calculate for the first pass the biggest depth of the PACK file. Then, in the second pass, when we delta-ify the rest of the object, I allocate n buffer (n = max_depth) and for each undelta-ification, I used these buffer to store hunks (instead to allocate).</p>
<p>So, we allocate, one time, a big buffer, and re-use this buffer as long as we undelta-ify the delta-ified objects.</p>
<p>This is needed to calculate the hash for each object and produce an IDX file, which will be saved in the file-system.</p>
<p>I tested this approach and, to clone ocaml-git for example, I use 1~2 % of my memory (4 GB) to deserialize all object of the PACK file received. However the process is little bit slow. Another point is, when I try to clone a repository with a huge file, I use lot of memory but all the time, the OCaml GC can compact the area and we are not close to the [Out_of_memory] problem now.</p>
<p>Now, I focus on the push command.</p>
<h4 id="liang-wang-6">Liang Wang</h4>
<ul>
<li>I have been working on Owl's dependency last week. Due to the recently added interface to CBLAS and LAPACKE, Owl relies on OpenBLAS. However, CentOS does not provide the corresponding binary format of OpenBLAS. Building from source code using conf-openblas seems tricky. Anil suggested submitting an RPM.</li>
<li>I enhanced core functions in Owl, e.g., by add a new function to generate magic square matrix.</li>
<li>Owl was posted on Hacker News. This brought in a lot of publicity so I improved the documentation a bit.</li>
</ul>
<h3 id="week-26">Week 26</h3>
<h4 id="takayuki-imada-11">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished performance evaluation with Netmap buffer manipulation in the guest OS side. I confirmed it can achieve 2.0 - 3.3x throughput under 1 sender/receiver pair on a host physical server.</li>
<li>However, its throughput under 6 sender/receiver pairs on two physical servers was similar to that with the original tap device. I found that this was mainly affected by non-Netmap processing. So I will try to identify what does affect the obtained performance.</li>
</ul>
<h4 id="romain-calascibetta-9">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-2">ocaml-git / sirodepac</h4>
<h5 id="encoder">Encoder</h5>
<p>I finish to integrate the core part of sirodepac inside ocaml-git. In the previous week, I explained that the couple Angstrom/Faraday is good about the serialization/deserialization. However, I have some bit problem with Faraday. The context of the serialization in ocaml-git is not the same than httpaf. The first difference is about where we serialize a Git object.</p>
<p>Faraday was thinked to write directly to a file descriptor/socket. It was thinked to be share between 2 process, one to write in the internal buffer, the next to write to the file descriptor. But, in ocaml-git, we use the serialization of a Git object in a other case. One of this case is about the serialization to feed a context and get, at the end, an hash. So, the target of the serialization is not a file descriptor but an internal buffer.</p>
<p>So, I decided to create a mini non blocking encoder with a fixed size memory fingerprint. And I finished in few day. It's used to produce the same as Faraday but with some news constraints. This is work perfectly and we keep a control about the memory consumption.</p>
<h5 id="write-a-pack-file">Write a PACK file</h5>
<p>Then, we can write a PACK file now but I need to polish deeply the API. This is the end thing to do. Before, I want to try my PACK file in the real world.</p>
<h5 id="smart-git-protocol">Smart Git Protocol</h5>
<p>To test my deserialization/serialization of the PACK file, I decided to interact with a Git server with the Smart Git Protocol. I saw the Sync.ml module, which implements all things about the communication. However, this module was thinked in the same way as the previous implementation of ocaml-git.</p>
<p>So, I fund the same problem before and I decided to take down all. I re-implement the Smart Git Protocol in same way than ocaml-imap. I described why in a long comment (and why I don't choose Angstrom/Faraday). So, I can clone now and for this week I'm focus about the negociation with a Git server.</p>
<h4 id="liang-wang-7">Liang Wang</h4>
<ul>
<li>Most of the time was spent in redesigning the linear algebra module. The new module is built atop of Owl's native interface to CBLAS and LAPACKE.</li>
<li>I was enhancing Owl's core functions: most of the vectorised math functions now support complex numbers.</li>
</ul>
<h3 id="week-25">Week 25</h3>
<h4 id="takayuki-imada-12">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished implementing the ring buffer manipulation functionality in the guest OS layer. I will start performance evaluation with it.</li>
<li>Tried to reduce the memory size mapped from the host OS layer. It worked fine, but requires a larger number of memory regions in Linux KVM. Memory regions are a concept of physical memory slots in KVM, so we cannot use a limited number of memory regions for a VM.</li>
</ul>
<h4 id="romain-calascibetta-10">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-3">ocaml-git / sirodepac</h4>
<p>I still in the integration of the sirodepac code-base inside the ocaml-git project. About all read operation, all is good, I found a bug in the beginning of this week but I fixed this quickly. Then, I continue to try to integrate the serialization.</p>
<p>So, previously, I said I used the couple Angstrom/Faraday from Seliopou. Angstrom is perfect but Faraday is specialized to serialize and write directly to an output (by iovec). However, by the API, I'm not free to decide how to write a Git object.</p>
<p>Firstly because iovec is not available with lwt (and we have a strong dependency with lwt) and because the way to serialize with Faraday is to up two process. One to write inside the Faraday encoder and the second to write to the output. In the ocaml-git context, it's better to let the user to do this choice.</p>
<p>But sometime, internally, I need to serialize a Git object to obtain a digest for example - but we have some other use-case when the serializer does not interact directly with the output (and the PACK file serializer is another good example).</p>
<p>So, I decide to provide at the same time a little encoder (minienc) to serialize a Git object correctly in a fixed size buffer (I use a ring-buffer and a queue in a limited context). The good point is, to digest (or serialize in the PACK), we continue to control the memory consumption strictly. So this encoder is done. However, it's may be better to provide an interface « à la Farfadet » or « à la Printf-like » for this encoder and improve the re-usability of the code. But I want to move fast, so not yet.</p>
<h4 id="digestif-6">Digestif</h4>
<p>I implemented the MD5 hash function in OCaml and rename the library. So if you want to use the C implementation of the hash, you just need to link with <code>digestif.c</code>. Otherwise, for the OCaml implementation, you can link with <code>digestif.ocaml</code>.</p>
<h4 id="radixpatricia-tree">Radix/Patricia tree</h4>
<p>When I worked on sirodepac, I re-used a code from BeSport about the implementation of a tree to store some object binding with a key. <span class="citation" data-cites="g2p">@g2p</span> seems to want the same but with a remove operation.</p>
<p>So, may be I will start a benchmark to compare my implementation with standard implementation of Map in OCaml - I already did a benchmark between my implementation and the implementation of the Thomas and I'm more fast (but use a lot of memory).</p>
<h4 id="liang-wang-8">Liang Wang</h4>
<ul>
<li>I spent a lot of time in writing the interface between Owl and low-level interface to CBLAS and LAPACKE.</li>
<li>I started rebuilding the documentation of Owl, studied some new tools and also tried to find a new place to host the docs.</li>
<li>I have improved several functions in matrix module.</li>
</ul>
<h3 id="week-24">Week 24</h3>
<h4 id="takayuki-imada-13">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Designed implemented memory mapping of Netmap ring buffers so that they can be easily handled by the Guest OS layer.</li>
<li>I found the current Netmap implementation does not allow us to reduce the maximum number of slots on a ring buffer in order to reduce the amount of memory size, though I was expecting it allows us to do so. The maximum number depends on a network device I use. Therefore, the prototype will consume larger memory space than expected.</li>
</ul>
<h4 id="sander-spies-2">Sander Spies</h4>
<ul>
<li>started moving RWO examples from corebuild to jbuilder</li>
</ul>
<h4 id="romain-calascibetta-11">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-4">ocaml-git / sirodepac</h4>
<p>I continue to integrate my work in ocaml-git. So, the integration of the decoding is close to be done. Indeed, I can read any object from any PACK file with the same API. I decided to provide an <em>easy-to-use</em> API (same as the previous API of ocaml-git) and a more complex API to control precisely the allocation. With this API, we can compute in a parallel way the git object if we have some specific buffers available, otherwise, we can compute step by step each objects with a <em>global</em> buffer.</p>
<p>So, now, I need to integrate the serialization inside ocaml-git and think about a good API.</p>
<p>I continue to check my work step by step, try with <code>decompress</code> and <code>camlzip</code> to keep the compatibility. I put a documentation for all and describe some complex process inside the ML file to keep an understable code for other user.</p>
<p>So, for this moment, all seems to be good and, I think, we will have a good API.</p>
<h4 id="cufp">CUFP</h4>
<p>I send my proposal after a review with Thomas, Gemma, Anil and KC, at the next CUFP, I'm waiting now the response :) !</p>
<h4 id="ocaml-network">OCaml network</h4>
<p>I'm currently in Singapore and met all people from Ahrefs. Obviously, I met Enguerrand (and he is good) but I met other people from this corporation and speak about ICFP, OCaml and other stuff.</p>
<p>A good news, some people from this corporation keep an eye in the MirageOS project - and think that the unikernel is the future!</p>
<h4 id="liang-wang-9">Liang Wang</h4>
<ul>
<li>I had been working on interfacing to CBLAS and LAPACKE last week. I wrote a parser to generate the interface automatically from cblas.h and lapacked.h. I also used Ctypes but the giant &quot;foreign&quot; function makes compilation extremely slow. I tried a couple of solutions then ended up using the c_stub code generated by ctypes but generate ocaml_stub myself in the parser. The parser also generates mli file to make sure the type signature is correct. This solution achieves both the strictness on type and efficiency on compiling.</li>
<li>Currently, Owl implements a full interface to all CBLAS and LAPACKE functions (over a thousand). These code are generated automatically, but I will write high level interface myself later this month.</li>
</ul>
<h3 id="week-23">Week 23</h3>
<h4 id="kc-sivaramakrishnan-2">KC Sivaramakrishnan</h4>
<ul>
<li>Planning for migrating Lwt and Async to direct-style effect-based I/O.</li>
<li>Experimenting with reify reflect for transforming monadic IO to direct-style. Experiments are here: https://github.com/kayceesrk/reify_reflect_concurrency</li>
</ul>
<h4 id="qi-li-1">Qi Li</h4>
<h4 id="databox-bridge">databox-bridge</h4>
<ul>
<li>supported dns, containers from different networks that are connected by the bridge could resolve the domain names of each other</li>
<li>looked into <a href="https://github.com/moby/vpnkit">vpnkit</a>, code about de/multiplexing packets from/to multiple tcp/ip stack endpoints could probably reused by the bridge</li>
<li>when started, each stack registerd itself to some central dispatching unit</li>
<li>for input, push packets to the same stream</li>
<li>the central unit drain from the stream, parse packets, distribute packet to corresponding stack</li>
</ul>
<h4 id="takayuki-imada-14">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished implementation of Netmap buffer mapping test functions, and confirmed Netmap buffers on the host OS can be directly accessed from the guest Solo5-ukvm kernel.</li>
<li>The current memory mapping location is designed like MMIO, but tentative. So I will need to consider the best mapping address for Solo5-ukvm.</li>
<li>I will move to the next step, implementation of queue-based packet handling in the guest Solo5-ukvm kernel.</li>
</ul>
<h4 id="romain-calascibetta-12">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-5">ocaml-git / sirodepac</h4>
<p>I continue to integrate my work in ocaml-git. I decided to do a change <em>bottom-to-top</em> replacement: that means, I keep the interface of the Git module but I create a new implementation. Why ? ocaml-git is based on a stop the world serialization and we can see this constraint for the File System interface (which implements <code>read</code> and <code>write</code> but not on a non-blocking interface).</p>
<p>I believe is that why ocaml-git consumes a lot memory because it does not work on a fixed size buffer. So I decide to add a non-blocking interface to the File System signature required.</p>
<p>Then, I provide an Angstrom parser and a top layer to de-serialize a non-blocking input from an Angstrom parser. We have a limitation but I explain precisely why this limitation exists.</p>
<p>So, I re-implement the loose file firstly and I will add my work then. It's a deep work, so when I have a result, I will notice. Another point is about the Hash. At this moment, we store the hash inside a bigarray (located directly in the major heap). May be we need to change this to a bytes to optimize the memory consumption (because the client should use a lot of hashes).</p>
<p>Voilà, not so much this week to show but a deep work :) !</p>
<h4 id="liang-wang-10">Liang Wang</h4>
<ul>
<li>I studied how the primitives of distributed computing are designed in Julia.</li>
<li>I implemented the experimental feature of distributed computing in Owl: for neural module and ndarray module.</li>
<li>I implemented ndarray.any module, it is an n-dimensional array module that supports any types besides numerical types.</li>
</ul>
<h3 id="week-22">Week 22</h3>
<h4 id="kc-sivaramakrishnan-3">KC Sivaramakrishnan</h4>
<ul>
<li>Submitted 3 papers to ICFP workshops</li>
<li>Mergeable Types: kcsrk.info/papers/mergeable_types_draft.pdf</li>
<li>Effectively Tackling the Awkward Squad: http://kcsrk.info/papers/awkward_effects_ml17.pdf</li>
<li>A Memory Model for Multicore OCaml: http://kcsrk.info/papers/memory_model_ocaml17.pdf</li>
</ul>
<h4 id="qi-li-2">Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>started implementing a first version by plumbing through DNS for containers not on the same network</li>
<li>adopted the idea of a forward DNS server, if couldn't resolve, forward to <code>127.0.0.11:&lt;port&gt;</code></li>
</ul>
<h4 id="takayuki-imada-15">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Started implementation of the second phase.</li>
<li>Finished iothread porting from kvmtool<a href="https://github.com/me-box/databox-export-service.git">1</a>, and confirmed ioeventfd-based trapping worked as expected.</li>
<li>Investigating the current design of the upper layers(mirage-tcpip and mirage-net-solo5) to have a new path between mirage-tcpip in a guest OS and Netmap on its host OS.</li>
</ul>
<p><a href="https://github.com/me-box/databox-export-service.git">1</a> https://git.kernel.org/pub/scm/linux/kernel/git/will/kvmtool.git</p>
<h4 id="romain-calascibetta-13">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-6">ocaml-git / sirodepac</h4>
<p>Previously, I found a bug in my implementation. Now all is ok we can serialize all git object with a fixed size memory consumption. It's done by a deserialization with a fixed size memory consumption. So I played with some buffer between the serialization and the deserialization and all is fine. The produced PACK file work and we keep the integrity of the data.</p>
<p>I asked to Gemma to have an access to a machine to run some huge tests about the compression.</p>
<p>Then, I finish to write the documentation for ALL modules. All modules are explained and some tricks and implementation specified are described inside the ML file. I hope all is clear and someone can read and understand the code.</p>
<p>I started to integrate all in ocaml-git. So, I did some big change.</p>
<ul>
<li><p>I replaced the LRU module from Simon Cruanes by the implementation provided by David as the <code>lru</code> package in OPAM. A good point about this library is to control precisely the memory consumption of your object (and no how many object you can store). This point is good to keep the precise control about memory consumption because when we store some git object inside the cache, may be one took 1 Go and one other took 100 Ko. So, instead to keep these 2 objects, we keep one of them if we limit the memory consumption by 5 Go for example.</p></li>
<li><p>I cleaned the interface of the CRC-32 checksum and provide a new type <code>t</code> which one is a <code>private int32</code>. So we keep the abstraction about the CRC-32 (and don't do a mistake with the <code>int32</code>) and optimize the the computation when we want to serialize to an <code>int32</code> (by the sub-typing: <code>v :&gt; int32</code>).</p></li>
</ul>
<p>I go to take my car to Sieam Reap sorry ...</p>
<h4 id="liang-wang-11">Liang Wang</h4>
<ul>
<li>I spent a lot of time in refactoring the API in neural module, and added several merge layers (add/mul/dot) into the module.</li>
<li>I finished the first version of <code>Owl_neural_graph</code> module. Owl can make a neural network of DAG topology. The new api is also easier to use. For example, making a convolutional neural network as below ```ocaml open Owl_neural;; open Owl_neural_feedforward;;</li>
</ul>
<p>let nn = input [|28;28;1|] |&gt; conv2d [|5;5;1;32|] [|1;1|] ~act_typ:Activation.Relu |&gt; max_pool2d [|2;2|] [|2;2|] |&gt; conv2d [|5;5;32;64|] [|1;1|] ~act_typ:Activation.Relu |&gt; max_pool2d [|2;2|] [|2;2|] |&gt; dropout 0.1 |&gt; fully_connected 1024 ~act_typ:Activation.Relu |&gt; linear 10 ~act_typ:Activation.Softmax in print nn;; ```</p>
<h3 id="week-21">Week 21</h3>
<h4 id="kc-sivaramakrishnan-4">KC Sivaramakrishnan</h4>
<ul>
<li>Adding support for <a href="https://github.com/ocamllabs/ocaml-multicore/tree/afl">afl-fuzz for multicore</a>. The aim is to fuzz the thread schedules. Progress is slow.</li>
<li>Admin stuff: trip planning, visa applications, paper reviews.</li>
</ul>
<h4 id="qi-li-3">Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>investigated the DNS service within docker environment</li>
<li>each container has a local dns server sitting at 127.0.0.11 on not standard <em>(53)</em> port</li>
<li>the default setting for container could be changed to assign a cutomized endpoint for DNS queries</li>
<li>looked for ways to change network gateway for containers</li>
</ul>
<h4 id="takayuki-imada-16">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Evaluated the network throughput performance with the first Implementation. But the first implementation does not achieve good performance compared with the original Solo5-ukvm(up to 10% performance degradation).</li>
<li>The main reason of this performance is high overhead in data queue syncing with DMA triggering on a NIC on the sender side. The first implementation does packet sending one by one depending on data write function calls from the GuestOS layer, so highly frequent write function calls can easily lead to performance degradation. This is not anticipated because data queue syncing is managed by Netmap.</li>
<li>Additionally, I also found that softirq RX processing is always triggered when packet sending is done, and the softirq processing is heavy load. This is the specification of the current Netmap implementation. I need to reduce the number of packet sending calls as possible.</li>
<li>However, I will move to the second implementation phase because reduction of the number of packet sending calls is planned in the second phase.</li>
</ul>
<h4 id="romain-calascibetta-14">Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-7">ocaml-git / sirodepac</h4>
<p>So I most done my last task about <code>sirodepac</code> and control the memory consumption. But I found a bug and it's about the serialization of a hunk. I created a mini hunks decoder to help to find the bug. And now, I know precisely where is it. So I will fix this and continue to test some others PACK files with an implementation of <code>zlib</code> and <code>decompress</code>.</p>
<p>I hope, I finish this week this bug, it's a very deep bug but it's ok, in same time, I put some useful comments to help me to understand my code and check my implementation.</p>
<h4 id="conferences">Conferences</h4>
<p>So, I created a new talk for the Functional Conference in India and my talk was accepted! Then, Mark Li asked me to do a CUFP tutorial about Git in OCaml. I think about this and OCaml labs was agreed to do this. So, I prepare in my mind what I will do and ship an abstract before the deadline.</p>
<h4 id="liang-wang-12">Liang Wang</h4>
<ul>
<li>I publish a new release for both Eigen.0.0.4 and Owl.0.2.5 on OPAM.</li>
<li>I am still focusing on the neural network module in Owl. I finished <code>Dropout</code>, <code>Reshape</code>, and <code>Flatten</code> layers this week. With these new layers, I implemented a convolutional version of the previous MNIST example which used simple Feedforward network.</li>
<li>I added a new <code>concatenate</code> function to Ndarray and Matrix module, this function is able to concatenate a list of ndarrays/matrices based on the specified axis.</li>
</ul>
<h3 id="week-20">Week 20</h3>
<h4 id="kc-sivaramakrishnan-5">KC Sivaramakrishnan</h4>
<ul>
<li>Lots of fixes to DWARF unwinding information: https://github.com/ocamllabs/ocaml-multicore/commit/65b329deb4296ea8fcfba788b9fcad921dbe1a9a.</li>
</ul>
<h4 id="david-allsopp">David Allsopp</h4>
<h2 id="ocaml">OCaml</h2>
<ul>
<li>Various exchanges regarding the GPR#1127/GPR#1168/GPR#1172 build system changes</li>
<li>4.05 testing leading to a few tweaks (GPR#1177)</li>
<li>Fixes pushed to trunk and 4.05 fixing Inria CI (MacOS, mingw32/64, ppc32/64)</li>
</ul>
<h2 id="opam">opam</h2>
<ul>
<li>Oozing towards being able to run the make win-zips test on Azure.</li>
<li>Various build system tweaks required, especially dealing with Warning 58 (-opaque not used) in third party libs</li>
<li>msvs-tools needs updating for VS2017 and integrating - turns out that's not just a simple meta-data change (there's a new tool called vswhere which needs to be integrated with msvs-detect)</li>
<li>PR#2935 merged; various work rebasing and keeping up with the others</li>
<li>Complete sweep of open opam issues (now subscribed to all changes)</li>
</ul>
<h4 id="qi-li-4">Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>developped a mirage network device that could be attached to the host interface directly</li>
<li>used packet socket in c layer, so not a compatible solution for all targets</li>
</ul>
<h4 id="takayuki-imada-17">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished writing some script files to conduct performance evaluation</li>
<li>Started the performance evaluation as follows:
<ol type="1">
<li>a pair of receiver and sender unikernels on a host physical server</li>
<li>multiple pairs of the unikernels on a host physical server</li>
<li>multiple pairs of the unikernels on two different physical servers(multiple sender unikernels on a physical server, and multiple receiver unikernels on the other physical server)</li>
</ol></li>
</ul>
<h4 id="romain-calascibetta-15">Romain Calascibetta</h4>
<h4 id="digestif-7">Digestif</h4>
<p>So I push a new PR to follow my change in digestif. We have two implementation now, a C and an OCaml implementation and they share the same interface. So you just need to link to the implementation you want.</p>
<p>I will look the go digest interface to do the same. But I think, we close to a good API. I asked to Andres Hauptmann to talk about cryptohash. Indeed, it's another project to provide some hashes functions and I ask to integrate this work inside Digestif. So, he agreed with me and when I have the time, I will integrate this work.</p>
<h4 id="decompress-6">Decompress</h4>
<p>I found a bug about one information available in Decompress, so I fixed it in a new PR. This change does not impact the API. So, I will wait the next release of Decompress to merge this PR.</p>
<h4 id="typebeat-farfadet">TypeBeat / Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="angstrom-1">Angstrom</h4>
<p>I just try to optimize Angstrom from <span class="citation" data-cites="seliopou">@seliopou</span> just for my curiosity and try to use the <code>[@@unboxed]</code> tag to the representation of a parser. But it seems to not be good. When I launch the benchmark, I noticed regression about performance. I don't know why but I noticed <span class="citation" data-cites="seliopou">@seliopou</span> about that in Slack.</p>
<h4 id="ocaml-git-sirodepac-8">ocaml-git / sirodepac</h4>
<p>I tried to control the memory consumption of <code>sirodepac</code> to try to compute a huge PACK file (like the PACK file from datakit). So, I try to limit the allocation of the deserialization and the serialization.</p>
<p>The problem is simply. Sometimes, <code>git</code> computes a huge git object. The problem is: we can't store all of this git object in memory (like if this huge object has 1 Go, we may be catch a <code>Out_of_memory</code>). This situation appear when we compute the PACK file in a <em>stop the world</em> context. We loaded all the git object inside the memory, then we compute the git object.</p>
<p>My idea and for the context of datakit is to continue to follow the non-blocking implementation and avoid any <em>stop the world</em> computes in the serialization and deserialization.</p>
<p>For the deserialization, it's already done. You can write directly step by step a huge git object with a fixed size buffer (and avoid to load all the git object inside memory). The API is very close to the non-blocking API from Mr. Mime, Decompress or dbuenzli's library. The state/context needed to deserialize a git object does not allocate any buffer. You need to notice which buffer the state can use (so we let the user to allocate the buffer needed to deserialize any git object). So, obviously, it's not easy-to-use (like the API of Decompress) because we let the user to control the memory fingerprint of this specific compute.</p>
<p>It's what git does. It prefers to use the file system instead the memory because it know than it's possible to have a huge git object. So it uses a lot of the <code>mmap</code> syscall. <code>sirodepac</code> do the same.</p>
<p>About the serialization, it's complex but not impossible. Firstly, I separate the compute of the delta-ification from the deserialization. The bad point is, the delta-ification is a <em>stop-the-world</em> algorithm (the Rabin's fingerprint is a <em>stop-the-world</em> algorithm specifically). So, the point is continue to let the user to control the memory fingerprint of this compute and it's possible by the <code>lru</code> library from David. Indeed, with this library we can control how many bytes you allow for this cache.</p>
<p>The point is, with the <code>git</code> algorithm, we need a cache/window to try to delta-ify the current git object with a previous git object. So the cache/window can be huge (because, it contains, by default, 10 git object, and these git objects can be huge). Then, we update this cache/window but we allocate a lot just to store the previous git object.</p>
<p>So, I decide to separate this compute from the serialization for two reasons:</p>
<ul>
<li>Firstly, because it's a <em>stop-the-world</em> algorithm, we can't consume step by step a git object and need to store all of some git objects.</li>
<li>Secondly, to let a optimization without any dependence with the serialization (like try to paralyze this compute, like <code>git</code>).</li>
</ul>
<p>So, we can change the serialization to be a non-blocking implementation and use a fixed size buffer to contain an huge git object step by step. The idea, then, is use the characteristic of the non-blocking axiom of the deserialization inside the non-blocking axiom of the serialization. That means:</p>
<p>When you try to serialize a PACK file, we need to serialize all git object inside this PACK file. One way (the previous way) is load all git objects inside memory and serialize all of these inside the PACK file but the memory consumption is too huge.</p>
<p>The new implementation asks the user which git object it wants to serialize. Then, we have a fixed size buffer to store a part of this specific git object. So step by step, we fill this buffer, we let the serializer to compute this buffer, we flush the buffer and continue to fill it while we are not finish to compute all data from this git object.</p>
<p>One point is, a git object is commonly come from another PACK file. So we deserialize in a fixed size buffer what the serializer wants and at the same time, we serialize this fixed size buffer and continue to the end of this git object. So, it's very complex because inside the serialization, we have a deserialization ... And we need to synchronize contexts used for serialization and the deserialization together to not lost any data. it's complex to deal with it but it's possible and it's what I did this week - I did a part, not all.</p>
<p>Then, we have a technical point about a git object provided by the deserialization delta-ified. In this context, you need to load the source git object inside the memory to construct the git object requested ... But you can limit the memory assumption to <code>max_int32 + 0x10000</code> because the Rabin's fingerprint is done only on this area. So, we continue to control precisely the memory consumption.</p>
<p>Voilà voilà :D !</p>
<h4 id="liang-wang-13">Liang Wang</h4>
<ul>
<li>More types of layers have been added in neural module: convolution 2D, convolution 3D, maxpool, fully_connected, lambda layer, and etc.</li>
<li>A large part of the code in neural module was also refactored. Now, Owl is able to validate every layer in a network having consistent input and output shape when constructing a Feedforward network.</li>
<li>Algodiff module is able to support (partially though) N-dimensional array now.</li>
</ul>
<h3 id="week-19">Week 19</h3>
<h4 id="kc-sivaramakrishnan-6">KC Sivaramakrishnan</h4>
<ul>
<li>Working on fixing call-frame information (CFI) in native code. This is important not only for debuggers like gdb, but also for any code that needs to unwind the stack (such as profilers). Finished PR#127 https://github.com/ocamllabs/ocaml-multicore/pull/127 which fixes the backtrace in the current branch.</li>
<li>TFP'17 submission on current system programming with effect handlers is accepted.</li>
<li>Working on extending the CFI information to support backtraces across handlers.</li>
</ul>
<h4 id="david-allsopp-1">David Allsopp</h4>
<h2 id="platform">Platform</h2>
<ul>
<li>Discussion with Gemma &amp; Anil on roadmap from here to ICFP (and a bit beyond...)</li>
</ul>
<h2 id="ocaml-1">OCaml</h2>
<ul>
<li>Started discussions on changes being made in GPR#1127 and GPR#1168 given nuisance it creates for Windows installations.</li>
</ul>
<h2 id="opam-1">opam</h2>
<ul>
<li>Upstreaming PR#2930 implementing the switch-defaults section for opamrc</li>
<li>Work on a --set option for opam init and opam switch allowing switch global variables to be specified at switch creation time (this builds on PR#2930)</li>
<li>Testing and updating lib-pkg build mechanism ready to transfer to Azure (I keep running out of disk space on my ageing opam development VM...)</li>
<li>Various Slack discussions about OPAM leading to docs change in PR#2941</li>
<li>Upstreaming PR#2935 &amp; PR#2936 containing various minor tweaks and fixes from windows-build</li>
<li>Upstreaming PR#2937 containing developer build options for opam</li>
<li>Upstreaming PR#2938 panellising lib-ext compilation</li>
<li>Upstreaming PR#2939 fixing the configuration and build system for native Windows</li>
<li>Upstreaming PR#2940 fixing the build process itself for native Windows</li>
</ul>
<h4 id="qi-li-5">Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>trying out a unix-based network device for mirage unikernel</li>
<li>following the idioms from <a href="https://github.com/mirage/ocaml-tuntap/blob/master/lib/tuntap_stubs.c">tuntap_stabs.c</a>, instead of <code>open(&quot;/dev/net/tun&quot;)</code>, get a packet socket by <code>socket(PF_PACKET, SOCK_RAW, ...)</code>, then add housekeeping and io functions around this socket</li>
</ul>
<h4 id="takayuki-imada-18">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Confirmed the first implementation operated correctly for the 1460 bytes MTU size.</li>
<li>But found that it could not operate when I tried larger MTU size such as 9000 bytes due to strange behavior in the Netmap layer(data frame was split into some blocks with the maximum size 2048 bytes). I will not investigate more on this issue.</li>
<li>I will move to performance evaluation in terms of 1) different MTU size smaller than 1460 bytes, and 2) scalability.</li>
</ul>
<h4 id="romain-calascibetta-16">Romain Calascibetta</h4>
<h4 id="digestif-8">Digestif</h4>
<p>I did the release but I spoke with daniel about the interface and the organization of the library. So I just change the API. I reimplemented the SHA1 and the SHA256 in OCaml. I will push all the next monday.</p>
<p>We moved this repository in mirage organization.</p>
<h4 id="decompress-7">Decompress</h4>
<p>I did the release of 0.6. This release fixed a bug about the decompression but nothing change about the API.</p>
<p>We moved this repository in mirage organization.</p>
<h4 id="typebeat-1">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="farfadet-1">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="ocaml-git-sirodepac-9">ocaml-git / sirodepac</h4>
<p>With Thomas, we push some PRs like the integration of decompress by default and the integration of digestif by default - but we keep all functors. Then, I fixed some bugs in sirodepac about the memory and integrate the optionnal usability of a cache (like a LRU cache) and an access of a hash by the offset.</p>
<p>Thomas sended me a huge PACK file (~ 4 000 000 commits, 10 Go), so I will try to generate a new PACK file from this source. However, the compute is very low and may be crash because I launched the process in my server (and it's not my best machine).</p>
<p>I wrote a documentation about <code>sirodepac</code> but only in french. When I finish, I will ask to fix some errors (in french), then I will try to translate to english - and publish an article :) !</p>
<p>Finally, with Thomas, we think about an abstraction and apply the generation of the PACK for something different than <code>git</code> object and I think it's possible, I have an idea about that. But I'm focus to integrate my work in ocaml-git for the moment.</p>
<h4 id="liang-wang-14">Liang Wang</h4>
<ul>
<li>I spent the whole week in studying convolution neural network stuff. I have looked into code in Tensorflow and implemented a convolution function in OCaml. I will do some comparison next week and focus on the implementation of convolution layer.</li>
</ul>
<h3 id="week-18">Week 18</h3>
<h4 id="kc-sivaramakrishnan-7">KC Sivaramakrishnan</h4>
<ul>
<li>Submitted a paper on concurrent programming with effect handlers to TFP. Draft is <a href="kcsrk.info/papers/system_effects_may_17.pdf">here</a></li>
<li>As a part of the submission, benchmarked http/af with async and effects and compared it against a Go webserver. The results are included in the paper.</li>
<li>We discovered that effects version was leaking memory, which was down to the program leaking bigstrings due to finalizers not being implemented on Multicore. Finalizers for custom objects should be easy to fix.</li>
</ul>
<h4 id="david-allsopp-2">David Allsopp</h4>
<h2 id="opam-2">opam</h2>
<ul>
<li>Teleconference discussing directions for opam 2.0</li>
<li>Roadmap of beta releases to follow (proposed release candidate to be beta3)</li>
<li>Windows hopefully included in beta4</li>
<li>Improvements to the upgrade story required (aim to allow safe side-by-side installation of 1 and 2)</li>
<li>Upstreaming PR#2927 to add &quot;%&lt;...&gt;%&quot; syntax for translating paths from Unix forward-slash style to Windows back-slash style. Lots of discussions ongoing for this...</li>
<li>Upstreamed PR#2928 to ease using Merlin when developing opam (merged)</li>
<li>PR#2915 merged</li>
<li>PR#2921 merged</li>
<li>PR#2923 abandoned (won't be necessary after beta3 is released)</li>
</ul>
<h2 id="ocaml-2">OCaml</h2>
<ul>
<li>Fixing problems with AppVeyor caused by GPR#1127</li>
</ul>
<h4 id="qi-li-6">Qi Li</h4>
<h4 id="databox-bridge-1">databox-bridge</h4>
<p>Thes first step is to intercept l2/l3 packets from multiple interfaces and forward them.</p>
<p>All the existed MirageOS network io solutions may not seem to fit:</p>
<ul>
<li>this compoment will be used inside a docker container, so <code>xen</code> is not good</li>
<li><code>unix</code> and <code>ukvm</code>, <code>virtio</code> targets all use tap devices to do the network io, so for each container interface, there will be bridging and NATing, which will filter out the arp traffic and the ip traffic not targeting the same network</li>
</ul>
<p>So for now, looking into the possibility of a new network device for unikernels, which is on unix, and instead of openning tun/tap devices, open raw sockets and output the l2 packets</p>
<p>Maybe could also modify the <a href="https://github.com/mirage/mirage-net-unix/blob/master/src/netif.ml#L58">mirage-net-unix</a>, to use <del><code>opentun</code></del><em>(mixed opentun and opentap here, so this approach doesn't work)</em> inside the <code>connect</code> function call <em>(tried earlier, but resulted in failures, could look further in the <a href="https://github.com/mirage/ocaml-tuntap/blob/master/lib/tuntap_stubs.c#L73">c code</a>)</em></p>
<h4 id="takayuki-imada-19">Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Confirmed that device initialization including queue allocation and finalization parts operates correctly.</li>
<li>Finished coding sender and receiver functions. I will check if they can operate correctly the next week.</li>
</ul>
<h4 id="romain-calascibetta-17">Romain Calascibetta</h4>
<h4 id="decompress-8">Decompress</h4>
<p>Prepare next 0.6 release.</p>
<h4 id="blake2b-digestif">BLAKE2B / Digestif</h4>
<p>Prepare release 0.1.</p>
<h4 id="farfadet-2">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-2">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="sirodepac-ocaml-git">sirodepac / ocaml-git</h4>
<p>It's DONE! I just finished to implement the git heuristic in <code>sirodepac</code> and the result is: - we produce a PACK file with 1.3MB - git produces a PACK file with 1.2MB</p>
<p>So, yes ... now all is done. <code>sirodepac</code> is finished and, we can start the integration in <code>ocaml-git</code>.</p>
<p>So I need to explain by step what I did:</p>
<ul>
<li>Firstly, I functorize the <em>packer</em> by a zlib implementation module. Now, we can use <code>decompress</code> or <code>camlzip</code>. I did that because <code>decompress</code> is not the best to inflate (the diff is about some bytes) and to follow exactly what git does, I decide to functorize the implementation.</li>
</ul>
<p>The diff between a <em>packer</em> with <code>decompess</code> and <code>camlzip</code> is about 0.1MB. So, it's ok.</p>
<ul>
<li><p>I reproduce exactly the same sort as git. This is the core of the PACK algorithm to find the best diff between 2 git objects.</p></li>
<li><p>I finish to implement the Rabin's fingerprint and the diff with that. I optimized the compute to avoid any allocation of <code>Cstruct.t</code>. The result is exactly the same as git.</p></li>
<li><p>I switch the window implementation of the <em>packer</em> to the <code>lru</code> project from David. So, I add a dependency but it's ok. It's to follow, again, what git does and when git find a good delta, it promotes this delta in the window.</p></li>
<li><p>I seperate the serialization from the compute of the delta-ification. A good point is to let a new optimization and thread the compute of the delta-ification. This is what git does but need lot of work. So, for the moment, the algorithm is sequential but we can improve independantly than the serializer.</p></li>
<li><p>Implement topological sort to ensure we don't miss any diff for all git object.</p></li>
<li><p>Handle a diff with an object outside the PACK file.</p></li>
<li><p>Clean all</p></li>
</ul>
<h4 id="stephen-dolan">Stephen Dolan</h4>
<ul>
<li><p>Worked out how to do asynchronous syscalls by dynamically adjusting concurrency level with SCHED_IDLE threads. Should get us something like Haskell's safe foreign calls, but with much lower overhead.</p></li>
<li><p>Helped out with a pretty panicked TFP submission on the design of our effectful I/O (blocking syscalls, asynchronous effects, and the likes)</p></li>
</ul>
<h4 id="liang-wang-15">Liang Wang</h4>
<ul>
<li>The operators are re-designed last week with some newly added ones. The Ext module is also finished. I then released the version 0.2.4 on OPAM.</li>
<li>The work on neural network module continues, at the same time I add more functions into Owl's core.</li>
<li>I wrote two tutorials: one is on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Operators-and-Ext-Module">operators and ext module</a>; one is on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Algorithmic-Differentiation">algorithmic differentiation</a>.</li>
</ul>
<h3 id="week-17">Week 17</h3>
<h4 id="kc-sivaramakrishnan-8">KC Sivaramakrishnan</h4>
<ul>
<li>Merged ARM64 backend for multicore OCaml: https://github.com/ocamllabs/ocaml-multicore/pull/120</li>
<li>Working on generating tests that would exhibit weak memory behaviours on arm64.</li>
</ul>
<h4 id="david-allsopp-3">David Allsopp</h4>
<h2 id="opam-3">opam</h2>
<ul>
<li>PR#2912 merged</li>
<li>Discussions with Louis on file format features required for Windows</li>
<li>Improved mechanism for detecting undefined variables. Presently, you can use &quot;%{foo}%&quot; which expands to &quot;&quot; if foo is undefined. New proposal adds operator ? so that ?foo returns false if foo is not defined.</li>
<li>Allow variables in ternary operator in string expansion. Presently, you can use &quot;%{foo?bar:baz}%&quot;. New proposal requires strings to be single quoted and interpret the rest as variables. So far, so hacky, but unfortunately you can't use scoped variables e.g. what should &quot;%{foo?bar:path:lib}%&quot; mean? Shelved, as there are other workarounds for this.</li>
<li>Mechanism for initialising switch global variables by extending /etc/opamrc</li>
<li>Upstreaming PR#2915 to fix issues with debugging failed updates</li>
<li>Upstreaming PR#2923 to fix issues with renaming the test and doc variables in opam-repository</li>
<li>Upstreaming PR#2921 to implement the defined operator ? described above</li>
</ul>
<h4 id="qi-li-7">Qi Li</h4>
<ul>
<li>databox-irmin-store</li>
<li>write tests for kv/ts stores about r/w and websocket sub/unsub functionlities</li>
<li><p>dockerize this component and shrink the image size</p></li>
<li>databox-bridge</li>
<li><p>browse the repo ocaml-openflow investigating the possibilities of integration</p></li>
</ul>
<h4 id="takayuki-imada-20">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Started implementing a new networking scheme using Netmap on Solo5-ukvm.</li>
<li>The first phase would be replacing a network tap device by a Netmap port, and the second phase would be integration of ioeventfd to reduce the number of VMExits.</li>
<li>Had discussion with Martin(<span class="citation" data-cites="Docker">@Docker</span>) about the scheme above including how I can conduct the implementation.</li>
</ul>
<h4 id="romain-calascibetta-18">Romain Calascibetta</h4>
<h4 id="decompress-9">Decompress</h4>
<p>Nothing to do.</p>
<h4 id="blake2b-digestif-1">BLAKE2B / Digestif</h4>
<p>Nothing to do.</p>
<h3 id="farfadet-3">Farfadet</h3>
<p>Nothing to do.</p>
<h4 id="typebeat-3">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="sirodepac-ocaml-git-1">sirodepac / ocaml-git</h4>
<p>Previously, I told about the final implementation of serialization and try to find a good heuristic to make a small PACK file.</p>
<p>I have some goods results and now, I produce a PACK file with ~5MB when git produces ~2MB. So we are very close to git but not yet. At this time, it's complex to find a good way because git use an heuristic to compress the PACK file. I don't use the same because I can't reproduce exactly what git doing on the PACK file.</p>
<p>So, for this week, it's a deep introspection and a reverse engineering about what git do. And I'm focus on two problems:</p>
<ul>
<li><p>the sort algorithm. I follow the description of the sort in the git's documentation and, if I understand correctly, it's a lexicocagraphic compare between the kind of the object, the basename and, finally the size. I copy/paste the code from git to my project but my production of the sorted list object is different. This is a big problem because it's the main assumption to compress a PACK file</p></li>
<li><p>the compression method. To produce a 5MB pack file, I re-implemented the patience diff from the Jane Street library patience_diff (to avoid the dependency with Core). But git don't use the patience diff when it computes a PACK file. And I know why: because it's slow. Indeed, when I try to generate a PACK file, I maked a (patience) diff between 2 files by the line because if I try to diff by character, the algorithm is <strong>very</strong> slow. However, when I diff by line, the compression is not optimal for thow reason:</p></li>
<li><p>a diff by line is only relevant for a blob (which contains the file) but it's unoptimal for tree, commit and tag because these are not organized by line (but by LF character). I try to specialize the split and I produce a PACK file with 4.3MB but I can't do a better.</p></li>
<li><p>for a blob, sometimes, is not relevant to split by line because sometimes, only one character change between these files.</p></li>
</ul>
<p>Finally, git does not split by line to produce a diff. So, I looked what git do to compress and he uses a rabin's fingerprint to make an <code>index</code> and uses this <code>index</code> to make a diff with another file.</p>
<p>Now, I produce the same <code>index</code>, so I implemented the rabin's fingerprint and try to implement the delta-ification between an <code>index</code> and a file. But, just to notice, it's a clever solution for 2 reasons:</p>
<ul>
<li><p>we do a real compression like Decompress but with another algorithm (not the Lz77 algorithm - but I can use it to compress ...)</p></li>
<li><p>we can reuse the index for multiples files and it's what git do. When I computed some PACK files, I see the delta-ification for some file with one same file/<code>index</code>. It's to make the serialization more faster because, to make an <code>index</code> we need a time.</p></li>
</ul>
<p>So, I continue to implement the rabin's fingerprint and the compression with this - and continue to follow what git do.</p>
<p>Good news, git can recognize my PACK file with no problem (I fixed a bug about the hash). So we can considere than the project works but Thomas want a project which produces the same PACK file (in size terms). So, I continue to optimize <code>sirodepac</code>.</p>
<h4 id="stephen-dolan-1">Stephen Dolan</h4>
<p>Lots of figuring out the interactions between asynchronous interrupts (e.g. signals, cancellation) and the rest of the system. Stealing a lot from Haskell's well-designed async exceptions.</p>
<h4 id="liang-wang-16">Liang Wang</h4>
<ul>
<li>I have been working on the redesign of math operators in Owl. I have looked into multiple implementations in different languages such as numpy, julia, and R.</li>
<li>I have been improving the NLP module, include Corpus, TFIDF, and Vocabulary modules.</li>
</ul>
<h3 id="week-16">Week 16</h3>
<h4 id="david-allsopp-4">David Allsopp</h4>
<h2 id="opam-4">opam</h2>
<ul>
<li>Working through rebase of features in windows branch onto beta2</li>
<li>Upstreaming PR#2912 to fix a rollback problem with failed package installations</li>
</ul>
<h2 id="ocaml-3">OCaml</h2>
<ul>
<li>Git precommit hook and also GPR validation against our syntax rules (WIP - GPR#1148)</li>
<li>Various investigations for future work:</li>
<li>Tweaks to bring coloured output trivially to Windows 10 OCaml users</li>
<li>Windows 10 1703 Creators Update requires some tweaks for the Unix module - for 4.06</li>
</ul>
<h4 id="qi-li-8">Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>change the inner service model from multiple clients one queue to one client one queue</li>
<li><p>produce basic latency and queueing effect analysis plots</p></li>
<li>databox-irmin-store</li>
<li><p>implement basic kv/ts stores read/write functionalites</p></li>
</ul>
<h4 id="takayuki-imada-21">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>No updates in this week. (attended DockerCon17 @ Austin)</li>
</ul>
<h4 id="romain-calascibetta-19">Romain Calascibetta</h4>
<h4 id="decompress-10">Decompress</h4>
<p>Nothing to do.</p>
<h4 id="blake2b-digestif-2">BLAKE2B / Digestif</h4>
<p>Used in <code>sirodepac</code> with no bug. Update the interface (and add the <code>type t</code>) but not very much more work.</p>
<h4 id="farfadet-4">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-4">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="sirodepac-ocaml-git-2">sirodepac / ocaml-git</h4>
<p>2 good news. I finish to implement the serialization of the PACK file and use my patience diff to try to compress the PACK file. Now, the result is: we produce a PACK file of 13MB and before, the length was ~21MB. So we reduce the length by 2 times! But it's not the best, [git] produced a PACK file with length: 2MB. I will try to find why we are wrong and I think, it's about the patience diff. But we are in the good way and now, we just need to improve and optimize the serialization.</p>
<p>In other side, I optimized the deserialization. Now, when you want a Git object from a PACK file, you just need to allocate 4 buffers (2 to inflate and 2 to undelta-ified the git object).</p>
<p>This result is possible because:</p>
<ul>
<li><p>we have a non blocking interface so we can start at any position of the PACK without a complexe description of a context (the state)</p></li>
<li><p>we compute the PACK file as the way than [git]. Indeed, [git] does not open the PACK file but some part of the file. We do the same to avoid the OCaml limitation about the native integer (and compute a huge PACK file firstly) and limit the allocation of what is needed to get the object. So, we avoid an attack by allocation.</p></li>
<li><p>we externalize all big allocation from the decoder state. The state is pure and don't have any internal buffer inside. The user need to specify 2 buffers (to inflate the git object) and can decide the length of these buffers. Then, the decoder handles these buffers without any problem but the purpose of the state is: it stores only some integers! So, obvisouly, it is located in the minor heap (like Decompress), I just follow some advises from Jeremy Yallop about that.</p></li>
<li><p>The 2 other buffers is about the undelta-ification of a PACK object to a git object. We can know the length needed to store a git object. So we just try to find the max length needed to undelta-ified a PACK object firstly.</p></li>
</ul>
<p>Undelta-ified means take a git object, a hunk (which it's list containing a data or an offset and a length to copy from the base git object to the new git object) and try to apply the hunk with the base git object to produce a new git object.</p>
<p>Obviously, we can have a delta of a delta of ... a delta of a git object. So we need to follow the chain and get the max length of all base git object needed to undelta-ified the git object requested.</p>
<p>Then, we just need to use 2 buffers and flip one to other for each undelta-ification. At the end, one of these buffers contains the git object requested.</p>
<p>So, it's a good optimization.</p>
<p>Finally, my last work is a functorization of the hash function (like ocaml-git) and an application with <code>Digestif</code>. I write a documentation too about the decoder firstly but I think is useless.</p>
<p>The next job is to try to optimize the serialization and understand how git can produce a small PACK file. But I think, I have an idea about that.</p>
<h4 id="liang-wang-17">Liang Wang</h4>
<ul>
<li>I have been working on the nlp module in Owl. The nlp module aims to provide stronger supports to deal with large text corpus. With Owl's numerical functions, I hope people can build up topic model easily.</li>
<li>I have been studying latest ocaml-tensorflow binding, and other libraries for fast prototyping such as keras.io, to see what Owl can learn from them.</li>
</ul>
<h3 id="week-15">Week 15</h3>
<h4 id="kc-sivaramakrishnan-9">KC Sivaramakrishnan</h4>
<ul>
<li>Submitted a paper with Oleg Kiselyov on embedding eff programming language in OCaml to ML workshop post-proceedings. The draft of the paper is here: http://kcsrk.info/papers/caml-eff17.pdf.</li>
<li>Working on CPS translation of effect handlers with Sam Lindley, Daniel Hillestrom and Bob Atkey.</li>
<li>Working on a Dagstuhl proposal with Matija Pretnar and Tom Schrijvers.</li>
<li>Developing the multicore aarch64 backend.</li>
</ul>
<h4 id="david-allsopp-5">David Allsopp</h4>
<h2 id="misc">Misc</h2>
<ul>
<li>While working on something unrelated, found a possible exponential blow-up type-checking GADTs, but need to investigate further (using an older OCaml, so it might have been fixed)</li>
</ul>
<h2 id="ocaml-4">OCaml</h2>
<ul>
<li>Misc reviews and CI tweaks</li>
</ul>
<h4 id="takayuki-imada-22">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Learned how to write a user program with Netmap, and investigated vhost-net implementation detail.</li>
<li>Finished designing integration of Netmap into Solo5-ukvm. Decided to employ Netmap in the host user layer to reduce the integration cost. I found that using Netmap in the host kernel layer costs a lot for lack of Netmap APIs.</li>
</ul>
<h4 id="romain-calascibetta-20">Romain Calascibetta</h4>
<h4 id="decompress-11">Decompress</h4>
<p>I found a bug in Decompress about a far distance and the window. It's about the <code>blit</code> function and the <code>Inflate</code> algorithm (the good news is that the <code>Deflate</code> algorithm has no error). Indeed, when we have a distance we can have 3 cases:</p>
<ul>
<li>the first is when the content of the window overlap the result. That means: the byte is not set yet, but when we advance in the window to write the new byte (from a old byte in window), we set the futur byte in the window. So, the all pattern is available only at the end of the <code>blit</code>.</li>
</ul>
<p>In this case, it's why we can't use <code>memmove</code> but <code>memcpy</code>.</p>
<ul>
<li>the second is when it's a far distance. When we <code>blit</code>, may be we delete some bytes considered as a pattern and these bytes was not saved in the output. It's happen because the result overlap the content of the window. In this case, we need to write at the same time in the window and in the output.</li>
</ul>
<p>So, we create a function <code>blit2</code> and write from a <code>src</code> to 2 <code>dst</code> (in this case, the window and the output).</p>
<p>A good news is that, when I fixed this bug, I fixed another bug. Indeed, in the <code>Deflate</code> algorithm, I avoid a compute of a far pattern because, when I try to inflate the result, I had some errors. Now, because I fixed the <code>Inflate</code>, I don't have error with a far pattern.</p>
<p>So, I need to do a new release now. But not yet, if I find a new bug, I don't want to release all the time. So, when I will make the PR in <code>ocaml-git</code>, I will release Decompress.</p>
<h4 id="blake2b-digestif-3">BLAKE2B / Digestif</h4>
<p>Nothing to do but need to be released.</p>
<h4 id="farfadet-5">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-5">TypeBeat</h4>
<p>Merge some PR from <span class="citation" data-cites="seliopou">@seliopou</span>, need to be released but not very important.</p>
<h4 id="sirodepac-ocaml-github">sirodepac / ocaml-github</h4>
<p>So the serialization is done as the half. Indeed, we produce a PACK file with the IDX file and we can recompute these (so, it's a big check to see if all is ok). I add some check like the hash of the IDX file and the hash of the PACK file.</p>
<p>I took my patience diff algorithm to try to apply a delta. I implement the window (in an optimal way) and compute the diff between 2 git objects by the line - before, I computed by the character but it's very slow.</p>
<p>So some good news: * the heuristic about the sort of the git object works! Indeed, when I try to apply a delta in a git object with the previous computed git object, I have some good ratio. * The performance is not killed. I don't say, I'm faster than git but the compute take a average time to make the PACK file. * The deserialization of the serialization of a PACK file produce the same result, we lost nothing when we deserialize and when we serialize.</p>
<p>So, I will implement the Hunk thing now to write the delta applied in the PACK file and optimize the size of this file. But the core of the serialization is already done.</p>
<p>Then, I will do some bench and make a PR to ocaml-git and, it's done :) ! But need a time to do all correctly :p !</p>
<h4 id="ps">PS</h4>
<p>I'm in Cambodia, I miss one day this week (the bus) but I will work this week end. it's the cambodia new year so all people come to home.</p>
<h4 id="gemma-gordon">Gemma Gordon</h4>
<ul>
<li>Infrastructure quotes and specs</li>
<li>Attended the PowerSwitch Symposium - notes/blog post to follow</li>
<li>Planning Q3 activities and events</li>
</ul>
<h4 id="liang-wang-18">Liang Wang</h4>
<ul>
<li>I updated the slicing function in Owl. It is more flexible than the previous version but can still be improved.</li>
<li>I released Owl.0.2.3. The current focus of the development is on neural network and nlp modules.</li>
<li>I did some experiments for actor system, this will continue and will be my focus in the following weeks.</li>
</ul>
<h3 id="week-14">Week 14</h3>
<h4 id="david-allsopp-6">David Allsopp</h4>
<h2 id="ocaml-5">OCaml</h2>
<ul>
<li>Wrote and used test harness for FlexDLL testing in 4.04.1/4.05.1</li>
<li>Sorted out Cygwin issues with CRLF following on from February update of grep/awk/sed (GPR#1140)</li>
</ul>
<h4 id="takayuki-imada-23">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Finished completing the Pros/Cons table, then I decided to employ Netmap rather than DPDK as a network acceleration scheme as DPDK usually requires a busy loop-based packet handling.</li>
<li>Desingning basic implementation to integrate Netmap into Solo5-ukvm. I will introduce a vhost-net like scheme to reduce the number of VMExit/Entry.</li>
</ul>
<h4 id="romain-calascibetta-21">Romain Calascibetta</h4>
<h4 id="decompress-12">Decompress</h4>
<p>I fixed the bug in Canopy about Decompress. As I said, the problem is come from the implementation of <code>inflator.ml</code>. It's a good new, that means than Decompress has no discovery bug.</p>
<p>This assumption is come from <code>sirodepac</code>. Indeed, I use a lot Decompress to deserialize/serialize the PACK file and I did not find a bug.</p>
<p>I created some issues in Decompress to show what is my goal for the next release.</p>
<h4 id="blake2b-digestif-4">BLAKE2B / Digestif</h4>
<p>Nothing to do.</p>
<h4 id="farfadet-6">Farfadet</h4>
<p>I released the first version of Farfadet (after the release of Faraday). I looked the implementation provided by <span class="citation" data-cites="Drup">@Drup</span> and I choose this one. This implementation is more confortable for any futur extension (we don't need to create a new GADT constructor to add a new writer).</p>
<p>So, I provided a good example, a serializer of JSON. It's just a example, I don't about the standard but the usability of Farfadet is very powerful!</p>
<p><span class="citation" data-cites="Drup">@Drup</span> told me to add a PPX then, I will think but not yet.</p>
<p>And, I provided a good documentation (I think). So, it's usable now.</p>
<h4 id="typebeat-6">TypeBeat</h4>
<p>Good news, <span class="citation" data-cites="seliopou">@seliopou</span> improved a lot <code>TypeBeat</code> and remove redundant code (came from Mr. MIME). I created a suit test. So, all is ok. I will do a new release in few weeks.</p>
<p>I improved the documentation and nothing else.</p>
<p>I asked to <span class="citation" data-cites="dbuenzli">@dbuenzli</span> if he wants a RFC822 date parser but I said no (and I know why :D). So, TypeBeat is finished.</p>
<h4 id="sirodepac-ocaml-git-3">sirodepac / ocaml-git</h4>
<p>After the release of Farfadet, I decide to use it in <code>sirodepac</code>. Obviously, it's not a mandatory part of the serializer/deserializer and, when I finish, we will talk about these dependancies.</p>
<p>The point is the deserialization/serialization of a git object is provided by Angstrom and Faraday/Farfadet library. It's an easiest way for me to maintain the serialization/deserialization, the code is much cleaner and we respect, again, the non-blocking assumption.</p>
<p>However, as I said, it's not mandatory to use it. In fact, I don't use the non-blocking assumption for the git object in my algorithm - I can but, it's not necessary (and may be not good about the performance).</p>
<p>I create a PoC of a function to get directly the git object without any compute with delta thing. So, you have directly the git object. I need to improve this function again (about the allocation) but it seems to be good as an API <em>easy-to-use</em>. Indeed, you just need the hash and some temp buffer to make the git object - but internnally, I create a big buffer and I think it's not mandatory so I will delete that and improve the performance (and the allocation).</p>
<p>I start the serialization. After the talk with <span class="citation" data-cites="samoth">@samoth</span>, I have a global and precise view of what we need to do. I implemented the <em>Window</em> other thing (not like my precedent report) and start the serialization without the delta thing for this moment.</p>
<p>But I sorted correctly the collection of the git object and compress correctly the git object with Decompress. I just need to know the politic treatment about the level of the compression. Indeed, I saw the git object was not compressed in the uniq and same way, it's depends on the kind of the git object and the size may be. I will look in <code>git</code> how to do this choice.</p>
<h4 id="ps-1">PS</h4>
<p>This week, I took a plane to Ho Chi Minh in Vietnam to go then to Cambodia (as you know), so I did not work this Thuesday (a little but not a lot, I was so tired by the plane). It's why I was not so productive this week. Voilà!</p>
<h4 id="liang-wang-19">Liang Wang</h4>
<ul>
<li>I have been working on the neural network module in Owl. Currently, I am focusing on various gradient descendent and learning rate algorithms. AD turns out to be really powerful in simplifying the design of neural network module.</li>
<li>For barrier control in actor system, I am still working on the experiments. The results reported by Ben seem really promising.</li>
</ul>
<h3 id="week-13">Week 13</h3>
<h4 id="gabriel-de-perthuis">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Insert: Fix a spill/split interaction</li>
<li>New LRU peek API</li>
</ul>
<h4 id="david-allsopp-7">David Allsopp</h4>
<h2 id="ocaml-6">OCaml</h2>
<ul>
<li>Lost quite a bit of time chasing down a non-existent platform bug :o( Issue was in fact a different OCaml being (incorrectly) picked up by the testsuite</li>
<li>More test cases for 4.04.1/4.05.0</li>
</ul>
<h4 id="qi-li-9">Qi Li</h4>
<ul>
<li>made some PRs to upstream macaroons libraries</li>
<li>merged in the websocket endpoint to the service</li>
</ul>
<h4 id="takayuki-imada-24">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>No advance this week (due to a private trip)</li>
</ul>
<h4 id="romain-calascibetta-22">Romain Calascibetta</h4>
<h4 id="decompress-13">Decompress</h4>
<p>Polish the documentation.</p>
<h4 id="blake2b-digestif-5">BLAKE2B / Digestif</h4>
<p>I just fixed the problem with <code>Bytes.t</code> in <code>Digestif</code>. So, I let the projet in my side but I keep in my head to implement the hashes functions in pure OCaml.</p>
<h4 id="sirodepac-ocaml-git-4">sirodepac / ocaml-git</h4>
<p>I move the internal structure to <code>Cstruct.t</code> to move my work in <code>ocaml-git</code> easily. The patience diff worked (without any other dependancies). I need to optimize a part of the algorithm (about the implementation of Dequeue from Simon Cruanes) but we can use it to serialize the PACK file.</p>
<p>Then, I looked a long time in <code>git</code> to understand the serialization. I talked with <span class="citation" data-cites="samoth">@samoth</span> about some informations and now all was clear to implement the serialization. My question was about the order of the git object before the serialization. Indeed, git has an heuristic to order the git object inside the PACK file and believe than this order is the best to apply a diff between the git objects.</p>
<p><code>sirodepac</code> (and <code>ocaml-git</code>) will follow this heuristic obviously.</p>
<p>Another good point was: I fixed the big bug about the limitation of OCaml for the huge PACK file. It's a complex point because it's about the architecture (32 / 64 bits) and the limitation of the native integer in the OCaml's runtime. I followed the implementation in <code>git</code> and it works! The solution is to map only a limited area of the PACK file, save this area as a <em>Window</em> and compute the object. If the requested object was not available in the current, we create a new <em>Window</em> and <em>map</em> a new area of the PACK file (and, obviously, this area contains the requested object).</p>
<p>Then, we keep a fixed-size bucket of <em>Window</em>s (that means, if we need a new window and the bucket is full, we will remove the oldest window) and we can compute any git object without any limitation!</p>
<p>So all continue to work and I will move my implemenation of the serialization of the git object to <code>Faraday</code> (because <span class="citation" data-cites="seliopou">@seliopou</span> will do a release).</p>
<h4 id="farfadet-7">Farfadet</h4>
<p>I will do a release of <code>Faradet</code> and check the PR of <span class="citation" data-cites="Drup">@Drup</span>.</p>
<h4 id="mr.-mime">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-7">TypeBeat</h4>
<p>So, it's new library to respond about <span class="citation" data-cites="dsheet">@dsheet</span> and a problem in <code>cohttp</code>. TypeBeat is a ligth library to parse the value of the <code>Content-Type</code>. This project was just a part of Mr. MIME but with the <code>Angstrom</code> dependancy.</p>
<p>However, I can't use <code>TypeBeat</code> in Mr. MIME. In fact, I need to know the implementation of the type <code>Angstrom.t</code> to do some mandatory optimisations.</p>
<p>I released the library, so I let <span class="citation" data-cites="rgrinberg">@rgrinberg</span> or <span class="citation" data-cites="dsheet">@dsheet</span> to use it in <code>cohttp</code>. I don't have a time to insert <code>TypeBeat</code> in <code>cohttp</code>.</p>
<p>Voilà!</p>
<h4 id="liang-wang-20">Liang Wang</h4>
<ul>
<li>I made an experimental module called <a href="https://github.com/ryanrhymes/owl/tree/master/lib/ext">Owl_ext</a> which allows interoperation of different number types. This should make analytical app easier to write and the code should be more concise. I finished the first version and here is an <a href="https://gist.github.com/ryanrhymes/f9cce1afcd06a5f4683aae45be01bdbe">example</a>. <strong>Please do let me know if you have any comments on the design.</strong></li>
<li>I made several c functions in Owl to cast bigarray between different number types. These functions serve Owl_ext module for converting number types whenever necessary during interoperation.</li>
<li>I start building neural network module atop of current Owl's functionality and AD module. I think Owl's future development should be motivated by the realistic applications. I will start looking into various application scenarios and neural network seems a good starting point.</li>
<li>I start working on the actor system and barrier control again, pushing forward the experiment to get more results out.</li>
</ul>
<h3 id="week-12">Week 12</h3>
<h4 id="kc-sivaramakrishnan-10">KC Sivaramakrishnan</h4>
<ul>
<li>Developed a CPS translation for L := λ calculus + effect handlers.</li>
<li>Developed a CEK machine for the L.</li>
<li>Working on a type inference for L.</li>
</ul>
<h4 id="david-allsopp-8">David Allsopp</h4>
<p>** OCaml ** - Windows testing of 4.04.1/4.05.0 revealed a few issues with the CI (GPR#1115, GPR#1116) - AppVeyor testing is sooo slow - GPR#1116 in particular took ages to prepare waiting for CI results! - Supporting build system changes across 4.04 and 4.05 is also proving slow work (GPR#1101 / GPR#1023) but at least that's only for this release cycle!</p>
<h4 id="qi-li-10">Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>bug fixes and working arounds to make the demo work for the launch, mainly tied to macaroons-related stuff</li>
<li>disabled the tests on dockerhub autobuild, refer to <a href="https://github.com/me-box/databox-export-service/pull/14">PR</a></li>
<li><p>NB: impression was that the image from autobuild could be corrupted? <em>Output like: Illegal Instruction (core dumped), through gdb found that the binaries tried to disable address space randomization?</em></p></li>
<li>databox-bridge:</li>
<li>such unstable that could make it for the launch event, will keep persuing this end later</li>
<li>should figure out the right timing and order of network creating and connection</li>
<li><p>should provide better failure control within inner libs</p></li>
</ul>
<h4 id="takayuki-imada-25">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Conducted some experiments to check how long time the MirageOS network stack spends for packet processing. Found that the IP packet frame allocation occupies 30-35% of the total processing time in MirageOS OCaml part, and that the VMExit/Entry cost cannot be negligible.</li>
<li>I will try to reduce the former bottleneck by employing an additional upper layer on Netmap or DPDK, and the latter bottleneck by reduction of context switching.</li>
<li>Still filling out a Pros/Cons table on network acceleration schemes.</li>
</ul>
<h4 id="romain-calascibetta-23">Romain Calascibetta</h4>
<h4 id="decompress-14">Decompress</h4>
<p>Nothing to do. <span class="citation" data-cites="engil">@engil</span> found a bug in Canopy but I think, it's not about Decompress. Indeed, I use Decompress in <code>sirodepac</code> and all is ok. But I will inspect what is wrong - because, may be it's <code>ocaml-git</code>.</p>
<h4 id="blake2b-digestif-6">BLAKE2B / Digestif</h4>
<p>I continue to polish this package. I try to provide an interface with the <code>Bytes.t</code> modules and break the <em>hard</em> dependency with <code>cstruct</code>. But, in fact, the end-user can use <code>cstruct</code> if he wants (<code>cstruct</code> is a <code>bigstring</code> and by default, the API provide a <code>bigstring</code> compute). Another point is to separate the pure implementation of the hash function in OCaml (in Digestif library) and a C implementation with an OCaml interface (in Rakia library). So, Digestif can be used in Mirage, JavaScript and OCaml - but I need to work a long time in this project.</p>
<p>I just finish to create a generic test suite between <code>bigstring</code> and <code>bytes</code> and I need to fix the problem with the <code>bytes</code> in the Rakia library. Then, I will re-implement the hash function in pure OCaml.</p>
<h4 id="sirodepac-ocaml-git-5">sirodepac / ocaml-git</h4>
<p>I finished the serialization of the IDX file. I talked with <span class="citation" data-cites="samoth">@samoth</span> about that and all works fine. To test, I deserialize an IDX file, serialize the IDX file, and deserialize the output and compare the result. I use a radix tree to store the IDX file and I have a lazy implemenation (like <code>ocaml-git</code>).</p>
<p>I try to implement the patience diff (without <code>core_kernel</code> package) to try to serialize the PACK file. Indeed, inside the PACK file, all git object was compressed by Decompress and by a diff function. So, I already have a PoC in <code>sirodepac</code>. I don't know if I need to create a new package for this thing but the good thing is that we have no dependencies. When I check my implementation, I will implementation the core of the serialization of the PACK file.</p>
<h4 id="farfadet-8">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="mr.-mime-1">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="gemma-gordon-1">Gemma Gordon</h4>
<ul>
<li>Databox launch on the Friday</li>
<li>Paperwork</li>
<li>Preparing contracts</li>
<li>Monthly and quarterly updates</li>
<li>Moving more content over to ocamllabs.io</li>
<li>Collating MirageOS hack retreat trip reports</li>
<li>Starting proposals for interns this summer</li>
</ul>
<h4 id="liang-wang-21">Liang Wang</h4>
<ul>
<li>The memory issue of Owl was completely addressed. Now the MNIST example only consumes about 400MB memory and GC works fine. AD module can now be used in practice.</li>
<li>The <code>change_layout</code> function was completely removed from Owl since Owl does not depend on Lacaml any longer. All the vectorised math functions were reimplemented in c last week.</li>
<li>The module structure was also significantly changed, now different number types are wrapped into corresponding modules (S, D, C, Z, Generic). This makes the API even simpler in programming.</li>
<li>I published a new release Owl 0.2.2 this Friday. The tutorials are also updated to be consistent with the new changes in Owl, also added AD stuff in readme.</li>
</ul>
<h3 id="week-11">Week 11</h3>
<h4 id="david-allsopp-9">David Allsopp</h4>
<p>** OPAM ** - Completed rebase and update of windows-build branch on to master. OPAM compiles, but the good stuff still needs cherry-picking/updating!</p>
<p>** OCaml ** - Finally set-up a proper test-bed for parallel testing Windows ports - Started Visual Studio 2017 testing for OCaml</p>
<h4 id="qi-li-11">Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>implemented websocket version of the endpoint, kept in a seperate branch for now: <a href="https://github.com/me-box/databox-export-service/tree/ws">ws</a></li>
<li><p>refactored bits of the test part and the export logic part, to ease the integration of ws endpoint</p></li>
<li>databox-bridge:</li>
<li>finished the first implementation, and merged</li>
<li><p>fixed some bugs, opened PRs to opium and upstream js libraries</p></li>
</ul>
<h4 id="takayuki-imada-26">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Started investigation of the current impelementation of Intel DPDK and Netmap to understand what can be a point to be considered.</li>
<li>Findings:
<ul>
<li>DPDK does packet handling in the user space whereas Netmap does it in the kernel layer</li>
<li>DPDK uses busy loop polling for packet arrival detection whereas Netmap uses a NAPI-like scheme (=mix of busy loop polling and interrupts)</li>
<li>Both DPDK and Netmap require a virtualized PCI device and virtualized interrupts for a virtual machine when we try to use the currently available features for virtual machines. However, Solo5-ukvm currently does not have the required functions. So they will ba a challenging point I must tackle.</li>
</ul></li>
<li>learned the current behavior of vhost-net in handling network packets, found that eventfd, irqfd and ioeventfd are used to realize in-kernel network packet processing in vhost-net.</li>
<li>Started creating a pros/cons table of DPDK and Netmap to check i) how many gaps they have and ii) how large the gaps are when I try to integrate them into MirageOS.</li>
</ul>
<h4 id="romain-calascibetta-24">Romain Calascibetta</h4>
<h4 id="decompress-15">Decompress</h4>
<p>I fix the distribution of Decompress noticed by <span class="citation" data-cites="hannes">@hannes</span>.</p>
<h4 id="blake2b-digestif-7">BLAKE2B / Digestif</h4>
<p>I just finish the implementation of BLAKE2B in C. I did not received yet a response of David about <code>nocrypto</code> and where is the best place to find the implementation of BLAKE2B (inside <code>nocrypto</code>, in a new library and if we choose this case, may be it's better to extract the Hash function of <code>nocrypto</code> in the new library).</p>
<p>So, the implementation works. I did not do any benchmark but may be it's good to put this thing in my TODO. May be, if I have a time, I will implement the same hash but in pure OCaml (to compile to JavaScript) and let the user to choose the C stub or the OCaml code.</p>
<p>And, in my TODO, I keep the SSE implementation.</p>
<p>If I have no response of David for the next month, I will release <code>Digestif</code> as a common library for the hash function. I will keep obsiously the Copyright Header inside <code>Digestif</code> for David (and Vincent Hanquez) for some parts of the code. But, for me, this project can be a redundant project. I prefer to discuss before but ...</p>
<h4 id="sirodepac-ocaml-git-6">sirodepac / ocaml-git</h4>
<p>I put an exhaustive explanation of a the previous big problem inside <code>sirodepac</code>/<code>ocaml-git</code> about the limitation of OCaml for the mapped file and how to fix that and how <code>git</code> fix this problem. But ... the comment is in french - it's hard for me to explain that in english. The most important point is to keep in my mind the problem for a long time (because, I think, if we want to fix that, we need to implement a complexe cache system).</p>
<p>I fix the implementation about the endianess too.</p>
<p>And I start the serialization of the IDX file. I will create a test between the encoder and the decoder to check if my implementation is good.</p>
<p>The next goal is to implement a patience diff and look how <code>git</code> produce (in the detail) a PACK file.</p>
<h4 id="farfadet-9">Farfadet</h4>
<p><span class="citation" data-cites="Drup">@Drup</span> looked the code and developped a new (seems good) API for Farfadet. I wait the release of <span class="citation" data-cites="seliopou">@seliopou</span> to look the code of <span class="citation" data-cites="Drup">@Drup</span> and decide to merge or not - but I think I will merge. In the same moment, I will write the documentation as KC expected.</p>
<p>So same as the previous week.</p>
<h4 id="mr.-mime-2">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="liang-wang-22">Liang Wang</h4>
<ul>
<li>I had been dealing with high memory consumption issue of AD module in Owl last week. In the end, the issue was identified: calling <code>Bigarray.Genarray.change_layout</code> function will cause OCaml unable to free the memory allocated for the variable.</li>
<li><code>change_layout</code> functions have been called a lot in order to pass variables to Lacaml. Because of the aforementioned issue, I had to remove all these calls. In the end, I rewrote many maths function locally in <code>c</code> so Owl does not depend on Lacaml any longer.</li>
</ul>
<h3 id="week-10">Week 10</h3>
<h4 id="kc-sivaramakrishnan-11">KC Sivaramakrishnan</h4>
<p>I've been lazy and not writing the report every week. Here are the updates from the last 2 weeks:</p>
<ul>
<li>Submitted the following PRs to Irmin merge functions
<ul>
<li>https://github.com/mirage/irmin/pull/422</li>
<li>https://github.com/mirage/irmin/pull/420</li>
</ul></li>
<li>Released mergeable-vector library: https://github.com/kayceesrk/mergeable-vector</li>
<li>Compiled Multicore OCaml programs to wasm which runs in Firefox!
<ul>
<li>https://github.com/kayceesrk/ocamlrun-wasm/tree/multicore</li>
<li>https://pbs.twimg.com/media/C6ai77CXQAYJAhI.jpg:large</li>
</ul></li>
<li>Wrote a blog post on topkg + carcass: kcsrk.info/ocaml/opam/topkg/carcass/2017/03/05/building-and-publishing-an-OCaml-package/</li>
<li>Submitted a paper on mergeable types</li>
<li>Fixed my homepage for moving from redcarpet to kramdown.</li>
</ul>
<h4 id="gabriel-de-perthuis-1">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Expanding tests</li>
<li>Bug fixing</li>
<li>Refactoring</li>
<li>Collecting and logging statistics</li>
<li>NeedsFlush signal</li>
<li>LRU pull request</li>
</ul>
<h4 id="david-allsopp-10">David Allsopp</h4>
<p>** OCaml 4.05 ** - Fixed the FlexDLL bootstrap allowing ocamlmklib to work correctly (GPR#1023). The fix is targeted for 4.04.1 and required a separate version for 4.05/trunk owing to the (very welcome) build system alterations. Lots of test cases... - Spent arguably too much time working on a test-case for the Unix.stat bug in GPR#1057. Interesting foray into kernel trickery on Windows (polite way of referring to disgusting code injection and re-writing tricks...)</p>
<h4 id="qi-li-12">Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>implemented a long-polling version endpoint, temporarily with the route <code>/lp/export</code></li>
<li><p>added a test case against this endpoint</p></li>
<li>databox-bridge:</li>
<li>decided to try to implement at first with docker bridge, equivalent to use <code>docker network create ...</code> and <code>docker network connect ...</code> to connect pairs that need communications</li>
<li>implemented this <a href="https://github.com/me-box/databox/pull/50">link</a>, waiting for more polishing and testing before merged</li>
<li><p>catched up with mirage3, cause later there should be a stand-alone bridge component rather that a patch in databox's container manager</p></li>
</ul>
<h4 id="takayuki-imada-27">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Found that the low performance under Solo5-ukvm was caused by a fault in my source code, and confirmed that the UDP iperf performance was 40MB/sec.</li>
<li>However, the receiver side can achieve 70MB/sec. This indicates that a current bottlenec is in the sender side.</li>
<li>Further investigation in the virtualization layer showed that the virtualization layer is a main overhead, and GC handling as shown in the previous experiments is not a performance impact.</li>
<li>I will continue to design new networking scheme wich consideration of the current Solo5-ukvm by the end of this month.</li>
</ul>
<h4 id="romain-calascibetta-25">Romain Calascibetta</h4>
<h4 id="decompress-16">Decompress</h4>
<p>Decompress is released in version 0.5. So, it seems work (no issue for this moment). I have a bug about the opam file and hannes just fixed that. I will report this change in opam-repository.</p>
<p>Finally, I decided to let 6 months to get the new release (1.0) of Decompress.</p>
<h4 id="sirodepacocaml-git"><code>sirodepac</code>/<code>ocaml-git</code></h4>
<p>I started the implementation of the BLAKE2B hash function. I send a message to david to know if it's the best to integrate this hash function inside nocrypto or outside (and if the best is to create a new library, may be the best is to locate all common hash function inside a new library).</p>
<p>So, fortunately, Eyyub (a friend) created a projet inside the <code>oklm-wsh</code> repository to aggregate the common hash function (like SHA1, SHA256, etc.). So, I will reuse this project to provide the BLAKE2B hash function.</p>
<p>For this moment, I look the reference implementation of BLAKE2B and the SSE implementation (to compute the hash fastly). So, I think, I can do a release this next week.</p>
<p>Nothing else about <code>ocaml-git</code>. I met in the hackthon a manager of a dev team for a git project in go. So I explained what is git and why is the best to store a data, a commercial job :p .</p>
<h4 id="farfadet-10">Farfadet</h4>
<p>So, I created the new repository <code>Farfadet</code>. I spoke with Spiros about the API and we fixed together the API.</p>
<p>Another good news is from <span class="citation" data-cites="Drup">@Drup</span>. In fact, I improved the API after my release and it seems good. So, I need to read the code and write the documentation now (and provide a good example - asked by KC) but I'm focus on the BLAKE2B hash now.</p>
<h4 id="mr.-mime-3">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="gemma-gordon-2">Gemma Gordon</h4>
<ul>
<li>Finished the Maintainerati blog post: http://reynard.io/2017/03/07/MaintaineratiWontFix.html</li>
<li>Planning for Databox launch</li>
<li>Paperwork</li>
<li>Proofreading ppx updates from Fred: https://github.com/let-def/ocaml-migrate-parsetree/blob/master/MANUAL.md</li>
<li>Moving more content over to ocamllabs.io</li>
<li>Following MirageOS hack retreat updates on Twitter: http://ocamllabs.io/events/2017/03/06/MirageHackUpdates.html</li>
</ul>
<h4 id="stephen-dolan-2">Stephen Dolan</h4>
<p>Many multicore yaks now bald.</p>
<ul>
<li>Atomics module exists! (or part thereof)</li>
<li>Got the multicore test suite running properly, and integrated with Travis. Fixed a bunch of issues with the testsuite and the runtime.</li>
<li>Added GC stats in multicore (functions in <code>Gc</code> now work, and account properly for every word of the shared major heap). Found a bug in trunk OCaml while doing this, now fixed in trunk and 4.05.</li>
<li>Fixed heap verification in multicore (in particular, debug mode now checks at runtime that the GC stats aren't lies)</li>
<li>Got some pull requests to trunk OCaml merged (#1088, #1069, #973)</li>
</ul>
<h4 id="liang-wang-23">Liang Wang</h4>
<ul>
<li>The GSL dependency has been removed from the core components in Owl.</li>
<li>Current modules (partly) rely on GSL are Maths, Stats, FFT. I am currently wrapping up Cephes to replace GSL-based modules.</li>
<li>I spend some time in refining the AD interface. The <a href="https://gist.github.com/ryanrhymes/582e1d1a5f3cd47a6b96fe5bed4914e8">code here</a> show how to build a trivial neural network with AD (from scratch). Comments are welcome.</li>
<li>However, I noticed the memory consumption grows really fast in the previous naive neural network experiment. The allocated memory did not seem to be correctly released after usage. I still try to identify the (possible) memory leak issue. Let me know if anyone has any idea about this.</li>
</ul>
<h3 id="week-9">Week 9</h3>
<h4 id="gabriel-de-perthuis-2">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Refactoring</li>
<li>Child node splitting</li>
<li>Bug fixing</li>
<li>Functoria pull request to switch the block implementation</li>
</ul>
<h4 id="david-allsopp-11">David Allsopp</h4>
<p><em>Ill for most of the week :( </em></p>
<p>** OCaml Labs ** - Preliminary discussions with <span class="citation" data-cites="avsm">@avsm</span>, <span class="citation" data-cites="gemmag">@gemmag</span> on moving the CI into the lab.</p>
<p>** OCaml 4.05 ** - Cygwin fork issue fixed! Patch accepted upstream to the Cygwin DLL. Issue was that when DLLs are dlopen'd using FlexDLL, the dependencies between them are not known to Cygwin/Windows. Cygwin contained a dependency-based topological sort which was unstable for DLLs with no dependencies: the effect was that even calls to fork would work (as the list is reversed each time). DLL rebasing meant that the problem wasn't apparent on Cygwin64, but with correctly based DLLs, the same problem occurred. OCaml docs will be updated once the new Cygwin DLL has been released to note that the minimum version.</p>
<h4 id="qi-li-13">Qi Li</h4>
<ul>
<li><a href="https://github.com/me-box/databox-export-service.git">databox-export-service</a> (<em>we renamed the repo from 'databox-bridge' to this</em>)</li>
<li>Dockerised this repo, added docker hub autobuild, added opam file to use opam to install the service</li>
<li>Supported https by wrapping <code>cert</code> and <code>key</code> environment varialbles into local files, and passing them to the <code>opium</code> interface</li>
<li>Refactored <a href="../blob/master/test/test.ml">test.ml</a> to make it easier to write more tests from client side rather the monolithic single test before this</li>
<li>Added some new tests to test against scenarios where we would have invalide id or macaroons etc.</li>
<li><p>Tried out some new libraries to make days easier: <code>depyt</code>, <code>rresult</code>, <code>bos</code> etc.</p></li>
<li>databox-bridge:</li>
<li>Discussed the functionalities and interactions with other components, should be able to see the very first version next week</li>
<li><p>Step one: assuming bridge has connected to the right network and so do other components, it should recognize DNS requests, give right responses and then forwarding ethernet packets to the right interfaces</p></li>
</ul>
<p><em>Only realized forgot to add the weekly 8 while in the middle of this week, so this log actually covered work done for the past two weeks</em></p>
<h4 id="takayuki-imada-28">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Attended MirageOS Hack Retreat on 1st-2nd March, and mainly had discussions on Solo5 with Martin.</li>
<li>Learned the current implementation philosophy of Solo5 and found that it focus on only simplicity and its functionality, not on performance.</li>
<li>Conducted iperf experiments under Solo5-ukvm, and confirmed that longer waiting periods in the sender side actually affets the iperf throughput performance. (Only 7MB/sec throughput due to the waiting periods though I confirmed the receiver side can achieve 70MB/sec throughput)</li>
<li>I will start designing new networking scheme wich consideration of the current Solo5-ukvm.</li>
</ul>
<h4 id="romain-calascibetta-26">Romain Calascibetta</h4>
<h4 id="decompress-17">Decompress</h4>
<p>I fix a bug about the window bits. Indeed, the zlib format only allow a window bits between 8 and 15. Then, I launched a test about that and we have a big bug, I put this in my TODO. In fact, when we work on a zlib flow with a specific window bits (&lt;&gt; 15), the inflater (the decompression) does not works with my deflater (the compression). But (and it's why it's very weird), <code>camlzip</code> works with my input - so the bug is only available for the inflater and we need to keep the size of the window to <code>1 &lt;&lt; 15</code> bytes and not to the <code>1 &lt;&lt; window_bits</code> (with <code>window_bits</code> is a value from the zlib header). So it's about the window inside the inflater.</p>
<p>Another weird things is with this change, the inflate for a flat flow (no compression, so no distance, so no need to use the window) does not work. So, yes, it's w.t.f and I need to focus on that one big time - because the bug is very deep.</p>
<p>But, I did a release of Decompress now. It's stable and I integrate this change in Canopy!</p>
<p>I test by my hand the window size/level/flush method with my alcotest to avoid any write in any file. So I launched like 35 000 tests with Decompress and compare with camlzip and all is ok. I think Decompress is robust :) .</p>
<h4 id="ocaml-gitsirodepac"><code>ocaml-git</code>/<code>sirodepac</code></h4>
<p>I find an another serious bug about <code>ocaml-git</code> and <code>sirodepac</code>. It's about the size of the pack-file. In fact, the offset delivered by the IDX file can be stored inside a int64 variable. That means the offset can be huge and can be upper than what OCaml can store inside a bigstring/string.</p>
<p>I found this problem in <code>cohttp</code> when it's possible to send a huge file by the HTTP protocol (like a video of Game Of Thrones). So, by this constraint, it's mandatory (if we want to compute all PACK file) to work on a flow of chunk of a PACK file - because the PACK file can be (easily) bigger than [Sys.max_string_length] and in this case, we need to compute the PACK to some chunk of [Sys.max_string_length].</p>
<p>But <code>sirodepac</code> handles that! When we compute a PACK file, we can compute this by some chunk. However, it's about the delta-fied object. In this case, we need to compute entirely the PACK file because the offset can be absolute (if the hunks refer to a hash) but in the main case, the offset is relative and we need to know if this relative offset can't be bigger than [Sys.max_string_length].</p>
<p>It's a complexe problem and I will discuss in the hackaton about that with Thomas to know what is the best way to compute an huge PACK file.</p>
<p>About the Merkle tree, I don't find a good case to use that so ... I go away from that.</p>
<p>About <code>ocaml-d3</code>, no time.</p>
<p>I fix the bug with SHA1 and I verify my implementation with the encoder/decoder. All is ok and I test <code>sirodepac</code> with a big PACK file from linux. That means the decoder and the encoder are good - we produce a good output from a good input and the SHA produced is correct, another thing, the offset of the SHA1 (from the IDX file) correspond to the offset of my parser. So, my program is reliable :) !</p>
<p>I will retake an old project, <code>Digestif</code> to implement the digest function for the new Hash of <code>git</code>. I spoke with Thomas about that and we find a mail to explain what happens for <code>git</code> after we can break the SHA1 and the new hash is BLAKE2b. So, for the hackathon, I will implement that. I spoke with hannes to know if it's cool to insert this new hash in Nocrypto but we think it's a bad idea (and, obviously, I don't find any BLAKE2b implementation in OCaml).</p>
<h4 id="farfadet-11">Farfadet</h4>
<p>I spoke with Seliopou and we fixed somethings in <code>Farfadet</code>. It's an high level interface of <code>Faraday</code>. So we decided to create a new repository about that in top of <code>Faraday</code>.</p>
<p>You can look the project at: https://github.com/oklm-wsh/Farfadet</p>
<h4 id="mr.-mime-4">Mr. MIME</h4>
<p>Nothing about that. I spoke with rgrinberg about the interface and I keep all things of my TODO.</p>
<h4 id="gemma-gordon-3">Gemma Gordon</h4>
<ul>
<li>Moving a lot of information over from ocaml.io to ocamllabs.io - taking a long time</li>
<li>Still working on maintainerati blog draft...</li>
</ul>
<h4 id="liang-wang-24">Liang Wang</h4>
<ul>
<li>We finalised the paper on privacy-preserving model training paper and submitted to PoPETs.</li>
<li>I worked with Jianxin to installed Owl on Raspberry PI and did some topic modelling experiment. There is an ARM-based docker image for Owl now.</li>
<li>I spent a couple of days in studying the software licensing stuff and made a new plan for Owl development. I will gradually remove the dependency on GSL to make sure Owl will remain MIT licence.</li>
<li>I start building an extension atop of Owl so that different types of math objects (scalar, matrix, ndarray) can interoperate.</li>
</ul>
<h3 id="week-8">Week 8</h3>
<h4 id="gabriel-de-perthuis-3">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Log spilling</li>
<li>Move testing to ramdisks</li>
</ul>
<h4 id="david-allsopp-12">David Allsopp</h4>
<p>** OCaml 4.05 ** - Cygwin-32 fork issue ongoing - identified that the problem is DLL load order, but not yet clear why this only affects Cygwin-32 or what the fix should be. - OCaml Developers' Meeting - a number of old GPRs discussed and triaged. Plea from Xavier that each dev triage, and preferably resolve, 5 Mantis PRs pcm.</p>
<h4 id="takayuki-imada-29">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Found that the longer waiting periods under Solo5-virtio were caused due to GC, and that they can be managed by changing the minor heap size. I will not have further investitation on the above because they are not a dominant factor of the current performance bottleneck.</li>
<li>Completed reading the source code of Solo5-ukvm, learned how Solo5-ukvm operates in receiving and sending network packets.</li>
<li>Also found that Solo5-ukvm can have longer waiting periods not anticipated expecially in packet sending (maybe) due to its polling mechanism.</li>
<li>I will need to determine if I should tackle the new issue under Solo5-ukvm, and to start designing new networking archtecture for Solo5.</li>
</ul>
<h4 id="romain-calascibetta-27">Romain Calascibetta</h4>
<h4 id="decompress-18">Decompress</h4>
<p>I rework on the interface and add some conveniences functions to manipulate an integer (<code>int16</code>, <code>int32</code>, <code>int64</code>) with a string or a bigstring. And I put in the interface the definition of the type <code>st</code> and <code>bs</code> to prove the exhaustivness of the GADT <code>B.t</code> outside the library.</p>
<h4 id="sirodepac-and-ocaml-git"><code>sirodepac</code> and <code>ocaml-git</code></h4>
<p>I start the encoding of the meta-data, so I find a way to serialize the data, so I start to serialize the user, the commit, etc. But I don't have a relevant result for the moment. I think a lot about the optimization and try to implement an amortized data structure.</p>
<p>I create a mini-encoder in the same way as <code>faraday</code> but with my GADT between <code>string</code> and <code>bigstring</code>. Then, I create a little library like a <code>printf-like</code> for <code>faraday</code> where is possible to specify an optimized <code>blitter</code>.</p>
<p>I need to explain, for example a tag data can be described by a format for the deserialization, like that:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> binding ~key ~value = <span class="dt">string</span> key *&gt; sp *&gt; value &lt;* lf
<span class="kw">and</span> tag =
  binding ~key:<span class="st">&quot;object&quot;</span> ~value:hash
  &gt;&gt;= <span class="kw">fun</span> obj -&gt; binding ~key:<span class="st">&quot;type&quot;</span> ~value:kind
  ...</code></pre></div>
<p>So I would like the same for the encoder. I looked the article about the GADT from <span class="citation" data-cites="drup">@drup</span> and I create an convenience interface with GADT to describe how to serialize a data with <code>faraday</code> and for the same example, we have:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> tag =
  (Const<span class="kw">.</span><span class="dt">string</span> <span class="st">&quot;object&quot;</span>) ** sp ** <span class="dt">string</span> **! lf **
  (Const<span class="kw">.</span><span class="dt">string</span> <span class="st">&quot;type&quot;</span>) ** sp ** <span class="dt">string</span> **! lf **
  ... nil</code></pre></div>
<p>This formatter expect somes arguments and you can decide to write or to schedule the writing in the buffer. Another fix is to specify a fast <code>blit</code> function to my GADT if you want - but I don't find a relevant example. It's like <code>printf</code> but for <code>faraday</code>.</p>
<p>I informed Spiros about that but he does not talk to me yet so I don't know if I extract this module in a new library (I can) or if I let this as an internal things for <code>sirodepac</code>/<code>ocaml-git</code>.</p>
<p>I <em>optimize</em> <code>sirodepac</code> and use only a <code>bigstring</code>, may be a good way is to test with spacetime to know how many <code>bigstring</code> I use. But, I found a bug, I can't reach a valid SHA1 hash when I deserialize the pack file. So, I will inspect that and I inform Thomas about that to know more precisely how to hash a git object. But a good things is that I start the encoding of <code>sirodepac</code> know.</p>
<p>In the same time, I look about the Merkle tree. It's a structure used by Git and the P2P protocol to provide a reliable data. I look a C implementation, and containers to propose an implementation.</p>
<p>About <code>ocaml-d3</code>, I don't have any work about that but it's just for fun. May be in hackathon, I will play with that but not for this moment.</p>
<h4 id="mr.-mime-5">Mr. MIME</h4>
<p>Nothing this week about Mr. MIME, I continue to keep in my head the TODO.</p>
<h4 id="next-things">Next things</h4>
<p>Now, I will create a test suites for <code>sirodepac</code> to prove that it works :) ! And, if I have a time, I will create a test suit for Decompress, specifically about the flush method.</p>
<h4 id="gemma-gordon-4">Gemma Gordon</h4>
<ul>
<li>Attended <a href="https://maintainerati.org/">Maintainerati</a> in SF last week (15th Feb)</li>
<li>Working on blog post about conference</li>
<li>Helped schedule OCL Platform blog posts go coincide with Mirage 3.0 release</li>
<li>General blog posts for OCL site</li>
<li>Porting the rest of our older content onto new site</li>
<li>Paperwork for new starter - Nicolas Assouad starting his internship next Monday (27th)</li>
<li>Wrote short blog post on Irmin release: http://ocamllabs.io/releases/2017/02/24/irmin1release.html</li>
<li>Designed and ordered MirageOS Hack t-shirts</li>
<li>Broke Atom on my laptop :(</li>
</ul>
<h4 id="liang-wang-25">Liang Wang</h4>
<ul>
<li>The first version of backward AD was implemented in Algodiff module. I overloaded most of the commonly used math operators.</li>
<li>I added another sub-module in Algodiff which is able to provide numerical differentiation. This can be used to cross-validate the results from Algodiff.AD module.</li>
<li>I added more functions (softplus, softsign, sigmoid, softmax, etc.) to Owl to provide better support for machine learning algorithms.</li>
<li>I have been doing experiment for Paar paper, and at the same time we have been trying to make ARM-based docker image for Owl so that we can run it on Raspberry Pi.</li>
</ul>
<h3 id="week-7">Week 7</h3>
<h4 id="kc-sivaramakrishnan-12">KC Sivaramakrishnan</h4>
<ul>
<li>Wrote blog post on Ezirmin: kcsrk.info/ocaml/irmin/crdt/2017/02/15/an-easy-interface-to-irmin-library/</li>
<li>Added ropes + operation transformation to Ezirmin.</li>
<li>Implemented prefetch instruction for OCaml</li>
<li>Working on the semnatics of DaLi progrmaming model</li>
</ul>
<h4 id="gabriel-de-perthuis-4">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Anticipate out of space situations and raise an error if necessary</li>
<li>Log spilling: find which child can receive the most data</li>
</ul>
<h4 id="david-allsopp-13">David Allsopp</h4>
<p>** OPAM ** - First attempt at rebasing onto Beta 2 (stuck at lib-pkg merge)</p>
<p>** OCaml 4.05** - Reviewing fix for GPR#861 relating to a DST-bug in Unix.stat on Windows. Far too much time spent reading MSDN and grep'ing source code of old CRTs... - Cygwin-32 fork crash. Moving mmap functions from Bigarray to Unix has broken Cygwin fork (reliable test case). Far too much time spent reading Cygwin source code - it's not yet clear whether this is a Cygwin bug, a FlexDLL bug or an OCaml bug...</p>
<h4 id="qi-li-14">Qi Li</h4>
<ul>
<li>implementation of <a href="https://github.com/me-box/databox-export-service.git">databox-bridge</a></li>
<li>using ocaml-macaroons to do the access right control of API</li>
<li>allow local driver/app to submit export request to a queue</li>
<li>worker thread (single one for now) extracts a request from the queue and processes it</li>
<li><p>driver/app polling the same API to get update on its request (may support websocket notification)</p></li>
<li><p>next week may spend some time to test the basic working flow, add logging operations, ws support maybe</p></li>
</ul>
<h4 id="takayuki-imada-30">Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Conducted investigation to understand which part (MirageOS or the host OS) affects the waiting periods, and found out only MirageOS probably does affect them. I confirmed that network processing on the host OS does not take such long time.</li>
<li>Started reading the source code of Solo5-ukvm to understand the current implementation of it. I found that (i) modular-based implementation in Solo5-ukvm helps me to easily add my new networking feature and (ii) the current Solo5-ukvm does not use vhost-net (= large room for performance improvement)</li>
<li>I will continue to understand the current Solo5-ukvm architecture in more detail next week. I will also start designing my networking feature after that.</li>
</ul>
<h4 id="romain-calascibetta-28">Romain Calascibetta</h4>
<h4 id="work-on-the-implementation-in-decompress">Work on the implementation in Decompress</h4>
<p>I finish to polish Decompress (test and documentation). So all is ok and the new version of Decompress (0.5) is ready. I choose to create the 0.5 version (and not the 1.0) because I insert an experimental thing in API and I would like to create a new test and prove that is more reliable to get the 1.0 version.</p>
<p>Indeed, I inserted the flush methods (<code>partial</code>, <code>full</code> and <code>sync</code>) and you use Decompress without these flush methods. After, all code is in OCaml (<code>alder32</code> compute and <code>memcpy</code> implementation).</p>
<p>Apparently, Decompress works with solo5, so it's a good news!</p>
<p>May be, I will push the new version in the hackathon because I don't have a good internet for the moment.</p>
<h4 id="ocaml-git-and-sirodepac"><code>ocaml-git</code> and <code>sirodepac</code></h4>
<p>I continue to work on the <code>sirodepac</code> at the same time. I just create a mini non-blocking decoder. May be I will implement a little fun interface with <code>ocaml-d3</code>. So I have a full deserialization of PACK and IDX git file and we can make easily the glue between <code>sirodepac</code> and <code>ocaml-git</code>.</p>
<p>So, I will create a mini non-blocking encoder now and after I will attack the main purpose of my mission, the create of the PACK file - to fix the <code>git push</code>. Thomas point me some bug, so I will focus now on this :) !</p>
<h4 id="mr.-mime-and-the-buffer">Mr. MIME and the buffer</h4>
<p>When I create the mini non-blocking decoder, I find a new way to handle the buffer and let the user to grow the buffer. It's the best choice (about the security) to let the user to grow the buffer. For the moment, it's Mr. MIME to grow the buffer and you can observe that but not precisely.</p>
<p>So, I push this big thing in my TODO. It's not complex but this idea changes the API a lot.</p>
<p>Voilà!</p>
<h4 id="liang-wang-26">Liang Wang</h4>
<ul>
<li>I added several more functions into Owl module such as tile, repeat, and etc.</li>
<li>I added matrix type into current AD forward mode to support simple linear algebra.</li>
<li>I started to re-design another AD module in order to have better supports for both forward and backward AD (to be implemented). Moreover, in new AD implementation, I change from recursive modules to a chain of recursive functions.</li>
</ul>
<h3 id="week-6">Week 6</h3>
<h4 id="gabriel-de-perthuis-5">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Node splitting</li>
<li>Prep for log spilling</li>
<li>Some refactoring of childlinks</li>
</ul>
<h4 id="david-allsopp-14">David Allsopp</h4>
<p><em>On &quot;holiday&quot; this week</em></p>
<h4 id="qi-li-15">Qi Li</h4>
<ul>
<li>implementation of <a href="https://github.com/me-box/databox-export-service.git">databox-storage</a></li>
<li>design and implementation of <a href="https://github.com/sevenEng/databox-bridge">databox-bridge</a></li>
</ul>
<h4 id="takayuki-imada-31">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Found out that the long waiting periods is a Xen-specific issue, it did not occur under my QEMU/KVM configuration.</li>
<li>Observed waiting periods even under the QEMU/KVM configurations, but they were shorter than under my Xen configuration and their fequency was low.</li>
<li><p>I will not have furuther investigation on this issue if not required, so I will move to designing new software archtecture to achieve higher network perforamnce on MirageOS.</p></li>
<li>FOSDEM2017</li>
<li>Attended the event to get topics realted to network, micro-kernel, micro-service, virtualization.</li>
<li>Several presentations were intersting for me (For example, TCP acceleration by using Intel Transration Layer Development Kit which is based on DPDK).</li>
<li><p>I will have a short presentation to report this topic on 28th Feb.</p></li>
</ul>
<h4 id="romain-calascibetta-29">Romain Calascibetta</h4>
<h4 id="work-on-the-implementation-in-decompress-1">Work on the implementation in Decompress</h4>
<p>I continue to implement the compression. Good news, the dynamic compression works with the dbuenzli's interface and the static compression should work too. The first layer (Lz77 compression) is done - the question is, it's good to functorize the implementation of the Lz77 or not ? I need to fix a bug in the flat compression - but it's very easy, may be one or two hours to fix that. Then, I will polish the interface. So, the second layer (Zlib compression) is most done.</p>
<p>Now, we have a complete interface for Decompress (with differents flush methods, like <code>partial</code> for SSH, <code>full</code> and <code>sync</code>). It's possible to change the frequencies before than Decompress computes a canonic Huffman tree. That means, it's possible to specialize the canonic Huffman tree with an external database of frequencies.</p>
<p>After polishing, I will do some benchmark with <code>landmarks</code> and try to compare with <code>zlib</code>. And, I will make the new release of Decompress (tagged 1.0). Then, I will attack the serialization to a PACK file.</p>
<p>UPDATE: I finish to fix the flat compression bug, I will make a good test suites.</p>
<p>UPDATE: I just add a test suites and <code>decompress.ml</code> works!</p>
<h4 id="encoding-and-mr.-mime">Encoding and Mr. MIME</h4>
<p>I don't have internet for now (for two weeks) so I can't see the database about the translation between an encoding and utf-8. But when I can get this database, I will start the new library (the name will be <code>uuuu</code>) and normalize all output of Mr. MIME to utf-8.</p>
<hr />
<p>May be, I will push (I can't for the moment because I don't have internet) my work in <code>dinosaure/sirodepac</code> repository in few days.</p>
<h4 id="liang-wang-27">Liang Wang</h4>
<ul>
<li>I re-implemented the forward mode of algorithmic differentiation [<a href="https://github.com/ryanrhymes/owl/blob/master/lib/owl_algodiff_forward.ml">code</a>]. Now the Algodiff supports higher-order derivatives now, check <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Algorithmic-Differentiation">here</a> please.</li>
<li>To support higher-order derivatives, Algodiff uses many recursive functions and also recursive modules. However, I was told recursive module is not a good option in OCaml due to losing the capability of compiler optimisation. I do not have a solution at the moment.</li>
<li>I overloaded some common math operators in Algodiff module. However, some matrix operations still need to be implemented.</li>
<li>I did some barrier control experiments in distributed learning. The simulator and result analysis are all done on top of Owl. The current results look good, Actor system seems more scalable than other barrier control. But I need to investigate a more into the accuracy.</li>
</ul>
<h3 id="week-5">Week 5</h3>
<h4 id="gabriel-de-perthuis-6">Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Node splitting</li>
<li>Publish the work done in January to <a href="https://github.com/g2p/mirage-storage" class="uri">https://github.com/g2p/mirage-storage</a></li>
</ul>
<h4 id="maxime-lesourd">Maxime Lesourd</h4>
<p>I'm trying to figure out all the places in TypedTree which end up as function definitions or applications for the effect analysis.</p>
<p>I also spent some time improving error messages in the fomega tool used for the advanced functional programming course.</p>
<h4 id="david-allsopp-15">David Allsopp</h4>
<p><em>Away for most of the week</em></p>
<p><strong>OCaml 4.05</strong> - Work on GPR#1010 (Prefixing the OCaml Standard Library</p>
<h4 id="qi-li-16">Qi Li</h4>
<ul>
<li>storage component of Databox</li>
<li>implemented tamper-proof logging feature of the store</li>
<li>implemented store engine, providing support for json and blob(by Cstruct.t) data types</li>
<li>browsed repo <a href="https://github.com/me-box/databox-export-service.git">ocaml-macaroon</a> and <a href="https://github.com/sevenEng/databox-bridge">opium</a>, for the purpose of integration into the store</li>
</ul>
<h4 id="takayuki-imada-32">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Implemented my iperf program using Mirage vnetif as an interconnect, and found there were still unexpected waiting(blocking) periods. So I concluded that somthing in MirageOS triggered this behavior. I will investigate a root cause of it by starting with further tracing schemes in MirageOS.</li>
<li>Conducted further analysis based on the previously obtained results, and found that the host OS side processing(i.e. network bridging) can occupies higher than 65% of the total network processing time without the unexpected waiting periods. This is an expected result, not suprising. The host OS side processing time can be reduced by taking advantage of existing schemes such as Netmap or DPDK.</li>
<li>Prioritized topics to be conducted
<ol type="1">
<li>investigation of the waiting periods not anticipated</li>
<li>implementation design to reduce overhead in the host OS side</li>
<li>implementation design to reduce overhead in the MirageOS network protocol layer</li>
</ol></li>
</ul>
<h4 id="romain-calascibetta-30">Romain Calascibetta</h4>
<h4 id="work-on-the-implementation-in-decompress-2">Work on the implementation in Decompress</h4>
<p>Move the implementation of the compression (deflate) in the same way of the decompression. With the work of Yallop, the implementation of <em>blosclz</em> and the advises of Thomas, I try to use a pure state for the Lz77 compression (first layer of Decompress) and the Zlib compression (second layer of Decompress) to use this implementation in <code>ocaml-git</code> to pack a git state.</p>
<p>For the moment, I have a non-blocking implementation of the Lz77 compression with theses changes: * pure state * non-blocking computation * remove a compute of a window - that means when the algorithm search a pattern, we limit to the input of the user. So, if the user compute the compression with a chunk of 4096 bytes (for example), we search a pattern only on this chunk (but theorically, we can keep ~ 28671 bytes) and the ratio between the literal and the distance for this compression will be bad. But, in a practical world, we compute the compression with a chunk of 32K bytes - and in this way, we have an optimal compression.</p>
<p>Finally, for a file (like an executable), we have a ratio about 1/3 for literals and 2/3 for matches - so 2/3 of compression without Huffman compression.</p>
<p>Now, I attack the Zlib (Huffman) compression in the same way (pure state and non-blocking) to get the new release of Decompress.</p>
<h4 id="ocaml.org">ocaml.org</h4>
<p>I try to find a bug inside ocaml.org about the feed generator (OCaml Planet). In the same time, I found lot of website with a bad or unaccesible feed. So, I sent an e-mail to advise some persons about that - like the website of Mirage or ocaml.io.</p>
<p>Chris00 fixed the bug (server side bug).</p>
<h4 id="encoding-and-mr.-mime-1">Encoding and Mr. MIME</h4>
<p>It's about the UTF-7. Some e-mails don't respect the encoding described by the standard (RFC 6532). The point is to create a library (but I already discuss about that with Daniel) to convert any encoding to UTF-8.</p>
<p>Mr. MIME has this problem, we respect the standard but not the practical e-mail, we need to be more resilient about that.</p>
<h4 id="gemma-gordon-5">Gemma Gordon</h4>
<ul>
<li>Adding more information to new OCL site - getting there!</li>
<li>Need to add projects next, most of the authors now added</li>
<li>Checking into Platform progress: odig, odoc, topkg</li>
<li>Preparing for Maintainerati in SF (15th Feb)</li>
<li>Planning Romain's next project with us</li>
<li>Preparing for Compiler Hacking next Tuesday</li>
</ul>
<h4 id="olivier-nicole">Olivier Nicole</h4>
<ul>
<li>Fixed small bugs with lambda quoting, bootstrapped the compiler.</li>
<li>Added some (hopefully temporary) code to print lambda quotes in the REPL.</li>
<li>Fixed a bug on <code>macros_unstable</code> that caused the compiler to crash when encountering a structure item with more than one splice in it.</li>
<li>On the way of fixing the bug that makes codes like: <code>module M = struct $ &lt;&lt; () &gt;&gt;   end</code> segfault.</li>
</ul>
<h4 id="liang-wang-28">Liang Wang</h4>
<ul>
<li>Implement a simple prototype of forward AD, but it does not support higher order derivatives. I need to read a bit more on algorithmic differentiation.</li>
<li>Try to test some barrier control logic in distributed learning.</li>
<li>Refactor the topic modeling module in Owl.</li>
</ul>
<h3 id="week-4">Week 4</h3>
<h4 id="kc-sivaramakrishnan-13">KC Sivaramakrishnan</h4>
<ul>
<li>Discussion with <span class="citation" data-cites="stedolan">@stedolan</span> about mergeable datatypes
<ul>
<li><em>if cons is the basis of functional data structures, what is the basis of mergeable funcational data structures?</em></li>
</ul></li>
<li>Multicore OCaml
<ul>
<li>Submitted PR for OSX compilation: https://github.com/ocamllabs/ocaml-multicore/pull/103</li>
<li>Working on fixing backtraces: https://github.com/ocamllabs/ocaml-multicore/issues/93</li>
<li>Rubber ducking for memory model discussion with <span class="citation" data-cites="stedolan">@stedolan</span>.</li>
</ul></li>
</ul>
<h4 id="gabriel-de-perthuis-7">Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>Exercising the tree with synthetic data</li>
<li>Node splitting (work in progress)</li>
</ul>
<h4 id="maxime-lesourd-1">Maxime Lesourd</h4>
<ul>
<li>Spent most of my time figuring out the application process for my future PhD...</li>
<li>Made some progress on the report, the introduction is almost done.</li>
</ul>
<h4 id="david-allsopp-16">David Allsopp</h4>
<p>(reduced week)</p>
<p><strong>OCaml 4.05</strong> - Change Log Processor merge - failed to reach consensus. Shelved for now - will hopefully get turned into a Git merge driver instead. - Various GPR reviews - PR#7373, fixing a bug (of my own) in the FlexDLL bootstrap part of the build system. Tacking on some improvements to that which will feed into OPAM.</p>
<h4 id="qi-li-17">Qi Li</h4>
<ul>
<li>work done for Databox</li>
<li>meeting with mort and Liang to clarify the functionalities/patterns of interactions for the new system components to be developped: storage and bridge.</li>
<li>for storage, it will provide tamper-proof, append-only logging of each store operations, and it will support different data types: Json, Timeseries, Blob, etc. Later, we could be more high-level features like model based compression on this</li>
<li><p>for bridge, still needs more discussion and thinking, for the first step, we could build it with &quot;redirect point&quot; style, which allows third parties to register/update their services, look up the others' services, and also allows internal components to insert/delete their own plug-in functions.</p></li>
<li>supervision</li>
<li><p>IB course CompNet</p></li>
</ul>
<h4 id="takayuki-imada-33">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Conducted a test on the unix configuration, and found that the sender and receiver sides behavior was quite simple without any blocking periods. This indicates Xen or the network bridging on the hostOS can affect the blocking periods.</li>
<li>Having additional tests where the sender(receiver) program on a MV and the receiver(sender) program on Dom0 to reduce noise from the virtualization side.<br />
</li>
<li>Had a meeting with Docker members to explain the findings. Comments from them are as follows;
<ul>
<li>To try to put one of the sender or receiver sides on Linux.</li>
<li>To try to have one unikernel VM having both the sender and receiver side using the vnetif module to completely remove noise from network bridging on the hostOS.</li>
<li>Checksum offloading and IP fragmentation offload will help us to improve the network performance.</li>
<li>ukvm rather than Xen would be better and easier for implementing a new network interface layer.</li>
</ul></li>
</ul>
<h4 id="gemma-gordon-6">Gemma Gordon</h4>
<ul>
<li>Continuing with OCL site: https://ocamllabs.github.io/</li>
<li>Planning for new interns and visitors</li>
<li>Catching up with Platform activity: odoc, odig, topkg</li>
<li>Planning Compiler Hacking: https://ocamllabs.github.io/compiler-hacking/2017/01/24/february-compiler-hacking.html</li>
</ul>
<h4 id="olivier-nicole-1">Olivier Nicole</h4>
<ul>
<li>Diagnosis of a &quot;problem&quot; with generation of Parsetrees and Lambdas in parallel by macros. To quote Leo:</li>
</ul>
<blockquote>
<p>the best thing to do would be to start by making lambda quoting work on its own without worrying about creating an AST Step two would be to make the extrusion errors in terms of source variables with locations And step three would be to start building the AST again The final version would, instead of producing:</p>
<pre><code>let splice1 = ... in
let splice2 = ... in
let ast = ... Field(0, [splice1]) ... Field(0, [splice2]) ... in
let lambda = ... Field(1, [splice1]) ... Field(1, [splice2]) ... in
  Makeblock [ast; lambda]</code></pre>
<p>produce something like:</p>
<pre><code>let splice1 = ref null in
let splice2 = ref null in
let lambda =
  ... (let res = ... in splice1 := Field(1, res); Field(0, res)) ...
  ... (let res = ... in splice2 := Field(1, res); Field(0, res)) ...
in
let ast = ... !splice1 ... !splice2 ... in
  Makeblock [lambda; ast]</code></pre>
<p>This would give us ASTs without any renaming of variables With a bit more work we could probably get renaming as well</p>
</blockquote>
<ul>
<li>Jeremy and Leo discovered three bugs, noted here for future reference:</li>
</ul>
<p><code>$ ocaml -dsource   # static r = ~Pervasives.ref None;;   static r = (~Pervasives).ref None ;;   static val r : '_a option ~Pervasives.ref = {~Pervasives.contents = None}   # let f () = let x = 10 in $(let c = &lt;&lt;x&gt;&gt; in ~Pervasives.(:=) r (Some c); c);;   let f () =  let x = 10  in $(let c = &lt;&lt; x &gt;&gt;  in (~Pervasives).(:=) r (Some c); c) ;;   splice #1: x val f : unit -&gt; int = &lt;fun&gt;   # let g () = let x = &quot;Hello world&quot; in $(let open ~Pervasives in match !r with Some c -&gt; c | None -&gt; &lt;&lt; 0 &gt;&gt;);;   let g () = let x = &quot;Hello world&quot; in $(let open ~Pervasives in match !r with Some c -&gt; c | None -&gt; &lt;&lt; 0 &gt;&gt;);;   Warning 26: unused variable x. splice #1: x val g : unit -&gt; int = &lt;fun&gt;   # g () + 5;;   - : int = 70275569256653</code></p>
<p><code>CamlinternalQuote.Exp.Local</code> should be used for all identifiers quoted in toplevel splices.</p>
<p><code>module M = struct $(&lt;&lt;()&gt;&gt;) end;;</code></p>
<p>results in an &quot;index out of bounds&quot; exception.</p>
<p><code>static print x = ~Pervasives.print_endline x;;   $(print &quot;one&quot;; &lt;&lt;()&gt;&gt;);;   $(print &quot;two&quot;; &lt;&lt;()&gt;&gt;);;</code></p>
<p>results in a segfault when put in a file and compiled with <code>ocamlc</code>.</p>
<ul>
<li>Lambda quoting now works, including path closures but without scope extrusion detection. There are still a few bugs to fix in the REPL but the tests show that all the other functions have been preserved. It is nice to see that macros are quite orthogonal to other features.</li>
</ul>
<h4 id="stephen-dolan-3">Stephen Dolan</h4>
<ul>
<li>off sick monday / tues</li>
<li>progress on memory models! (more soon..)</li>
<li>mpi/multicore debugging with <span class="citation" data-cites="dhil">@dhil</span></li>
</ul>
<h4 id="liang-wang-29">Liang Wang</h4>
<ul>
<li>Study automatic algorithmic derivation, prepare for the implementation.</li>
<li>Work on distributed data processing system (Actor System), document what has been done so far.</li>
<li>Refine and formulate the idea of a new barrier control technique in distributed machine learning, write the initial draft, plan the evaluation.</li>
</ul>
<h3 id="week-3">Week 3</h3>
<h4 id="kc-sivaramakrishnan-14">KC Sivaramakrishnan</h4>
<ul>
<li>Moving more issues to under Multicore issues. Organizing the issues under projects.</li>
<li>Chat with Daniel Hillestrom about progress on default handlers &amp; ICFP papers.</li>
<li>Chat + planning with Gowtham for DaLi paper to ICFP/OOPSLA.</li>
</ul>
<h4 id="gabriel-de-perthuis-8">Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>reloading support, testing and bug fixing</li>
<li>indexing child and log structures from disk</li>
<li>freeing replaced nodes from the space map</li>
</ul>
<h4 id="maxime-lesourd-2">Maxime Lesourd</h4>
<ul>
<li>Started writing on the work I've done so far</li>
<li>Finished setting up the blog after some troubles with mathjax over https</li>
<li>Little progress on the Agda developments. Since we still don't have a typed cps translation I'm going to spend less time on this.</li>
<li>The plan for next week is to have a summary our attempts at &quot;verifying&quot; the cps translation either through a type system or a proof that it preserves semantics. Then we can start asking for outside feedback and see what we can do.</li>
</ul>
<h4 id="david-allsopp-17">David Allsopp</h4>
<p>(reduced week)</p>
<p><strong>OCaml 4.05</strong> - Change Log Processor - Various GPR reviews</p>
<h4 id="qi-li-18">Qi Li</h4>
<ul>
<li><p>Read literatures about model-based data compression. Found two algorights that might be apt to integrate into pih-store, Adaptive Piecewise Constant Approximation and Slider Filter. They are both online processing algorights. The idea is to cut the stream of data into appropriate segments, and fit the data in each segment to a specific linear function. Next week, may try to implement the first version of this.</p></li>
<li><p>Continued learning about the design and structure of <code>packetdrill</code>. Still not clear about what shoud the statck test framwork should look like.</p></li>
<li><p>Browsed some repos that use <code>topkg</code> from <a href="http://erratique.ch/software/topkg/doc/Topkg.html#menagerie">doc page</a>, finished learning how to use it.</p></li>
</ul>
<h4 id="takayuki-imada-34">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>iperf tests for tracing done, so I am summarizing findings from the tests</li>
<li>Findings
<ul>
<li>the CPU utilization on the sender side reached 100%</li>
<li>there were waiting (or blocking) periods on the sender side, they are not anticipated and occupy 50% of the total network processing time. (Due to thread scheduling?)</li>
<li>the waiting periods always occurred during a &quot;ring.write&quot; phase</li>
<li>The receiver side had sleeping periods which would correspond to the waiting periods above, so its CPU utilization was not so high.</li>
</ul></li>
<li>I will need to specify what triggers the waiting periods.</li>
</ul>
<h4 id="gemma-gordon-7">Gemma Gordon</h4>
<ul>
<li>Finished MirageOS feedback blog: http://reynard.io/2017/01/18/MirageIRCFeedback.html</li>
<li>Ongoing report</li>
<li>MirageOS press details</li>
<li>New OCL site started: https://ocamllabs.github.io/</li>
<li>Funding planning and allocation for next quarter</li>
</ul>
<h4 id="olivier-nicole-2">Olivier Nicole</h4>
<ul>
<li><p>Work done on lambda quoting: combinators are in place, now Translquote has to use them properly, i.e. the path arguments given to macros must become <code>lambda</code> instances (and not <code>Longident.t</code> instances).</p></li>
<li><p>After the last fixes on module type discovery, it seems that the compiler is now fully (except for syntax) backward-compatible, in the sense that projects that don't use macros should have the same dependency tree in 4.04 and in 4.04+macros.</p></li>
<li><p>My fork of Camlp4 now compiles on the macro switch.</p></li>
<li><p>Some reflexion on Flick and looking at the code of motto.</p></li>
<li><p>Flick: added a few elements in the DSL for channel declarations. For now, channels are implemented as a <code>'i option ref * 'o option ref</code> in the interpreter (i.e. a 1-capacity channel). Trying to replicate the program (https://github.com/NaaS/motto/blob/master/tests/runtime/factorial.ml)[factorial.ml].</p></li>
<li><p>Flick: add operations on channels, temporarily implement channels in terms of two references on lists (for incoming and outgoing data) and write my first &quot;embedded&quot; Flick program using the unstaged interpreter. This program doesn't use processes.</p></li>
<li><p>Macros: Introduced a new constructor <code>Lescape</code> to denote when a piece of lambda code should not be lifted when constructing a lambda quote. My current problem is: how to construct Parsetree quotes and lambda quotes in the same recursion without doing a lot of pairing/unpairing?</p></li>
</ul>
<h4 id="liang-wang-30">Liang Wang</h4>
<ul>
<li>Release Owl 0.2.0 to OPAM. The new release contains a lot of significant changes in the fundamental data structures in Owl. The number types and precision can be passed in as parameters in creation functions. Meanwhile, the interface remains compatible with the old <code>Dense.Real</code> and <code>Dense.Complex</code> modules, the latter two have default 64-bit precision.</li>
<li>Write a tutorial on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Basic-Data-Types">Basic Data Types in Owl</a></li>
<li>Write a tutorial on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Metric-Systems">Metric Systems in Owl</a></li>
<li>Ben Caterall implemented a topic modelling algorithm (SparseLDA) using Owl, the pull request has been merged. This actual application of Owl will help in refining the interface of Owl. The code can be found <a href="https://github.com/ryanrhymes/owl/blob/master/lib/topic/owl_topic_lda.ml">here on github</a>.</li>
<li>LDA code revealed a problem of Sparse module in Owl. The new implementation of Sparse module actually slows down the LDA algorithm a lot. The reason is current matrix storage format (CRS) is not ideal for random access of matrix elements (even tough it speed up many linear algebra operations), whereas my previous implementation uses a combination of hash table and CRS. This needs to be solved in future.</li>
</ul>
<h3 id="week-2">Week 2</h3>
<h4 id="kc-sivaramakrishnan-15">KC Sivaramakrishnan</h4>
<ul>
<li>Investigated the issue of slow compile times on 4.04.0. Reported the bug to mantis: https://caml.inria.fr/mantis/view.php?id=7456</li>
<li>Planning for DaLi research paper. tl;dr is to add language level support for mergeable datatypes. This builds on several pieces of work that has already been done:
<ul>
<li><a href="https://github.com/kayceesrk/ezirmin">ezirmin</a></li>
<li><a href="roscidus.com/blog/blog/2015/04/28/cuekeeper-gitting-things-done-in-the-browser/">Cuekeeper</a></li>
<li><a href="https://github.com/gprano/diff-datatypes">diff-datatypes</a></li>
</ul></li>
<li>Updated CV and website.
<ul>
<li>Updated the timeline :-) http://kcsrk.info/timeline.html</li>
</ul></li>
<li>Submitted OCaml bug report for failing thread initialization: https://caml.inria.fr/mantis/view.php?id=7452.
<ul>
<li>xleroy confirmed the bug and has proposed the fix: https://github.com/ocaml/ocaml/pull/1009</li>
</ul></li>
<li>Multicore planning. Have come up with a laundry list of features.</li>
</ul>
<h4 id="gabriel-de-perthuis-9">Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>build a free space map from a filesystem scan</li>
<li>flush support</li>
<li>upgrade to mirage 3 interfaces</li>
</ul>
<h4 id="maxime-lesourd-3">Maxime Lesourd</h4>
<ul>
<li>Set up a blog hosted on github pages. I plan to do a few posts about my attempts at typing and/or verifying the CPS translation</li>
<li>Made some progress on the Agda formalization of a lambda calculus with simple effects</li>
<li>The syntax and types are done</li>
<li>The small step semantics using substitution is almost done</li>
<li>The abstract machine needs some work</li>
</ul>
<h4 id="david-allsopp-18">David Allsopp</h4>
<p>(reduced week)</p>
<p><strong>OCaml 4.05</strong> - Change Log Processor</p>
<h4 id="takayuki-imada-35">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>finished preparing for performance bottleneck investigation.
<ul>
<li>finished learning and testing how to conduct tracing on Xen as well as on QEMU/KVM.</li>
<li>finished building my MirageOS environment with the profiling support.</li>
</ul></li>
<li>TCP-based iperf tracing
<ul>
<li>Found the vCPU utilization on the receiver side reached 100% though the sender side did not (~30%)</li>
<li>also found it difficult to capture their behavior due to complicated ACK/SYN mechanisms in the TCP stack, so decided to use UDP.</li>
<li>I will resume this after finishing the UDP-based iperf investigation</li>
</ul></li>
<li>UDP-based iperf tracing
<ul>
<li>Finished coding UDP-based iperf based on TCP-based iperf</li>
<li>Tracing in the MirageOS layer and the Xen layer by using the mirage-trace-viewer, xentop and xentrace commandes</li>
</ul></li>
</ul>
<h4 id="gemma-gordon-8">Gemma Gordon</h4>
<ul>
<li>Completed first draft of MirageOS Feedback blog</li>
<li>Ongoing OCL Oct-Dec report</li>
<li>Admin/management for new visitors</li>
<li>Multicore planning with KC and Stephen - specifically repo organisation</li>
<li>Working on MirageOS 3.0 posts/articles and press details</li>
<li>Submit Slack for Education application</li>
<li>Plan POPL liveblog</li>
<li>Start work on OCL site with updated information</li>
<li>Start planning for Maintainerati</li>
</ul>
<h4 id="olivier-nicole-3">Olivier Nicole</h4>
<p>Start working on &quot;lambda quoting&quot; again.</p>
<p>Added the <code>CamlinternalLambda</code> file, contains a <code>lambda</code> type that resembles <code>Lambda.lambda</code>.</p>
<p>WARNING: Unlike with <code>CamlinternalAST</code> types, we do not necessarily want <code>CamlinternalLambda.lambda</code> to be isomorphic to <code>Lambda.lambda</code>! E.g. the <code>Ident.t</code> in <code>Lambda.lambda</code> is replaced with a simple string in <code>CamlinternalLambda</code>. Instead, we will rely on a trivial function to transform a <code>CamlinternalLambda.lambda</code> into a <code>Lambda.lambda</code>. This approach is simpler than the one used in <code>CamlinternalAST</code>.</p>
<ul>
<li>Re-read Oleg's paper about BER MetaOCaml to understand scope extrusion detection checks.</li>
</ul>
<p>It has been decided that for now, we will leave those checks in Parsetree quoting and not try to replicate them in Lambda quoting.</p>
<ul>
<li><p>Flick: read stuff about ctypes, try to figure out how to represent processes and command blocks.</p></li>
<li><p>Add the <code>iterate</code> combinator (translation of Flick for loops) and start building the blocks of processes.</p></li>
<li><p>Compiler: add more lambda quoting combinators and move all combinators in a Lambda module in <code>CamlinternalQuote</code>.</p></li>
<li><p>Fix bug with phase of type extensions, improved the compilation of menhir (in the sense that the first error occurs later in the build process). Menhir is necessary to build motto.</p></li>
<li><p>Now having a problem with module type discovery. Recall that, for compatibility reasons, each module declared in a source file must be deeply inspected in case it exports static values or macros. If it is not the case, then it is safe not to include it in the static code. This way, we don't add useless static dependencies, so that dependency trees are backward-compatible.</p></li>
<li><p>Here, some module types are not found for an unknown reason, entailing irrelevant static dependencies and preventing the compilation of Menhir.</p></li>
<li><p>Update other files to Parsetree quoting combinators being moved in a new module.</p></li>
<li><p>Keep working on interface discovery.</p></li>
<li><p>Start working on using the lambda combinators to actually construct lambda quotes in <code>Translquote</code>.</p></li>
<li><p>There is little documentation on the syntax and semantics of Flick. All that is available is documentation about Crisp, and sometimes the designs of these two languages diverge. For instance, in Crisp, two expressions at the same level of indentation separated by a newline, e.g.: <code>expr1   expr2</code> are evaluated in parallel, whereas in Flick they are evaluated sequentially.</p></li>
</ul>
<p>After speaking with Nik, it would be useful to keep a kind of log of such remarks that could be included in Flick's documentation.</p>
<ul>
<li>FINALLY found the bug in deep interface inspection: in <code>Includemod</code>, the environment used for building module coercions should know about the largest signature (using <code>Env.add_signature</code>), but it wasn't the case.</li>
</ul>
<p>Menhir now compiles on the macro switch, and so does motto.</p>
<h4 id="liang-wang-31">Liang Wang</h4>
<ul>
<li>Split out Owl's interface to Eigen3 as a standalone library: <a href="https://github.com/ryanrhymes/eigen">Github Repo</a></li>
<li>Manage to learn how to interface between OCaml and C++ template library using Ctypes when interfacing to Eigen3.</li>
<li>Submit Eigen OCaml library to OPAM on Friday and wait for approval now.</li>
</ul>
<h3 id="week-1">Week 1</h3>
<h4 id="kc-sivaramakrishnan-16">KC Sivaramakrishnan</h4>
<ul>
<li>Ezirmin
<ul>
<li>Add <code>Sync</code> module that roughly mirrors <code>Irmin.Sync</code>. Discovered that <code>push</code> is broken. This is tracked in the following issues:
<ul>
<li>https://github.com/mirage/ocaml-git/issues/139</li>
<li>https://github.com/mirage/irmin/issues/379</li>
</ul></li>
<li>Added support for history</li>
<li>Adding features to write a blog post</li>
</ul></li>
<li>Write and submit DaLi paper to <a href="https://github.com/gowthamk/snapl">SNAPL 2017</a></li>
</ul>
<h4 id="gabriel-de-perthuis-10">Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>Start refactoring the way cache items are addressed. This is a precondition for flush support.</li>
<li>Document many design and implementation decisions.</li>
</ul>
<h4 id="david-allsopp-19">David Allsopp</h4>
<p><strong>General</strong> - Settling into the lab</p>
<p><strong>OPAM-on-Windows</strong> - MSR meeting. Immediate things to note: - Once rebase complete, liaise with <span class="citation" data-cites="protz">@protz</span> on package requirements to eliminate MSR internal OPAM scripts - Andreas Hauptmann (fdopen) has stopped (is stopping) supporting his Windows opam-repository</p>
<p><strong>OCaml 4.05</strong> - Reviewing &quot;my&quot; [GM]PRs and devising workplan ready for 1 Feb freeze</p>
<h4 id="takayuki-imada-36">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>started preparing for performance bottleneck investigation.
<ul>
<li>finished building a QEMU/KVM hypervisor with a tracing feature by ftrace, and confirmed it can work.</li>
<li>building my MirageOS environment with the profiling support.<br />
</li>
</ul></li>
<li>Tools for network performance measurement</li>
<li>Finished making them available on the GitHub Website.</li>
<li>(throughput) https://github.com/TImada/mirage_iperf</li>
<li>(latency) https://github.com/TImada/mirage_pingpong</li>
</ul>
<h4 id="gemma-gordon-9">Gemma Gordon</h4>
<p><strong>General</strong> - Catching up post-Christmas MANY EMAILS<br />
- Exploring using furore for weekly worklogs with a view to everyone adding their weekly logs directly<br />
- Paperwork and administration for visiting researchers to the lab<br />
- Working on our 2016 catch up report: https://ocamllabs.github.io/furore/index.html<br />
- Prepping Oct-Dec short report on activities<br />
- Helping settle David Allsopp in the lab for his first day<br />
- Writing up a blog about the MirageOS feedback<br />
- Working on MirageOS logos</p>
<p><strong>Projects</strong> - Talked with Fred re Merlin progress:<br />
- stateless frontend: working on wrapper for Windows<br />
- logging: working on currently<br />
- parsing: late Jan, needs to talk with Francois first<br />
- Talked with Mark Shinwell (JS) about Merlin use at JS and issues they are facing<br />
- Planning Romain's next project with OCL</p>
<h4 id="frédéric-bour">Frédéric Bour</h4>
<ul>
<li><p>OCaml compiler work (that affects Reason and OCaml): migrating the parse tree - with Alain Frisch and Jeremie Diminio - different solution. Useful for JS via ppx and FB via Reason.</p></li>
<li>Merlin:</li>
<li><p>Stateless frontend: Happy with it as it stands, has not optimised performance, but what is currently there works. Planning to spend some time at JS working on integration as it is quite a deep change - after POPL.</p></li>
</ul>
<p>Merlin TODO: - Stateless wrapper for Windows: started, more difficult than expected. The current design is not portable, so needs to work on that and then implement it. Needs Windows box - arriving next week. - Logging: Logging is made possible by the stateless frontend. Has a prototype but doesn't match - will progress quickly once started - likely early January. - Parsing: Meeting Francois to discuss features/direction</p>
<h4 id="liang-wang-32">Liang Wang</h4>
<ul>
<li>Owl</li>
<li>Implement the module of sparse matrices.</li>
<li>Implement the module of sparse n-dimensional array.</li>
<li>Add the unit tests for Dense.Matrix, Dense.Ndarray, Sparse.Matrix, and Sparse.Ndarray modules using Alcotest.</li>
<li>Add the performance tests for the aforementioned four modules.</li>
</ul>
<h2 id="weekly-notes-for-2016">Weekly notes for 2016</h2>
<h3 id="week-51">Week 51</h3>
<h4 id="david-allsopp-20">David Allsopp</h4>
<p><strong>OCaml</strong> Various mildly time-consuming bits 'n bobs: - Testsuite hardening to improve CI (GPR#974, GPR#975) - CI tweaks (GPR#978, GPR#979) - Windows asmrun build system merge test+review (GPR#941) - GPR#980 test+review</p>
<h4 id="takayuki-imada-37">Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Finished it on MirageOS and Linux VMs.</li>
<li>Observed network throughput on MirageOS VMs is worse than on Linux VMs. We will need to investigate why this happens.</li>
<li>128-byte buffer size:
<ul>
<li>3MB/s on MirageOS-Xen, 24MB/s on MirageOS-virtio</li>
<li>46MB/s on Linux-Xen, 38MB/s on Linux-virtio</li>
</ul></li>
<li>1024-byte buffer size:
<ul>
<li>16MB/s on MirageOS-Xen, 38MB/s on MirageOS-virtio</li>
<li>230MB/s on Linux-Xen, 295MB/s on Linux-virtio</li>
</ul></li>
<li>Also preparing for releasing my source codes on the Github.</li>
<li>this includes only source code sophistication for releasing, and will be finished in several days.</li>
</ul>
<h4 id="frédéric-bour-1">Frédéric Bour</h4>
<p>I haven't progressed much on merlin this week, all my work was reason-related</p>
<h3 id="week-50">Week 50</h3>
<h4 id="takayuki-imada-38">Takayuki Imada</h4>
<ul>
<li>Preparing for the network performance evaluation -&gt; Finished automation framework implementation for the network performance evaluation.</li>
<li>The automation script I implemented worked fine. -&gt; Started building a MirageOS environment on another physical server @ packet.net.</li>
<li>MirageOS/Solo5: mirage-dev</li>
<li>OCaml version: 4.03.0, 4.04.0</li>
<li>Hypervisor: Xen, KVM(virtio) -&gt; But now having a problem in executing MirageOS with OCaml v4.03.0 on Xen, so investigating how to solve it.</li>
<li>This seems a bug in MirageOS. -&gt; Also started and finished the iperf network performance evaluation on Linux Virtual Machines.</li>
<li>on the physical server above.</li>
<li>Observed throughput: 38MB/s(128 bytes buffer length), 290MB/s(1024 bytes buffer length)</li>
</ul>
<h4 id="frédéric-bour-2">Frédéric Bour</h4>
<ul>
<li>Distributed witnesses, https://github.com/let-def/distwit (with <span class="citation" data-cites="samoht">@samoht</span> )</li>
<li>Solve the problem of marshalling exceptions / extensible type by externalizing the equality.</li>
<li>HyperLogLog, https://github.com/let-def/grenier/blob/master/hll/hll.mli</li>
<li>Cardinality estimation in constant space. I made a p-o-c implementation a while ago, now there is one user.</li>
<li>I added serializability, improved memory representation and fixed a bug causing small biases in estimations</li>
<li>Macho support for Owee, https://github.com/let-def/owee, WIP</li>
<li>Loading Macho would be useful for supporting macOS binaries in spacetime.</li>
<li>This would also a cheap lwt instrumentation tool for monitoring and backtraces. I discussed with <span class="citation" data-cites="antron">@antron</span>, maybe we will look at providing the necessary hooks in the future.</li>
<li>OCaml meeting (monday last week, some notes about stuff I want to look at)</li>
<li>Namespace: Didier Remy worried about specification of build (clumsy, not part of the langage)</li>
<li>Interested by bytecode/native interoperability (mentioned by <span class="citation" data-cites="dim">@dim</span>, <span class="citation" data-cites="stedolan">@stedolan</span>)</li>
<li>About release process: too much GPR, not enough testing &amp; code review, quality not satisfying</li>
<li>Eliom presentation (yesterday) &amp; talk with <span class="citation" data-cites="drup">@drup</span></li>
<li>Seems feasible to add eliom support to Merlin.</li>
</ul>
<h4 id="liang-wang-33">Liang Wang</h4>
<p>I have been working on the following things.</p>
<ol type="1">
<li><p>I received a lot of feedback of Owl via github and emails from different people. Based on the feedback, I decided to restructure the Owl a bit by providing a more general matrix module using GADT. I already finished the initial version of Dense.Matrix module. In the near future, it will replace the current Dense.Real and Dense.Complex to provide matrix support for more types and precisions.</p></li>
<li><p>I met Huawei people with Jon and presented Owl and Actor (the data processing system) I developed. They showed some interests which is a good sign (maybe:)</p></li>
<li><p>For Actor, I have been collecting papers and doing literature survey to formulate the idea.</p></li>
</ol>
<p>For next week, I will fly back to Helsinki so I cannot attend the meeting any more this year. I will see you guys next year in January :)</p>
<h3 id="week-49">Week 49</h3>
<h4 id="qi-li-19">Qi Li</h4>
<ul>
<li><p>talked with mort about the next project/direction to work on, for now, there are two possibilities: about PIH-store, develop a model-based compression engine inside of it, so that the data could take up much less storage space, yet with tolerant divergence from their real values; another one is about developing some temporal logic(together with buffer management) to extend the expressibility of packet capturing of network traffic</p></li>
<li><p>talked with Magnus about work within MirageOS tcp/ip stack testing, at the moment there are testing about different parts of a protocol (say for TCP, we have tests for options and window management), Magnus is working on more different vnetif backends (to simulate different network traffic failure modes), I think there may be something missing in between, like tests when different parts of a protocol working together as a whole under various scenarios, or a test for layers in the stack working together with different packets traces, there are some parts in test_rfc5961.ml and test_iperf.ml, but I think there should be a easier way to express these and a higher level interface to create packets and traces instead of manually created cstruct(s), I'd like to develop something like `packetdrill', probably together with a test environment and I've already started to look into this.</p></li>
</ul>
<h4 id="takayuki-imada-39">Takayuki Imada</h4>
<ul>
<li>Preparing for the network performance evaluation</li>
<li>Implementing an automation framework of the network performance evaluation
<ul>
<li>This will be finished in several days</li>
<li>Took long time to solve how to get logs of the MirageOS console (A logging scheme provided by Libvirt could not work, so I investigated and tried other logging frameworks)</li>
</ul></li>
<li>Making a slide deck to introduce my work at OCaml Labs to Hitachi Data systems guys</li>
<li>90% finished
<ul>
<li>I will be able to submit the slide to you for checking next week</li>
<li>I will also check what kind of checking process in Hitachi for the slide is needed.</li>
</ul></li>
</ul>
<h4 id="olivier-nicole-4">Olivier Nicole</h4>
<p><strong>Compiler</strong></p>
<ul>
<li>The compiler &quot;without placeholders&quot; (and thus without useless static dependencies) now broadly works, i.e. I was able to bootstrap (necessary because adding an argument to one constructor of <code>Path.t</code> changed the cmi format) and compile <code>re</code> (a regexp library that previously didn't compile because of dependency issues).</li>
<li>Fixed some tests, including <code>warnings/w53.ml</code> and other easy things. My changes appear to have broken recursive modules again (assertion failed in <code>CamlinternalMod</code>).</li>
<li>Fixed some tests involving recursives modules, but not all of them, by fixing the <code>init_shape</code> function.</li>
<li>Changed the lifting symbol to <code>~</code> (which unlike <code>^</code> should be non-breaking) in order to break less Opam packages.</li>
<li>Fixed various issues and bugs with the new system of coercion. It seems quite robust, all tests are passed (except <code>no-alias-deps/aliases.cmo</code> but that's for a completely different reason, and was expected), and a lot of code from Opam compiles fine.</li>
<li>Fixed priority of &quot;illegal quoting&quot; errors over phase errors after drup's remarks</li>
</ul>
<p><strong>Examples using macros</strong></p>
<ul>
<li>I try to make a fork of camlp4 compile again, but I encountered a bug that wasn't caught by the tests.</li>
<li>A segfault occurs when running static code for the main source file of camlp4. Investigating on the issue.</li>
<li>Started to look at the Flick network DSL, and its OCaml implementation Motto, and whether it can benefit from compile-time metaprogramming.</li>
<li>Menhir is a dependency of motto, and doesn't compile because of wrong dependency tree — can be fixed by not translating type extensions into static code</li>
<li>Talked with Mort about networking examples. It would be nice to be able to optimize a packet stream processor like POF or P4 using staging (maybe trying to use or get inspiration from strymonas).</li>
</ul>
<h4 id="liang-wang-34">Liang Wang</h4>
<ol type="1">
<li><p>I finished the first version of n-dimensional array in Owl, including some optimisation and the full documentation.</p></li>
<li><p>I also wrote a tutorial on Ndarray which you can find here: https://github.com/ryanrhymes/owl/wiki/Tutorial:-N-Dimensional-Array</p></li>
<li><p>I did some initial comparison to numpy and julia, it looks promising at the moment, and I will do more thorough evaluation next week.</p></li>
<li><p>I also talked to kc and michel and discussed about further optimisations on owl, I will look into the directions they suggested in the following weeks.</p></li>
</ol>
<h3 id="week-48">Week 48</h3>
<h4 id="takayuki-imada-40">Takayuki Imada</h4>
<ul>
<li>Preparing for the network performance evaluation</li>
<li>finished the iperf modification, now iperf can be conducted between independent MirageOS VMs</li>
<li>finished investigation of performance profiling schemes for MirageOS/Solo5</li>
<li>tested mirage-trace-viewer and it worked fine</li>
<li>investigated Xen and QEMU/KVM tracing facilities, and confirmed they can provide what I want to know (I will try them later) https://blog.xenproject.org/2012/09/27/tracing-with-xentrace-and-xenalyze/ http://www.linux-kvm.org/page/Perf_events http://vmsplice.net/~stefan/stefanha-tracing-summit-2014.pdf</li>
<li>Started implementing an automation framework of the network performance evaluation</li>
<li>Completed rough implementation design and checking other software required</li>
<li>I will implement it next week</li>
</ul>
<h4 id="olivier-nicole-5">Olivier Nicole</h4>
<ul>
<li>Remove &quot;zero&quot; placeholders for other-phase values in the lambda code. This took me most of the week, as I had to phase information to <code>Path.t</code>, but also to <code>module_coercion</code>s. This modification should avoid over-approximating the static dependency tree as is currently the case. Currently, every run-time dependency is a static dependency. Since static dependencies must be compiled before there parent in the tree can be compiled, this limitation would break most OCaml projects. I expect this work to be finished, I'll do the tests later tonight.</li>
<li>Talked with Leo about linking and side effects. Maybe, at some point, it will be necessary to ban the <code>static</code> keyword, unless the effect system is integrated into OCaml soon enough.</li>
<li>In addition to switching the quoting library to producing lambda code, it would be good to detect scope extrusion. This would be done by passing <code>CamlinternalQuote.Var.t</code> to macros, instead of the current <code>Longident.t loc</code>.</li>
<li>Note for later: rename <code>CamlinternalQuote.Ident</code> to <code>CamlinternalQuote.Global</code> and move <code>lfrommacro</code> to <code>Exp</code>.</li>
</ul>
<h4 id="liang-wang-35">Liang Wang</h4>
<p>Sorry for the late email this time, I was travelling on Friday. For the last week, I had been only focusing on the N-dimensional array in Owl.</p>
<ol type="1">
<li><p>I implemented the first version of N-dimensional array, atop of which, I also implemented a N-dimensional view module which can pipeline some operations on the array to speed up the performance.</p></li>
<li><p>I later find a better way to further optimise the performance of ndarray by using blas/lapack library. I am currently rewriting some code for better performance.</p></li>
</ol>
<h3 id="week-47">Week 47</h3>
<h4 id="qi-li-20">Qi Li</h4>
<p><em>Magnus is interesting in spending a day a week contributing to the MirageOS and DataBox efforts, specifically around the work he has already done on Jitsu, ARM and networking. He will spend Wednesdays in the Lab around the standup time and work with Qi on the new Alpine xen-arm-builder distribution, to get it up to speed. He is also working on mirage-vnetif and testing of the network stack.</em></p>
<ul>
<li><p>before Wednesday, run the system prepared for UCN final review to make sure it works, worked out the serial output from cubie so that without a vga screen we could still have a prompt to do the work, made SD card copies</p></li>
<li><p>from Wednesday on, in Portugal, for the UCN final review, discovered that both the original card and the copy were corrupted because of some last second invalid writes crossing partition boundaries on the card, panicked, put up something mimicking the behaviour of PIH to make sure our partners' demos could still run, since in the schedule, we wouldn't demo anything, it's just our collaborators using our platforms, then the review seemed going well...</p></li>
</ul>
<h4 id="takayuki-imada-41">Takayuki Imada</h4>
<ul>
<li>Completed building my MirageOS/Solo5 environments in Japan</li>
<li><p>they are operating perfectly.</p></li>
<li>Investigating and trying to execute existing network programs on MirageOS</li>
<li>found arp and iperf implementation, but found out they cannot use with the latest MirageOS branch (mirage-dev) due to rapidly changing MirageOS APIs</li>
<li>modifying their source codes: arp : modification finished and worked correctly iperf: under modification, network connection and data transfer were OK but a result printing part was wrong</li>
<li><p>I will move to learning of performance profiling on MirageOS after finishing the iperf modification</p></li>
</ul>
<h4 id="liang-wang-36">Liang Wang</h4>
<ol type="1">
<li><p>I kept working on the P2P engine, and I implemented a distributed LDA atop of P2P engine in my data processing framework. I spent about two days in debugging it and finally managed to make it work.</p></li>
<li><p>I had a meeting with Mort to refine our thinking on the data framework and identified a couple of interesting research questions: barrier control, and model consistency.</p></li>
<li><p>I had a couple of meetings with those who are interested in owl and identified some potential directions: more advanced support for multi-dimensional array, and auto gradient derivation functions. I will focus on these two and try to get them ready by the end of this year.</p></li>
<li><p>I wrote a separate post for using owl to manipulate matrices, in case you didn’t notice before, here is the link: https://github.com/ryanrhymes/owl/wiki/Manipulate-Matrices-in-Owl</p></li>
</ol>
<h3 id="week-46">Week 46</h3>
<h4 id="qi-li-21">Qi Li</h4>
<ul>
<li><p>Finished porting to the Alpine system, now our PIH system is running on Alpine based cubeietruck full time. This involved putting the data persistence service and web interface for the end user into a debian-based domU.</p></li>
<li><p>Figured out and fixed various bug (well, at least temporarily), mainly about PIH-bridge. This part works like a Network Address Translation device, which is doing traffic relays between clients and data holding unikernels. It will keep using up its own port numbers on its network interfaces if there is no proper &quot;garbage collection&quot; for the port numbers. This bit became a problem when our collaborators started testing there demos against our PIH, where lots of connections would be involved. Indeed, to make it more robust, we have to address this problem. For the time being, each translation rule has its own lifetime(5 min for now), and a queue is maintained in memory to hold these rules, once the number of rules reaches a threshold(30_000 for now), a function will be invoked to clear out all expired rules.</p></li>
</ul>
<h4 id="takayuki-imada-42">Takayuki Imada</h4>
<ul>
<li>Made a list of functionality in existing networking software and hardware for virtualised environments.</li>
<li>both Netmap and DPDK have a similar approach (software-based packet switching, userspace packet processing)<br />
</li>
<li><p>using SR-IOV VFs is difficult to apply to some situations (for example, combined with DPDK on ARM) So I will conduct performance evaluation of the current implementation to understand which part is a bottleneck</p></li>
<li>Preparing for the performance evaluation for the coming MirageOS v3 release</li>
<li>I will be engaged in network related topics.</li>
<li><p>I have started building a MirageOS/Solo5 testbed (in Japan) to easily move to the actual evaluation in a local environment. I will learn and test Mirage-related operations on the testbed in advance</p></li>
</ul>
<h4 id="olivier-nicole-6">Olivier Nicole</h4>
<p><strong>Monday (2016-11-14)</strong></p>
<p>Specification of macro closures: the result of translating a macro into lambda code should be:<br />
* if the target phase is 1: the code of the macro itself;<br />
* if the target phase is 0: the closure, i.e. a block containing pointers to the cross-stage, phase-0 identifiers used in the macro's body.</p>
<p>Unrelatedly: discovered a bug in our early form of CSP. This &quot;weak&quot; CSP enabled the programmer to quote non-global identifiers <em>if</em> the quote was &quot;trapped&quot; inside a top-level splice. The current implementation is faulty, as it allows to quote simple identifiers like <code>y</code>, but not compound paths like <code>M.y</code>, e.g. the following does not work:</p>
<pre><code>  # module M = struct let y = 42 end;;
  (seq
    (apply (field 1 (global Toploop!)) &quot;M/1388&quot;
      (pseudo //toplevel//(1):11-32 (makeblock 0 0)))
    (makearray[addr]))
  (apply (field 1 (global Toploop!)) &quot;M/1388&quot;
    (let (y/1389 =[int] 42)
      (pseudo //toplevel//(1):11-32 (makeblock 0 y/1389))))
  module M : sig val y : int end
  # let x = $(&lt;&lt;M.y&gt;&gt;);;
  &gt;&gt; Fatal error: No global path for identifier
  Fatal error: exception Misc.Fatal_error</code></pre>
<p>Although this early form of CSP should be made redundant by path closures, I note this here for future reference. Improved printing of macros in signatures (<code>macro</code> instead of <code>static val</code>).</p>
<ul>
<li><p>Tuesday<br />
Generation of <code>Lfrommacro</code> identifiers by macro expansion works. Now working to make the type-checker handle <code>Lfrommacro</code> properly. Quite nicely, there is no need to add a constructor to the <code>Path.t</code> type, since <code>Path.Pdot</code> already has an integer field that can be used to represent closure fields. Also, the compiler now shows the results of splicing when the options <code>-dsource</code> or <code>-dparsetree</code> are set.</p></li>
<li><p>Wednesday<br />
Note: when modifying <code>CamlinternalQuote</code> it might be necessary to do <code>make   install</code> to have the changes taken into account in <code>Translquote</code>, since <code>Translquote</code> loads <code>^CamlinternalQuote</code> from the standard path unless otherwise specified.<br />
First examples with path closures working. Deactivated all warnings during compilation of splices.<br />
Nested macros now work as well.</p></li>
<li><p>Thursday</p></li>
</ul>
<p>Fix quoting of identifier so that globals are spliced as <code>Lglobal</code>. That incidentally fix the issue with compound paths (see Monday). Fix bug with macro numbering that would trigger segfaults when mixing macros and the <code>include</code> keyword. Replace previous warning deactivation with something cleaner. Discovered a bug in the REPL that raises problems with values that exist in two phases (i.e. currently, macros and modules that contain static values). The current mechanism is:<br />
1. The static lambda is compiled and executed and its result is stored in the global map of the REPL via <code>Toploop.set_value</code><br />
2. The run-time lambda of the same phrase is compiled and executed and its result is stored in the same place, thus erasing the previous result.<br />
This is fine for entirely static or entirely run-time values, because they are &quot;associated&quot; an identifier in one phase only. But it makes macros and two-phase modules unusable.<br />
To fix that, it was sufficient to split the global map by phase (just as what has been done with the symtable).<br />
I also ran the test suite and after a few minor fixes all tests are successful. There is not yet a proper testing of path closures though. Added a string component to <code>Lfrommacro</code> to print the name of field (along with its position) in a macro closure, for debugging and clarity purposes. The drawback is that it exposes internal names that depend on the implementation and might confuse the user.</p>
<ul>
<li>Friday<br />
Talked with Leo about future plans.<br />
Banned quoting from outside of macros and splices. As a direct consequence, turned <code>Expr.of_*</code> functions into macros.</li>
</ul>
<h4 id="liang-wang-37">Liang Wang</h4>
<p>For this week, I have been focusing on the development of the data processing framework. I have done the following things:</p>
<ol type="1">
<li><p>I implemented a very simple DHT for the framework.</p></li>
<li><p>I finished the first version of peer-to-peer model parallel engine, on top of which I also implemented a SGD algorithm.</p></li>
</ol>
<p>Besides these, not much, the P2P model turned out to be much more complicated than the map reduce and parameter server models. Currently, I am focusing on the barrier control implementation in the framework.</p>
<h3 id="week-45">Week 45</h3>
<h4 id="qi-li-22">Qi Li</h4>
<ol type="1">
<li><p>Working with sys-admin to set up the PIH service to our external collaborators.</p></li>
<li><p>Bumping into some bug in the MirageOS TCP/IP stack, only until yesterday did I be able to locate it , will try to fix it and issue a PR on github later</p></li>
<li><p>Continuing porting some services to Alpine based system. For now, the service accessible to the partners are running on a Debian based system. The binaries for unikernels were easy to deal with, but there are some parts need some dynamically linked libraries, I tried different ways: statically link these libraries; porting these parts together with the libraries; altering the unikernel's implementation to get rid of these parts. For now, I'm settling with the last solution, but I think I would try the <code>porting with libraries</code> later, case the bug in &quot;2&quot; made me think that solution wouldn't work initially. Since I'm not very familiar with the building tools (especially with the linking phase), I think the first solution will cause me more time.</p></li>
</ol>
<h4 id="takayuki-imada-43">Takayuki Imada</h4>
<p>What I have done in the recent weeks is as follows; - Finish reading (and testing codes in) Real World OCaml which will be related to my research topic - Investigated how MirageOS boots up on Xen by reading the MirageOS and mini-os source codes, and understood how OCaml based modules and the mini-os part in MirageOS interact - Started reading papers, documents, and source codes of Netmap and DPDK networking frameworks to consider how I can taking advantages of them in implementing my network acceleration feature on MirageOS</p>
<h4 id="olivier-nicole-7">Olivier Nicole</h4>
<ul>
<li><dl>
<dt>Monday (2016-11-07)</dt>
<dd>Laptop still in repair, spent all day trying to get a desktop PC as a replacement. Will use one of the lab shared computers from now on.
</dd>
</dl></li>
<li><dl>
<dt>Tuesday</dt>
<dd>Added a new <code>value_kind</code> for macros and made the typechecker tag macros with it.
</dd>
</dl></li>
<li><dl>
<dt>Wednesday</dt>
<dd>Stopped keeping track of cross-stage identifiers in the typing environment. Instead, iterate through the typed tree to find them in a expression when needed.<br />
During the Compiler hacking event at Pembroke, paired with Maxime to work on signatured opens (https://github.com/ocamllabs/compiler-hacking/wiki/Things-to-work-on#signatured-open-command); we're about halfway through it.
</dd>
</dl></li>
<li><dl>
<dt>Thursday</dt>
<dd>Add support (parser and typechecker) for macros in signatures.
</dd>
</dl></li>
<li><dl>
<dt>Friday</dt>
<dd>Add a closure argument to macros, yet unused.
</dd>
</dl></li>
</ul>
<h4 id="liang-wang-38">Liang Wang</h4>
<ol type="1">
<li><p>I realised the first version of Owl to OPAM with the help of others, also included it in the MirageOS documentation.</p></li>
<li><p>I started shifting more efforts back to the distributed data processing framework. I rewrote the part of the data parallel and model parallel engine and wrapped them into a separate core module. On top of that, I implemented the one stochastic gradient decedent algorithm using model parallel engine.</p></li>
<li><p>I have been investigating the Latent Dirichelet Analysis model and identified some potential research questions. Me and mort met the student (Ben Caterall) who will work with on his part III project. He will also contribute to Owl.</p></li>
<li><p>I also implemented a simple LDA model using Owl, I hope Ben and me together can make a topic module for Owl.</p></li>
</ol>
<h3 id="week-44">Week 44</h3>
<h4 id="qi-li-23">Qi Li</h4>
<ol type="1">
<li><p>Measure the performance of PIH-gatekeeper(infrastructure within UCN), mainly the operation latency when serving clients' requests. As there are different branches based on the validity of client certificate and/or the right to access a data holding unikernel, accordingly there are different scenarios where the PIH-gatekeeper need to be measured against.</p></li>
<li><p>As mort successfully updated the dom0 OS from Debian-based to Alpine earlier last week, I started to port the system to the new platform. The out-of-box SDcard image has insufficient storage space assigned for dom0, I can't install required tools/libraries in it, then I started to rebuild one image which has larger persistent storage space.</p></li>
</ol>
<h4 id="liang-wang-39">Liang Wang</h4>
<ol type="1">
<li><p>I have optimised the performance of sparse complex matrix module. Many operations are much faster than before now. I think this module is mostly done.</p></li>
<li><p>I have implemented a module for Fast Fourier Transforms with basic operations. I still need some time to finalise this module next week.</p></li>
<li><p>I start writing up some documents to prepare for an opam release in the following weeks.</p></li>
<li><p>I start allocating more time on the distributed data processing framework again this week. The progress on this was slow due to the distraction from Owl.</p></li>
</ol>
<h3 id="week-43-1">Week 43</h3>
<h4 id="takayuki-imada-44">Takayuki Imada</h4>
<p>My research topic - Started learning OCaml, and finished installation of OCaml on my laptop. - Completed the chapter 1 of Real World OCaml and now following the chapter 2 - Felt I need to have a flexible mind to understand the OCaml language expression.</p>
<p>Others - Arrived at Cambridge 16th Oct. - Found my long term flat and I will make a contract with a landload in this weekend. - Still setting up IT services (e-mail address, lab network, printer/scanner).</p>
<h4 id="liang-wang-40">Liang Wang</h4>
<ol type="1">
<li><p>I have implemented complex number support in Owl. The Dense module now have two submodules: Real and Complex which support dense matrices of real number and complex number respectively.</p></li>
<li><p>I also split the current Sparse module into two parts to support both real and complex sparse matrices. The real number is already supported but the complex number support in Sparse module is still missing.</p></li>
<li><p>I removed the dependency on Ctypes.Foreign module in Owl and change completely to stub generation as suggested by Yallop. So the interface to GSL is supposed to be faster and type safer.</p></li>
<li><p>I tested using functor to generalise some matrix operation, it worked fine but caused some performance penalty in certain operations that I am still trying to figure out the reason.</p></li>
<li><p>I gave a pitch of my kvasir project last night in Petershouse last night, since it entered into Cambridge Enterprise Business Plan competition. However, I didn’t win the first prize in the end but nice experience and received a lot of publicity.</p></li>
</ol>
<h3 id="week-42-1">Week 42</h3>
<h4 id="olivier-nicole-8">Olivier Nicole</h4>
<ul>
<li><dl>
<dt>Monday (2016-10-24)</dt>
<dd>Still tracking that bug. The facts are the following: the program segfaults when trying to dereference a <code>code_t*</code> pointer. The value of this pointer has been set by the instruction <code>PUSHGETGLOBAL Pervasives, 48</code>. The fact that this instruction was executed without segfault shows that accessing the field labelled <code>Pervasives</code> (at that moment) is not an issue. What is an issue is the value of field 48. Ok, so the problem is that the slot 41, corresponding to <code>Pervasives</code>, is erased. So an invariant has been violated. I understood what the problem is, it's actually very simple: I've tried to execute bytecode (using <code>reify_bytecode</code>) with a fresh symtable. But that resulted in the erasing of the compiler's global data in <code>Symtable.update_global_table</code>. So it can be stated that: &quot;to execute bytecode directly, the symtable needs to be shared between the executer and the executed&quot;. This bug was introduced by the change I made last Thursday, when I turned an <code>init_static</code> in <code>Runstatic</code> into <code>init</code>. I did that for the sake of bootstrapping, which otherwise would fail with an <code>Undefined global</code> error on a built-in exception.
</dd>
</dl></li>
<li><dl>
<dt>Tuesday</dt>
<dd>The bug was fixed, along with a few others (see commits for details), and all the tests are passed again.
</dd>
</dl></li>
<li><dl>
<dt>Wednesday, Thursday, Friday</dt>
<dd>Spent some time working on a staged regular expression matcher, to try macros in a &quot;real-world&quot; situation. I simply staged a very simple, higher-order representation of regular expressions with continuations. It allowed for some compile-time optimizations like: <sub>~</sub> # static f = compile @@ (lit &quot;John&quot; +.+ lit &quot;Kevin&quot;) <em>.</em> lit &quot; likes apples&quot;;; val f : (str -&gt; bool) expr = &lt;&lt; fun cs_1 -&gt; (cs_1 = &quot;John likes apples&quot;) || (cs_1 = &quot;Kevin likes apples&quot;) &gt;&gt; # static f = compile @@ maybe (lit &quot;A&quot;) <em>.</em> lit &quot;A&quot; <em>.</em> lit &quot;B&quot;;; val f : (str -&gt; bool) expr = &lt;&lt; fun cs_2 -&gt; (cs_2 = &quot;AB&quot;) || (cs_2 = &quot;AAB&quot;) &gt;&gt; <sub>~</sub>
</dd>
</dl></li>
</ul>
<p>The performance is unfortunately quite poor, due to the naiveness of the initial, higher-order algorithm. In particular, the code size for concatenated regexp increases exponentially with the number of regexps. But it has had the merit to demonstrate the tractability of macros, since no problem related to the macro system arose during development.</p>
<h4 id="liang-wang-41">Liang Wang</h4>
<p>This week I have been working on the Plot module in Owl library by adding more basic plotting functions. Currently the Plot module supports many widely used plots. There are still many minor things in the module can be improved, but I will do that slowly in the future. I also wrote a tutorial on how to use the plot module and sent it to the ocamllabs mailing list.</p>
<p>Besides the Plot module, I am also focusing on the Stats module because GSL only provides very basic ones and there are many useful statistical functions are missing. I will implement most of them by myself in OCaml since I do not want to introduce too many dependency in the library. So far, I have implemented z-test, t-test, jb-test, chi2-test, and so on. Based on the feedback, it becomes clearer now that Owl will evolve into a numerical library for OCaml and Matrix, Maths, Stats, Regression, and Plot will be the core modules.</p>
<h3 id="week-41-1">Week 41</h3>
<h4 id="olivier-nicole-9">Olivier Nicole</h4>
<p>: I finished merging branch <code>4.04</code> into <code>macros</code>, but the repo is not functional yet: I get a segfault on <code>utils/clflags.ml</code> when bootstrapping. Strangely, printf-debugging pointed the segfault to happen on a call to <code>open_in_bin</code> inside <code>Bytelink.load_object</code>, although several successful calls have been made to <code>open_in_bin</code> during the execution. This suggests that the global data containing the Pervasives module has been somehow corrupt. * Tuesday<br />
: A lot of time spent fighting with the built system and trying to find the cause of my bug(s), without success. * Wednesday<br />
: Since <code>macros</code> was based on <code>trunk</code>, I shouldn't have used <code>merge</code> to rebase it on <code>4.04</code>, since changes from <code>trunk</code> have been introduced on <code>4.04</code>. In order to rebase macros on <code>4.04</code> without having to resolve conflicts on each commit (which would be necessary to keep the commit history), I had to squash all the macro-related commits into one commit, and cherry-pick that commit onto <code>4.04</code>. * Thursday<br />
: Conflicts solved and <code>.depend</code> files updated. <code>make coreall</code> works but the segfault on <code>open_in_bin</code> is back. What's more, when trying to compile some dummy file with a static printf in it, the compiler segfaults in <code>Symtable.update_global_data</code>, more specifically on the operation: <code>glob.(slot) &lt;- transl_const cst</code> where <code>glob</code> is <code>Meta.global_data ()</code>. I checked, it's not an out-of-bounds segfault. Another segfault I'm currently tracking is on a call to <code>Pervasives.output_string</code> (or <code>output_char</code>, one of the two). * Friday<br />
: Today, meeting with Mort and Anil to check the progress of macros. I need to start writing down ideas of applications. The runtime segfaults on the following line while executing the instruction APPTERM2: <code>pc = Code_val(accu);</code> Where <code>accu</code> has been set by the previous instruction: <code>PUSHGETGLOBALFIELD Pervasives, 48</code></p>
<h3 id="week-40-1">Week 40</h3>
<h4 id="olivier-nicole-10">Olivier Nicole</h4>
<ul>
<li>Monday (2016-10-10)</li>
</ul>
<p>Added static modifiers where appropriate in reference files to fix three <code>parsing/</code> tests. More importantly, fixed <code>bytecomp/bytelink.ml</code> so that <code>std_exit.cmo</code> is linked last, which was not the case until then. Number of failed tests fell to 20.</p>
<pre><code>  Summary:
    577 tests passed
      8 tests skipped
     20 tests failed
      2 unexpected errors
    607 tests considered
  List of failed tests:
      tests/typing-recmod/t19ok.ml
      tests/typing-implicit_unpack/implicit_unpack.ml.reference
      tests/basic-more/testrandom.ml
      tests/typing-recmod/t18ok.ml
      tests/no-alias-deps/aliases.ml.reference
      tests/typing-recmod/t10ok.ml
      tests/typing-modules/aliases.ml
      tests/typing-modules-bugs/pr6572_ok.ml
      tests/ppx-attributes/warning.ml
      tests/translprim/module_coercion.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-gadts/pr6993_bad.ml
      tests/typing-poly/poly.ml
      tests/typing-modules-bugs/pr7182_ok.ml
      tests/typing-recmod/t03ok.ml
      tests/typing-recmod/t16ok.ml
      tests/lib-num
      tests/typing-recmod/t06ok.ml
      tests/match-exception/match_failure.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
      tests/typing-fstclassmod
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<p>Note: the current linker may load/link object files in a different order from that given on the command line. That should be avoided.</p>
<ul>
<li>Tuesday</li>
</ul>
<p>Fix the linker to guarantee that object files are linked in the same order as specified on the command line (provided that the command-line arguments are topologically-sorted). Removed 2 errors.</p>
<pre><code>  Summary:
    579 tests passed
      8 tests skipped
     18 tests failed
      2 unexpected errors
    607 tests considered
  List of failed tests:
      tests/typing-recmod/t19ok.ml
      tests/typing-implicit_unpack/implicit_unpack.ml.reference
      tests/typing-recmod/t18ok.ml
      tests/no-alias-deps/aliases.ml.reference
      tests/typing-recmod/t10ok.ml
      tests/typing-modules/aliases.ml
      tests/typing-modules-bugs/pr6572_ok.ml
      tests/ppx-attributes/warning.ml
      tests/translprim/module_coercion.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-gadts/pr6993_bad.ml
      tests/typing-poly/poly.ml
      tests/typing-modules-bugs/pr7182_ok.ml
      tests/typing-recmod/t03ok.ml
      tests/typing-recmod/t16ok.ml
      tests/typing-recmod/t06ok.ml
      tests/match-exception/match_failure.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
      tests/typing-fstclassmod
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<p>Fixed segfaults by lifting &quot;CamlinternalMod&quot; module name in <code>Translmod</code>, when appropriate. Only 6 failures left, even less than after the last testing session!</p>
<pre><code>  Summary:
    592 tests passed
      8 tests skipped
      6 tests failed
      1 unexpected errors
    607 tests considered
  List of failed tests:
      tests/no-alias-deps/aliases.ml.reference
      tests/translprim/module_coercion.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-poly/poly.ml
      tests/match-exception/match_failure.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<ul>
<li>Wednesday</li>
</ul>
<p>Two other fixes (see commit logs):</p>
<pre><code>  Summary:
    594 tests passed
      8 tests skipped
      4 tests failed
      1 unexpected errors
    607 tests considered
  List of failed tests:
      tests/no-alias-deps/aliases.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-poly/poly.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<p>With the help of Leo, I changed the placeholder for classes in static code to make <code>typing-recmod/t22ok.ml</code> work.</p>
<ul>
<li>Thursday</li>
</ul>
<p>: Managed to fix all the tests (including the unexpected error), see commit logs. Started rebasing on branch <code>4.04</code>.</p>
<ul>
<li>Friday</li>
</ul>
<p>: Mark Shinwell remarked that in the case of a branch with so many changes on it, doing a rebase is extremely long: conflicts need to be resolved on a per-commit basis, and almost all commits trigger conflicts. So I decided to rather do a merge. The merge is at about 30% progress (building and testing not included).</p>
<h3 id="week-39-1">Week 39</h3>
<h4 id="olivier-nicole-11">Olivier Nicole</h4>
<ul>
<li><dl>
<dt>Monday (2016-10-03)</dt>
<dd>With the help of Leo White, I realised that <code>Int_base</code> (see prev. worklog) should not be set to 0 in the static code. So I just removed the related condition in <code>Translmod</code>, and this segfault went away. But doing that incurred new dependencies from files such as <code>utils/numbers.ml</code> to stdlib <code>cmm</code> files. I moved all <code>stdlib/*.cmm</code> files to <code>boot/</code> (as was already done with <code>stdlib/*.cmi</code>) and it seems to do the trick for now. Today's issue arose in the following code: <code>(* this introduces a module `T` in scope *)   include Identifiable.Make (struct (* ... *) end)   module Pair = Identifiable.Make (Identifiable.Pair (T) (T))</code> Causing a <code>Bytegen.comp_expr: var T_1712</code> error.
</dd>
</dl></li>
<li><dl>
<dt>Tuesday</dt>
<dd>Removing another <code>target_phase</code> condition just made it work. It's quite surprising and I am afraid that something might break if I keep applying fixes that I don't understand, but I'm too lazy to take it seriously right now. But bad news: <code>ocamldoc/odoc_args.ml</code> uses first-class modules in way that makes the current way of translating modules go wrong: <code>module Html = (val  (  match !Odoc_args.current_generator with    None -&gt; (module Odoc_html.Generator : Odoc_html.Html_generator)  | Some (Odoc_gen.Html m) -&gt; m  | _ -&gt;  failwith    &quot;A non-html generator is already set. Cannot install the Todo-list html generator&quot; ) : Odoc_html.Html_generator)   ;;</code> Simply translating module unpacking (<code>Tmod_unpack</code>) fixed that one, but it will probably break in certain cases. Warning: phase not taken into account when typing recursive modules in <code>Typemod</code>. (later note: fixed)
</dd>
</dl></li>
<li><dl>
<dt>Wednesday</dt>
<dd>Basic examples with static modules work. And even static functors! How amazing is that! I implemented phase checks for modules, i.e. the compiler raises an error if a module identifier of the wrong phase is used in a functor application or a binding.
</dd>
</dl></li>
<li><dl>
<dt>Thursday</dt>
<dd>Today, I removed all the debug messages printed by the compiler and started to write a test suite for macros. For now it only contains very basic checks related to static values, quoting, splicing and static modules. I also removed the <code>Translstatic</code> module, which had become unnecessery, and moved its contents to <code>Translmod</code>. Doing that enabled me to make the REPL compile static modules (prior to that, they were just ignored). To-do list for the next days:
</dd>
</dl></li>
<li>make <code>ocamlopt</code> work again by fixing <code>Translmod.transl_store_implementation</code>.</li>
<li>run all tests on both compilers to see if anything is broken.</li>
<li>rebase <code>macros</code> on <code>trunk</code> (ouuuuch) and run the tests again.</li>
<li><dl>
<dt>Friday</dt>
<dd>Remark: one day, I will have to harmonize the behaviour of bytecode and native linker. This is not needed for macros to work, but is necessary to have a consistent user interface between the two compilers. <code>ocamlopt</code> compiles again. Testing time! A bunch of tests failed this time: <code>Summary: 551 tests passed   8 tests skipped  46 tests failed   2 unexpected errors 607 tests considered   List of failed tests:   tests/typing-recmod/t19ok.ml   tests/typing-implicit_unpack/implicit_unpack.ml.reference   tests/parsing/shortcut_ext_attr.ml.reference   tests/lib-format/pr6824.ml   tests/lib-format/tformat.ml   tests/lib-printf/pr6534.ml   tests/lib-printf/tprintf.ml   tests/lib-printf/pr6938.ml   tests/basic-more/testrandom.ml   tests/basic-more/tbuffer.ml   tests/basic-more/opaque_prim.ml   tests/utils/test_strongly_connected_components.ml   tests/typing-recmod/t18ok.ml   tests/basic-more/morematch.ml   tests/no-alias-deps/aliases.ml.reference   tests/typing-recmod/t10ok.ml   tests/lib-scanf   tests/typing-modules/aliases.ml   tests/typing-modules-bugs/pr6572_ok.ml   tests/ppx-attributes/warning.ml   tests/basic-more/tformat.ml   tests/basic-more/if_in_if.ml   tests/lib-threads/torture.ml   tests/translprim/module_coercion.ml.reference   tests/basic-more/pr2719.ml   tests/basic-more/top_level_patterns.ml   tests/typing-recmod/t22ok.ml   tests/no-alias-deps/aliases.cmo.reference   tests/typing-gadts/pr6993_bad.ml   tests/typing-poly/poly.ml   tests/parsing/extensions.ml.reference   tests/parsing/attributes.ml.reference   tests/lib-str/t01.ml   tests/basic-more/sequential_and_or.ml   tests/typing-modules-bugs/pr7182_ok.ml   tests/misc/weaktest.ml   tests/typing-recmod/t03ok.ml   tests/basic-more/function_in_ref.ml   tests/typing-recmod/t16ok.ml   tests/basic-more/bounds.ml   tests/lib-num   tests/utils/edit_distance.ml   tests/basic-more/tprintf.ml   tests/basic-more/pr6216.ml   tests/typing-recmod/t06ok.ml   tests/match-exception/match_failure.ml   List of unexpected errors:   tests/lib-dynlink-bytecode   tests/typing-fstclassmod   List of skipped tests:   tests/lib-dynlink-csharp   tests/unwind   tests/asmcomp/is_static_flambda   tests/asmcomp/unrolling_flambda   tests/lib-bigarray-2</code> In comparison, results on the 5th of July were: <code>Summary:   590 tests passed 8 tests skipped 9 tests failed 1 unexpected errors   608 tests considered   List of failed tests:   tests/typing-recmod/t18ok.ml   tests/typing-recmod/t10ok.ml   tests/typing-modules-bugs/pr6572_ok.ml   tests/ppx-attributes/warning.ml   tests/typing-recmod/t22ok.ml   tests/typing-poly/poly.ml   tests/typing-modules-bugs/pr7182_ok.ml   tests/typing-recmod/t03ok.ml   tests/typing-recmod/t06ok.ml   List of unexpected errors:   tests/typing-fstclassmod   List of skipped tests:   tests/lib-dynlink-csharp   tests/unwind   tests/asmcomp/is_static_flambda   tests/asmcomp/unrolling_flambda   tests/lib-bigarray-2</code> By taking the diff, I can see that no errors fixed themselves, and which ones are new: <code>8a9,22   &gt;     tests/typing-recmod/t19ok.ml   &gt;     tests/typing-gadts/pr7230.ml   &gt;     tests/typing-implicit_unpack/implicit_unpack.ml.reference   &gt;     tests/parsing/shortcut_ext_attr.ml.reference   &gt;     tests/lib-format/pr6824.ml   &gt;     tests/lib-format/tformat.ml   &gt;     tests/lib-printf/pr6534.ml   &gt;     tests/lib-printf/tprintf.ml   &gt;     tests/lib-printf/pr6938.ml   &gt;     tests/basic-more/testrandom.ml   &gt;     tests/basic-more/tbuffer.ml   &gt;     tests/basic-more/opaque_prim.ml   &gt;     tests/utils/test_strongly_connected_components.ml   9a24,25   &gt;     tests/basic-more/morematch.ml   &gt;     tests/no-alias-deps/aliases.ml.reference   10a27,28   &gt;     tests/lib-scanf   &gt;     tests/typing-modules/aliases.ml   12a31,38   &gt;     tests/basic-more/tformat.ml   &gt;     tests/tool-ocaml/t330-compact-2.ml   &gt;     tests/basic-more/if_in_if.ml   &gt;     tests/lib-threads/torture.ml   &gt;     tests/translprim/module_coercion.ml.reference   &gt;     tests/basic-more/pr2719.ml   &gt;     tests/basic-more/top_level_patterns.ml   &gt;     tests/typing-extensions/extensions.ml.reference   13a40,41   &gt;     tests/no-alias-deps/aliases.cmo.reference   &gt;     tests/typing-gadts/pr6993_bad.ml   14a43,47   &gt;     tests/parsing/extensions.ml.reference   &gt;     tests/parsing/attributes.ml.reference   &gt;     tests/lib-str/t01.ml   &gt;     tests/typing-warnings/application.ml.reference   &gt;     tests/basic-more/sequential_and_or.ml   15a49   &gt;     tests/misc/weaktest.ml   16a51,59   &gt;     tests/typing-gadts/pr5906.ml   &gt;     tests/basic-more/function_in_ref.ml   &gt;     tests/typing-recmod/t16ok.ml   &gt;     tests/basic-more/bounds.ml   &gt;     tests/lib-num   &gt;     tests/typing-gadts/pr7269.ml   &gt;     tests/utils/edit_distance.ml   &gt;     tests/basic-more/tprintf.ml   &gt;     tests/basic-more/pr6216.ml   17a61   &gt;     tests/match-exception/match_failure.ml   19a64   &gt;     tests/lib-dynlink-bytecode</code> Several failures seem due to include path problems, causing <code>Unbound modules</code> errors.
</dd>
</dl></li>
</ul>
<h3 id="week-33-1">Week 33</h3>
<h4 id="romain-calascibetta-31">Romain Calascibetta</h4>
<ul>
<li>I continue to work on a prototype of ocaml-git. I just finished the decoder for the IDX file, I will try the implementation next week.</li>
<li>I continue to document MrMime - Richard showed me some emails when MrMime fails. These emails are wrong and the thing is, if you use MrMime by the best effort way, you can extract all information from the email, so MrMime can parse these email by the hard way - not the simple way.</li>
</ul>
<h3 id="week-32-1">Week 32</h3>
<h4 id="romain-calascibetta-32">Romain Calascibetta</h4>
<ul>
<li>I continue to document MrMime, you can see the documentation at this link: http://oklm-wsh.github.io/MrMime/ (not very exciting)</li>
<li>I started a new prototype for ocaml-git, the name is sirodepac, you can see the reopository at this link: https://github.com/dinosaure/sirodepac For the sirodepac, the goal is to created a non-blocking encoder/decoder. So, Thomas follows the project and it's works for the moment despite some little bugs.</li>
</ul>
<h4 id="ciaran-lawlor">Ciaran Lawlor</h4>
<p><strong>Monday + Tuesday</strong></p>
<p>Rewrote the lexer and parser to be able to understand more about the input, i.e. whether it's a positional arg, flag or optional arg etc. This also requires that the parser have access to the commands and their arguments so that required some more rewriting. This information can then be used for both predictions and syntax highlighting. It's also easier to extend. Parsing optional arguments is tricky because it means the next positional value might actually be their value. Quite a few edge cases, and haven't added support for a few widely used conventions like using -- to denote that the next value is a positional value, or using = when specifying values.</p>
<p><strong>Wednesday</strong></p>
<p>Working on making predictions better using the additional information. Quite a lot of cases. Just doing the basic ones for now. Flags only need their name predicted. Non flags need their name predicted but can also predict their value. Positional arguments can be predicted based on their index. Not working yet for optional arguments. Also not working for some other edge cases.</p>
<p><strong>Thursday</strong></p>
<p>Added syntax highlighting by traversing the raw input and the syntax tree together. Some more work on prediction. Refactoring and separating out modules.</p>
<h3 id="week-31-1">Week 31</h3>
<h4 id="enguerrand-decorne">Enguerrand Decorne</h4>
<ul>
<li>Worked on the ocaml-tls binding: Fixed a few memory leaks problems. Tried to run spacetime against the binding, to no avail Tried to run landmarks against the binding: not much success too.</li>
</ul>
<h4 id="romain-calascibetta-33">Romain Calascibetta</h4>
<ul>
<li>I talked with Christophe about the optimization, I have not yet advised Jeremy about the benchmark but I keep this thing when Jeremy will try to optimize Decompress</li>
<li>I move Decompress to topkg because Anil wanted a Dockerfile inside the project</li>
<li>Richard retested MrMime and I fixed some bugs and optimized some computations. Now, we compute 180 mails per second and MrMime fails on 500 emails with 815 000 emails! So it's not bad, we will fix the rest with Richard when he comes back</li>
<li>I fixed a little bug for Qi Li on the Xen librairies</li>
<li>I continue to document MrMime</li>
<li>And I looked inside ocaml-git to understand where I need to start but I does not do revelant something for the moment.</li>
</ul>
<h4 id="ciaran-lawlor-1">Ciaran Lawlor</h4>
<p><strong>Wednesday</strong></p>
<p>Current state of the shell: - Commands work, but I haven't actually added most of the commands. E.g. connecting doesn't actually work as it's asynchronous, so using Lwt throughout is top priority. - Tab completion doesn't really work. It kind of did at one point, but I've changed quite a lot of stuff since then. Should be fairly easy to get working again though. - Parsing the input works mostly fine, handles quotes / strings, allows escaping etc. - Notty interface now works, which means I can continue using Notty, but it isn't perfect.</p>
<h3 id="week-30-1">Week 30</h3>
<h4 id="joel-jakubovic">Joel Jakubovic</h4>
<p>Discussed with KC some interesting ideas I've been having related to making GUI programming less painful. Possible direction for Part II research. I need to investigate the existing literature and write up a brief explanation of what I'm looking at. Also, in the context of this summer, need to see if I can integrate it with the work I'm doing at Docker / OCaml Labs. KC suggested working on same as Ciaran: build 9P client, to develop these principles and test them.</p>
<p>Summary:</p>
<ul>
<li>Motivation comes from building games, where the rule is reinventing the GUI wheel every time.</li>
<li>GUIs are systems of lots of interacting components. Difficult to code and organise.</li>
<li>Immediately tied up with graphics and layout: naive, ad-hoc solutions based on fixed, pixel coords and sizes commonplace.</li>
<li>Want graphical systems that automatically adjust to different constraints eg window shape/size.</li>
<li>iOS uses Cassowary constraint solver... potentially solved problem, but need expertise in linear prog / optimisation to implement...</li>
<li>The other broad problem area: specifying interaction.</li>
<li>Java Swing approach: add event listeners to everything. Asynchronous imperative programming: not scalable with complexity.</li>
<li>Reinventing for Game N: take similar approach. Sick of it</li>
<li>My ideas: related to DSLs, formal languages, grammars, parsers.</li>
<li>Fundamental hypothesis: Parser generators convert language specs into parsers - state machines which accept / reject (and, structure) linear sequences of tokens. Usually thought of as text, but my insight is this: the inputs (mouse, keyboard) that the user submits to an interface are a just such a linear sequence; simply in the time dimension. What if: when we write horrible imperative Java Swing ActionListeners, we are actually painstakingly and unwittingly constructing, by hand, the state machine for a parser of the UI's language? And if so, could it be easier to write UIs as formal grammars of some sort, and then automatically generate the parser (application code) from them? Just as you would enlighten a newbie to CS who has not heard of grammars and who writes all their parsing code in an ad-hoc manner. And furthermore - how useful would it be to view ALL programs (of the sort that depends on inputs from the outside world) as parsers - the language-vs-machine view; elaborate on the fact that, when we slog through the imperative state code for Turing machines, we're dually writing parsers for their [recursively enumerable] languages.</li>
<li>In one sense, a command-line utility that adds numbers together doesn't just do that - rather, it takes a bunch of characters from the command line and spits out more characters, which happen to correspond to numbers in a particular way.</li>
<li>Final facet: the principle of compositionality and abstraction. Context-free grammars; their benefits and limitations. Embedding semantics / context-sensitivity into grammars. CFGs let you elaborate in a top-down manner.</li>
</ul>
<h4 id="romain-calascibetta-34">Romain Calascibetta</h4>
<ul>
<li>I just improved (again!) the interface of MrMime:</li>
<li>So the design of the API is approved by Daniel and I wait a feedback of Richard to know if we will release a new version or not</li>
<li>After, I did go to docker to meet Thomas and prepare a TODO list for ocaml-git. Now, I have a clear idea to what I need to do for this project.</li>
</ul>
<p>Not a big week so, but a good week to clarify some points about MrMime and ocaml-git.</p>
<h4 id="ciaran-lawlor-2">Ciaran Lawlor</h4>
<p><strong>Monday</strong> - Rewrote a lot of the code as I was using quite a bit of mutable state. For example, using an array to store the current input. Now storing it as two int lists (ints as characters are unicode), the first representing the input before the cursor (stored in reverse), and the second representing the input after the cursor. Lots of other changes as well. <strong>Tuesday</strong> - Some more rewriting. Code a lot terser and almost no mutability. - Managed to get Notty working with scrolling etc by disabling canonical mode myself then passing the input from stdin into the notty module to filter escape sequences. A bit of a hack but it means I can use notty and have proper scrolling etc, and don't have to redraw everything each time. - Still a few things that are only half working. For example tab completion is kind of there but not actually 'wired up'. <strong>Wednesday</strong> - Not much to log, just starting to get the shell working with ocaml-9p, rather than just the couple of small examples I've been using so far. - I've written the shell to be synchronous at the moment, which won't work well with things like ocaml-9p, so I'm going to change it to use Lwt throughout.</p>
<h3 id="week-29-1">Week 29</h3>
<h4 id="romain-calascibetta-35">Romain Calascibetta</h4>
<ul>
<li>I finished fixing some bugs with Decompress, so we have a stable version after many optimization. As I explained, we don't have a big improvement on the performance but Jeremy will take the relay</li>
<li>After Richard focused me on a performance problem in MrMime, so I fixed the bug. It's a technical point bug I wait Richard to launch an other test</li>
<li>I started a little library to see any differences between an email before and after decoding/encoding, I think, I will finish this mini-project this week-end - and may be it's a useful project for irmin</li>
</ul>
<h4 id="olivier-nicole-12">Olivier Nicole</h4>
<ul>
<li>Macro support has been implemented in <code>ocamlc.opt</code> (bytecode compiler running on the native back-end), after various bug corrections. The execution of macros is as follows:<br />
</li>
</ul>
<ol type="1">
<li>static code is compiled to bytecode and written to a temporary <code>.cmm</code> file<br />
</li>
<li>that <code>.cmm</code> file is linked with its dependencies to make a temporary bytecode executable<br />
</li>
<li>using <code>Sys.command</code>, <code>ocamlrun</code> is called on that file. The executable runs and writes the top-level splices to the file passed as a command-line argument.<br />
</li>
<li>The untyped parse trees are unmarshalled and spliced into the run-time code.</li>
</ol>
<ul>
<li>I pushed further the idea of HTML templates using the Markup.ml library. An example of a code that can be run (and that includes run-time strings in the template) is:</li>
</ul>
<pre><code>open Markup
open Htmltemplate
let par =
  Printf.printf &quot;Please enter a string: &quot;;
  read_line ()
let () =
  $(template [Lit {|
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
      &lt;head&gt;
        &lt;title&gt;Some page&lt;/title&gt;
      &lt;/head&gt;
      &lt;body&gt;
        &lt;h1&gt;Some page&lt;/h1&gt;
        &lt;p&gt;|}; Var &lt;&lt;par&gt;&gt;; Lit {|&lt;/p&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  |} ])
    |&gt; of_list |&gt; pretty_print |&gt; write_html |&gt; to_string
    |&gt; print_endline</code></pre>
<p>The HTML tree is constructed statically, entailing no parsing costs at run-time. The next step is to convert the Markup.ml tree to a TyXML tree to have the typechecker enforce the validity of the HTML tree.</p>
<h4 id="ciaran-lawlor-3">Ciaran Lawlor</h4>
<p><strong>Monday</strong> - Experimenting with Notty to make the shell interactive, for things like tab completion. - Notty doesn't seem to support applications that aren't full screen terminal when capturing key presses. For example utop allows tab completion while still being scrollable. Notty generally seems to be more for graphics. lambda-term should support this but also has a lot of stuff that I probably don't need. - Notty also doesn't appear to clean up the terminal after ctrl + c, leaves mouse interaction on etc. And ctrl c can't be intercepted. - Actually it does allow capturing scrolling events and mouse position, so maybe I can implement scrolling manually instead, but not ideal.</p>
<p><strong>Tuesday</strong> - Would be good to handle unterminated input - e.g. if string doesn't have a closing quote or if the line ends in a backslash then go to the next line. Requires some support in the lexer. - Notty assumes unicode throughout so I will too. Supporting unicode by storing input as an int list and using that when lexing and printing back to the terminal. - I'm currently lexing and parsing the entire input on each keystroke, as I need to know the meaning of the input to be able to do prediction. Not really ideal but usually commands are so short that it might not matter. I might have a go at making it more efficient anyway.</p>
<p><strong>Wednesday</strong> - I spent today trying to figure out a better way of supporting completions by trying to only lex the part of the input that changes and swap out the affected tokens. I got it sort of working but it was buggy and had lots of mutable state so I gave up on it, at least for now.</p>
<p><strong>Thursday</strong> - Notty will only capture input events when using a single screen (not scrollable) terminal application, so using print doesn't work as it's quickly overwritten when redrawing the screen. This would be fine as I could just return a string and handle printing elsewhere, but as a lot of the stuff with ocaml-9p is asynchronous I might want to print during executing the command to let the user know what's happening. Which means I might have to take another look at Lambda-term. - In terms of supporting completions, I had a look at Cmdliner as it parses the arguments and automatically checks if an arg is a file or an int etc, which would be useful information for prediction. Would be cool to be able to pass the Cmdliner data to this shell and have prediction done automatically, but unfortunately not really possible. - I can add a small amount of stuff to add prediction to an existing program that uses Cmdliner (or something else). Basically just two functions (one for named args and one for positional args) that map a prefix to a list of possibilities.</p>
<p><strong>Friday</strong> - Got most things working together today, commands now work properly. Still haven't actually got the actual interface working yet though...</p>
<h4 id="philip-dexter">Philip Dexter</h4>
<p>Automatic perforation is coming to the point where it could be ready for more users. I have slowly started to focus on providing a good user interface.</p>
<p>This week I ran my auto perforation tool on two sets of inputs for kmeans with the goal of showing that results from a run of the automatic perforation program can be used to approximate further inputs. That is, running kmeans with the automatic perforator gives you a result on how to best perforate your loops. Using this result with future data sets previously unseen gives you just as good results. For this experiment I trained the perforation using 10 inputs with 100,000 points. I then ran the resulting perforated program on 10 other inputs of 1,000,000 points and achieved very similar results (a 5x speedup with only a 10% loss in accuracy).</p>
<p>This week I've written a blog post about the troubles with writing generic approximate computing frameworks (found at: http://phfilip.com/the-difficulty-in-a-general-approximate-computing-framework.html)</p>
<p>This week I've also discussed with KC at lengths about a use-case of approximate computing. The general idea is to add approximate reasoning to programs which work over distributed key-value stores. Programs in this domain are usually already written to handle consistency anomalies. The addition of a dynamic system to track and handle the levels of approximation could be a good fit for my approximate computing work.</p>
<h3 id="week-28-1">Week 28</h3>
<h4 id="joel-jakubovic-1">Joel Jakubovic</h4>
<p><strong>Monday</strong></p>
<p>Setting up Angstrom: I follow the readme instructions, ignoring the initial opam install as the package is not yet released.</p>
<p><code>opam pin add -n angstrom .   opam install --deps-only angstrom</code></p>
<p>Which goes fine.</p>
<p>I want to use vim to explore the source but it complains that it doesn't have alcotest, so I fix that:</p>
<pre><code> opam install alcotest
  [...]
  Building fmt.0.8.0:
  ocaml pkg/pkg.ml build --pinned false --with-base-unix true --with-cmdliner true
  Installing fmt.0.8.0.
  [ERROR] &#39;pinned&#39; has type bool, but a env element of type string was expected`</code></pre>
<p>Messing around with versions settles on alcotest.0.4.1 as one that works. I run the config and make commands without incident.</p>
<p>Spent the rest of the day surveying Angstrom, OCaml internals and practising more Vim.</p>
<p><strong>Tuesday</strong></p>
<p>Wrote simple test parser for balanced parentheses using Angstrom. Went surprisingly smoothly - my previous experimentation with parser combinators and monads earlier in the year has clearly paid off.</p>
<p>Wrote initial version of ANSIparse - first test results in out-of-memory from infinite loop somewhere. !!</p>
<p>Rewrote the grammar and the code, still need to rewrite testing code and do the tests.</p>
<p><strong>Wednesday</strong></p>
<p>Continued rewrite a few times. Became apparent during testing that I had misread the format codes and fixed that. Got a working parser from string -&gt; (style list * string) list, eg</p>
<pre><code>`&quot;Hello, \x1b[1mBrave, \x1b[4;31mNew \x1b[0mWorld!&quot;`

to

`[ ( []                    , &quot;Hello, &quot; );
  ( [Bold]                , &quot;Brave, &quot; );
  ( [Underline; Fore Red] , &quot;New &quot;    );
  ( [Reset]               , &quot;World!&quot;  ); ]`</code></pre>
<p>Now I need to work on the structuring, i.e. converting to HTML. There is already implicit structure; (styles, str) :: rest applies styles in order to str AND, implicitly, rest. However, the presence of Reset turns things off. I wonder how useful it would be to try and extract some tree structure from this data by e.g. matching styles and Resets.</p>
<p><strong>Thursday</strong></p>
<p>Today, worked on making the parser incremental, in that it works a line at a time given its intended use. Ran into some more unpleasant infinite-loop bugs; one of which was of the form</p>
<pre><code>`Items --&gt; Item*
Item --&gt; Escape | Text
Text --&gt; char*`</code></pre>
<p>So we can derive &quot;HELLO&quot; as</p>
<pre><code>Items --&gt; Item* --&gt; Text* --&gt; Text --&gt; &quot;HELLO&quot;, or
Items --&gt; Item* --&gt; Text* --&gt; Text Text* --&gt; &quot;HELLO&quot; &quot;&quot;, or &quot;HELLO&quot; &quot;&quot; &quot;&quot;, etc... and never finishing</code></pre>
<p>So I had to add lookahead whereby the parser for Text fails if it will read the empty string (because it's at the end of input).</p>
<p><strong>Friday</strong></p>
<p>Split into concrete (text) and abstract (tree) modules for later use. Had a look at TyXml.</p>
<h4 id="romain-calascibetta-36">Romain Calascibetta</h4>
<ul>
<li>I push my big change to MrMime, so Richard launched a test with ~18 000 emails and all emails are ok (we catch no error).</li>
<li>We find a performance problem (with the multipart and the quoted-printable encoding) but it's a specific problem (so when I have a time, I will fix this problem)</li>
<li>But, overall, MrMime is more faster (it's the result of improvement of internal buffer)</li>
<li>After, I worked on Decompress and I defunctorized the project, I optimized the translation between op-code and character and I avoided some closures allocations, but, with all this point, with Jeremy, we can't notice any imrpovement :disappointed:</li>
<li>So, I will try a deforestation of Decompress and we will see if we have a good result</li>
<li>For the hackaton, I worked on Decompress, but, as I said, no big change and just some experimentals modifications.</li>
<li>For the next week, I will start to fix some bug in ocaml-git as Richard advised me. Voilà!</li>
</ul>
<h4 id="olivier-nicole-13">Olivier Nicole</h4>
<ul>
<li>Automatic loading implemented in the bytecode linker, both at compile-time and for linking of runtime code. Automatic here means that the needed .cmm, .cmo and .cma file are automatically searched for in the include path. It's mainly for convenience reasons now, if it is too big a change it can be suppressed later.</li>
<li><code>ocamlc.opt</code> should work very soon, I just need to make phase-1 built-in exceptions work.</li>
<li>I experimented a bit, trying to use macros with the Markup.ml library (with HTML templates in mind). The very simple following code runs and prints &quot;
<p>
lol
</p>
&quot;:</li>
</ul>
<pre><code>static identity str =
  let open ^Markup in
  let open ^Pervasives in
  let res =
    (string str |&gt; parse_html |&gt; signals |&gt; write_html |&gt; to_string) in
  Expr.of_string res

let () = print_endline $(identity &quot;&lt;p&gt;lol&quot;)</code></pre>
<p>I will try writing more useful macros ASAP.</p>
<h4 id="ciaran-lawlor-4">Ciaran Lawlor</h4>
<p><strong>Monday</strong></p>
<p>IOCaml on 4.03 - Requires ctyptes. ctypes fails due to requiring libffi. There is a message about needing to brew install libffi but I missed it at first. Installed after that. - Forked and cloned iocaml, followed wiki post on iocaml github to create kernelspec for jupyter: <code>{   &quot;display_name&quot;: &quot;OCaml&quot;,   &quot;language&quot;: &quot;ocaml&quot;,   &quot;argv&quot;: [     &quot;&lt;full path to iocaml&gt;/iocaml.top&quot;,     &quot;-object-info&quot;,     &quot;-completion&quot;,     &quot;-connection-file&quot;,     &quot;{connection_file}&quot;   ]   }</code><br />
Had to use the full path to get it to work.<br />
Then run &quot;jupyter kernelspec install --name iocaml-kernel <code>pwd</code>&quot; inside that directory.<br />
And run<br />
<code>DYLD_LIBRARY_PATH= pwd :$DYLD_LIBRARY_PATH &amp;&amp; eval opam config env &amp;&amp; jupyter notebook --Session.key= --notebook-dir=notebooks</code><br />
to get jupyter running (again inside the iocaml directory). - Actually just <code>jupyter notebook --Session.key=</code> seems to work fine? - Hydrogen connects directly to the kernels without going through Jupyter (even though it uses jupyter for the kernelspecs). In atom, trying to use Hydrogen with ocaml code causes it to hang. Running just <code>jupyter notebook without --Session.key=</code> causes the server to repeatedly connect and disconnect to the kernel, so this is probably the issue.</p>
<p><strong>Tuesday</strong></p>
<p>IOCaml<br />
- Used 'apm develop hydrogen' to clone hydrogen as a development plugin, so I can modify it. To use my version I have to start atom with atom --dev. - Trying to figure out where exactly in Hydrogen the key stuff is set. Adding lots of console.log statements. - The connection to a kernel is created in kernel.coffee, which uses the config passed in by kernel-manager.coffee. - KernelManager either generates the config or loads it from ./hydrogen/connection.json in the atom project directory. So you can set key: &quot;&quot; and signature_scheme: &quot;&quot; in the json file, but then every option must be set. This means ports aren't found automatically etc, they must be set manually. * For now, I'm just hardcoding in the key and scheme into kernel.coffee. - Trying to do more with iocaml. Need to #require various things, but #use &quot;topfind&quot; doesn't work. That can be fixed by adding a .iocamlinit file to ~, starting it with</p>
<pre><code>  `let () =
    try Topdirs.dir_directory (Sys.getenv &quot;OCAML_TOPLEVEL_PATH&quot;)
    with Not_found -&gt; ()
  ;;
  #use &quot;topfind&quot;;;
  #thread;;
  #require &quot;iocaml-kernel.notebook&quot;;;</code></pre>
<ul>
<li>The actual ocamlinit doesn't need the above to come before adding other things like #use &quot;topfind&quot;. Shouldn't IOCaml load the toplevel path itself? (Some of Monday and Tuesday is summarised in a gist on github)</li>
</ul>
<p><strong>Wednesday</strong><br />
- Trying to figure out how iocaml displays data but I can't figure it out. There's something about adjustable type definitions. - Trying to figure out how hmac stuff works in zmq, but I don't think I'm going to get anywhere. IOCaml is difficult to figure out. Sockets are opened in sockets.ml, messages are sent and received though message.ml only? - Following datakit quick start. Managed to get the basics working. - Trying to get ocaml 9p working, currently a dependency bug. - Can't connect to the docker container yet, trying to figure out.</p>
<p><strong>Thursday</strong></p>
<p>Datakit<br />
- I can run it in docker but I can't actually connect to it. Trying to connect ocaml-9p just eventually results in a timeout. - Got it connecting, had to expose the port to the host using -p 5640:5640. (Most of Thursday was spent reading about docker networking or looking at datakit or ocaml-9p, so not much to log.)</p>
<p><strong>Friday</strong></p>
<p>Shell for ocaml-9p or datakit<br />
- Writing a quick lexer and parser for the commands so that things like strings and ids are actually handled properly. - Works pretty well, quite resilient. Parses input into an AST of commands with their arguments. Also handles strings properly, plus relatively easy to extend. - I'm writing this in such a way that tab completion should be fairly easy to add. - To interact with Datakit I will need to install it properly rather than through docker so I can use it in my program. But currently it won't make - getting error during linking, undefined symbols for x86_64. - Experimenting with Notty to make the shell interactive, for things like tab completion. - Notty doesn't seem to support applications that aren't full screen terminal when capturing key presses. For example utop allows tab completion while still being scrollable. Notty generally seems to be more for graphics. lambda-term should support this but looks more low level and depends on Camomile. - Notty also doesn't appear to clean up the terminal after ctrl + c, leaves mouse interaction on etc. And ctrl c can't be intercepted.</p>
<h4 id="philip-dexter-1">Philip Dexter</h4>
<p>This week I split my time under two projects: the continuing of my auto perforator and the datakit project.</p>
<p>The auto perforator is coming along very nicely. There is now a hill climbing algorithm built in which will explore the perforation state space. I have the system working under 3 domains: swaptions, ray tracer, and kmeans. I will give a talk about the system next Tuesday.</p>
<p>The datakit project is under KC's guidance. The idea is to use datakit to power a distributed key-value store. The implementation would be a domain for testing systems which adapt to byzantine errors by changing the strength of their reads into the database.</p>
<h3 id="week-27-1">Week 27</h3>
<h4 id="joel-jakubovic-2">Joel Jakubovic</h4>
<p><strong>Tuesday</strong></p>
<p>Tried installing OPAM and OCaml etc on Windows:</p>
<p>Follow the instructions on https://github.com/protz/ocaml-installer/wiki, up to the final Sanity Check <code>Env var OCAMLLIB</code> exists, so I &quot;clean it up&quot; - removing it, I assume, from my environment. However I can only do so for my current cmd session using SET, and it doesn't show up in systemwide environment variables so I assume it must be part of my user account's environment. Unfortunately I cannot change or access those; &quot;edit environment variables for your account&quot; shows no dialog, nothing (this has been a problem on my machine for a while, but I've never needed the feature till now). So I decide to unset OCAMLLIB in my Cygwin terminal, as it will at least persist for that session. I get to running opam install depext-cygwinports, but I get errors and unfortunately the others are not able to fix.</p>
<p>Later I open Cygwin terminal again. I forget to source .bashrc and run opam install depext-cygwinports and to my surprise it works. I then opam install zarith batteries stdint etc. and it also works, although I have to use the &quot;fake install&quot; steps in the Troubleshooting section. I then look at https://github.com/realworldocaml/book/wiki/Installation-Instructions and opam install core utop, but I get: <code>[ERROR] core is not available because your system doesn't comply with os != &quot;win32&quot; &amp; ocaml-version = &quot;4.02.3&quot;</code></p>
<p>I also read at the beginning of the article that Core is unsupported on Windows. So maybe I will have to go through the hassle of installing an Ubuntu VM after all, since my existing one is at home on my external hard drive.</p>
<p>opam install'd core utop on Ubuntu. Initially had some issues with an older version but fixed them.</p>
<p><strong>Wednesday</strong></p>
<p>Begin by installing the next list of packages. During the process I get one</p>
<p><code>Building conf-zlib.1:    pkg-config zlib  [ERROR] The compilation of conf-zlib.1 failed</code></p>
<p>I later end up with detailed error descriptions (as well as one for cohttp) giving &quot;Out of space&quot; errors - I'd given it the default size of 8GB, and I'd used a fixed-size virtual disk so it can't just be resized!</p>
<p>After wasting time grappling with VirtualBox to accept my new 512GB dynamic vdi, I now need to expand the partition or something. But I know nothing about it, and it involves boot-level munging of irreversible operations and I am seriously not interested in reinstalling the VM along with all the OCaml/OPAM stuff that took absolutely ages yesterday (and will probably take even longer, given my new VDI is dynamic). Instead I resolve to see what I can do in OCaml without zlib or cohttp installed in OPAM.</p>
<p>Not a great deal, it seems. For when I type in utop to my terminal (now using the old 8GB disk) all I get is Fatal error: unknown C primitive <code>unix_has_symlink</code></p>
<p>I would be surprised if this had anything to do with the lack of zlib or cohttp, since they were opam packages presumably for development. I google a bit, find similar looking errors, and do eval <code>opam config env</code>, try again and this time I'm finally in.</p>
<p>And it only took two whole days!</p>
<p>Later, we get to Docker, where I continue getting through Real World OCaml and receive a licence key for Windows 10 Professional - thanks Dr. Titmus.</p>
<p><strong>Thursday</strong></p>
<p>I begin the day by attempting the Windows 10 Pro upgrade three times in a row, using the official channels. Frustratingly, each time, after the restart, it appears as if nothing has happened. I'm still on Home. Maybe it would be better after all to just get a computer at Docker and the CL.</p>
<p>I talk to Graham Titmus and download the Win10 Multiple Editions ISO from DreamSpark. It tells me I'll need to burn it to a boot disk, so I go back to Titmus' office to ask - he isn't there, so after a while I go back and e-mail him, continuing with R.W.O in the meantime.</p>
<p>The time comes to run corebuild on my VM. I do so, and I get the &quot;out of memory&quot; error, because I'm still using the 8GB disk. I thought I could get away with it.</p>
<p>Titmus arrives and gives me a disk. I burn the ISO to the disk. I go through the setup process and, after many loooong waits eventually come to the final setup screen. &quot;You have chosen to: install Windows Home&quot; nope, I never chose anything like that, or even had any options. Google told me that the Multiple Editions version contained both Home AND Professional - and that it would ask me which one I would like.</p>
<p><code>C:\WINDOWS\system32&gt;dism /Get-WimInfo /WimFile:D:\sources\install.wim   Deployment Image Servicing and Management tool   Version: 10.0.10586.0</code></p>
<p><code>Details for image : D:\sources\install.wim</code></p>
<p><code>Index : 1   Name : Windows 10 Pro   Description : Windows 10 Pro   Size : 14,516,205,352 bytes</code></p>
<p><code>Index : 2   Name : Windows 10 Home   Description : Windows 10 Home   Size : 14,431,121,717 bytes</code></p>
<p>The operation completed successfully.</p>
<p>So it does contain Pro. Why didn't it acknowledge this? Perhaps I need to boot from the disc instead.</p>
<p>I can't seem to boot from it. Instead I enter in the new code to System &gt; Activation. This time it takes a LOT longer ... but ultimately ends up just like the other attempts.</p>
<p>I give up. I'll use my VM.</p>
<p>Increased primary partition, shouldn't have any (of the same) problems now.</p>
<p><code>$ eval</code>opam config env<code>$ opam install -y async yojson core_extended core_bench cohttp async_graphics cryptokit menhir merlin</code></p>
<p><code>...</code></p>
<pre><code> `#=== ERROR while installing conf-zlib.1 =======================================#
  # opam-version 1.2.0
  # os           linux
  # command      pkg-config zlib
  # path         /home/jdj27/.opam/4.03.0/build/conf-zlib.1
  # compiler     4.03.0
  # exit-code    1
  # env-file     /home/jdj27/.opam/4.03.0/build/conf-zlib.1/conf-zlib-5816-d2c37b.env
  # stdout-file  /home/jdj27/.opam/4.03.0/build/conf-zlib.1/conf-zlib-5816-d2c37b.out
  # stderr-file  /home/jdj27/.opam/4.03.0/build/conf-zlib.1/conf-zlib-5816-d2c37b.err`</code></pre>
<p>Googled, performed some magic, got it to work.</p>
<p>Continuing with RWO, this time much faster and more productively since I now have something to type into.</p>
<p><strong>Friday</strong></p>
<p>Just did RWO today, finally, was nice - got through several chapters, now up to chapter 8 (Imperative programming).</p>
<h4 id="romain-calascibetta-37">Romain Calascibetta</h4>
<ul>
<li>I defunctorized Decompress, so the API is more simply and I won 2 Mb/s for the inflate but I losted 2 Mb/s for the deflate</li>
<li>Now Decompress uses memcpy function instead memmove (standard function used by OCaml), it's a technical aspect but a big technical point about the portability on Decompress (on Xen architecture specifically). So, I talk about that with Jeremy and we think we have no problem and may be it's a good change to improve the performance of Decompress</li>
<li>I used a project from LexiFy, landmarks (Thomas advised me to use that), and Spacetime from Mark to find the bottleneck in Decompress and I found this Friday. I have an idea to optimize Decompress (again and again) but I think, we found the the big problem about the performance in Decompress (and it converges with Jeremy's idea)</li>
</ul>
<h4 id="olivier-nicole-14">Olivier Nicole</h4>
<ul>
<li>Testing of rebased branch and subsequent corrections finished. The remaining test failures are (all but one) due to lack of support for recursive modules, except for an unexpectedly long type error, probably due to the twofold compilation.</li>
<li>Alain Frisch's native toplevel (<code>ocamlnat</code>) now compiles again, but has no macro support.</li>
<li>Macro support was added to <code>ocamlopt</code> (careful, not <code>ocamlc.opt</code>). There was almost nothing to do since <code>ocamlopt</code> is a bytecode program.</li>
<li>Installing packages with <code>opam</code> is possible again but the fix is very ugly (<code>ln -s ocamlc ocamlc.opt</code>). <code>opam</code> doesn't seem to support bytecode-only installations.</li>
</ul>
<h4 id="ciaran-lawlor-5">Ciaran Lawlor</h4>
<p><strong>Monday</strong><br />
- Background reading. Refreshing how git works in more detail. Looking at irmin, datakit. - Reading articles from Thomas Leonard's blog.</p>
<p><strong>Tuesday</strong></p>
<p>Setting up opam / ocaml. - Installing opam using brew. Following RWO setup guide. Installing core, utop etc via opam. Configuring utop to #require core packages. - Setting up vim. Installing merlin and creating .merlin file. Installing ocp-indent-vim. Sorting out .vimrc. Installed syntastic, setup to use merlin.</p>
<p>Docker tutorial - Installed docker. Followed the basic docker tutorial - the basics of images, containers etc.</p>
<p>OCaml - Reading some more of Thomas Leonard's articles. Reading RWO.</p>
<p><strong>Wednesday</strong><br />
- Finished reading most of part 1 of RWO. Read some of the later chapters as well, but part 1 covers most of the language features.</p>
<p>Dependencies and utop - utop doesn't load the init file (.ocamlinit) when loading an ml file from the command line. Using #use loads the init file. - I expected utop to work with a file that used other modules in the same directory, but it doesn't. It is possible by building first using ocamlbuild and then using #load_rec on the cmo file. Useful for interacting / quickly testing a bit of code split across multiple files.</p>
<p>Lexing and Parsing - Read the chapter about parsing in RWO and managed to get the very basics working.</p>
<p><strong>Thursday</strong></p>
<p>IOCaml and Hydrogen - Setting up Hydrogen for Atom as explained on the website. Working with python (although requires running atom via terminal), need to get working with IOCaml. Installed OCaml support for atom using apm install language-ocaml. - Doesn't work on 4.03 for some reason, requires &lt; 4.03.0. Switching to 4.02.3. (Later on - after updating opam I can install on 4.03) - Trying to opam install IOCaml fails as it depends on gmp, which it isn't installing automatically. Installed manually with homebrew. - Still failing as ctypes won't compile - The compilation of ctypes failed at &quot;make XEN=disable libffi.config&quot;. - Installed libffi manually using brew. opam install IOCaml now works. - IOCaml doesn't work. Jupyter says 0 active kernels. Hydrogen works with python even if jupyter notebook isn't running, so I guess it's using its own instance. IOCaml works by itself from the command line, just not sure how to link with Jupyter or Hydrogen. - Jupyter doesn't have a kernel spec for IOCaml. I have no idea how to add one.</p>
<ul>
<li>There are pages on the IOCaml wiki for adding the kernel spec, but I can't figure it out.</li>
</ul>
<p>Lexing and Parsing<br />
- Messing around with ocamllex and Menhir in the afternoon, trying to create a simple template language. - Decided to try sedlex instead as it supports unicode. - sedlex won't install for 4.03. Latest version does work on 4.03 but opam isn't seeing it. Trying to figure out how to refresh the repo. - Can't find much (Later on - did I actually try opam update?). The latest version listed by opam is 1.99.2, but the opam repository online gives 1.99.3. - Adding PKG sedlex to my .merlin file causes 'Error while running external preprocessor'. Can't figure out what exactly is the problem for now, something to do with the fact sedlex uses ppx?</p>
<p>Sedlex<br />
- Just trying to lex for now, the template language consists of text and logic parts which need to be lexed differently, so the lexer needs some contextual infomation. - Managed to get lexing working pretty well for the template language, by using some mutable state. Don't think there is any other way really.</p>
<p><strong>Friday</strong></p>
<p>Sedlex<br />
- I'm currently testing my lexer by building, then going into utop and doing</p>
<pre><code>    #directory &quot;_build&quot;;;
    #load_rec &quot;_build/lexer.cmo&quot;;;</code></pre>
<p>This lets me quickly test it with different strings without having to rebuild, and lets me see the returned list of tokens.</p>
<ul>
<li><p>Sedlex doesn't let you define regexps using <code>let lid =   let lid1 = [%sedlex.regexp? R] in   [%sedlex.regexp lid1]   as they will be unbound. Currently doing: let lid1 = [%sedlex.regexp? R] let lid = [%sedlex.regexp lid1]</code> They have their own scope anyway.</p></li>
<li><p>Does defining a function within a function that is called often have a significant performance penalty to defining it outside the function?</p></li>
</ul>
<p><strong>Weekend</strong> - Messed around with lexing a bit more, got parsing working as well using Menhir. Requires using MenhirLib.Convert API as Menhir is made to work with ocamllex.</p>
<h4 id="philip-dexter-2">Philip Dexter</h4>
<p>This week I have generalized the perforation system to the point where I was able to take an off-the-shelf ocaml implementation of kmeans clustering and run it through the perforation system. The program was able to produce nice, readable results for different configurations [attached image]. However when more than 2 loops are perforated, the data starts becoming very hard to visualize. The system is really smooth but it's still lacking: I had to turn one use of List.iter into a for loop. However, I have created a plan to perforate recursive functions which will allow the system to work on programs which don't use for loops.</p>
<p>This week I also worked with the reagents library for ocaml-multicore. In the beginning of the week I parallelized an existing ray tracer written in OCaml. (The ray tracer also is a good candidate for perforation.) Further, KC and I have discussed working on a lock-free hash table implementation to use in the Hack type checker (written in OCaml). Currently hack use a C hash table implementation strapped on the to OCaml code. Writing a competitive implementation in OCaml would be a great way to show of ocaml-multicore.</p>
<h3 id="week-26-1">Week 26</h3>
<h4 id="romain-calascibetta-38">Romain Calascibetta</h4>
<ul>
<li>I continue to improve the interface of MrMime</li>
<li>I succeed to use the interface of david (it's the same of angstorm project) - now, the user can produce its parser</li>
<li>I find some littles regressions with my big test (my 2000 emails) - I will fix that</li>
<li>We can use the bigstring instead the string module now (so, possibly, we can improve the performance - but I need some tests about that)</li>
<li>I continue to documente the project and after we can have a release of MrMime</li>
<li>For this week, I will work on Decompress (as Richard advise me) about the performance, I already a PoC from zlib so I will test it.</li>
<li>I think I continue to work the morning on MrMime (because is just some fixes) and after I work on Decompress.</li>
</ul>
<h4 id="olivier-nicole-15">Olivier Nicole</h4>
<ul>
<li>Vast changes in the way dependencies of static code are loaded: although <code>.cmm</code> files are still automatically loaded from the include path (<code>-I</code>), <code>.cmo</code> and <code>.cma</code> dependencies of static code must now be specified using the <code>-m</code> command-line flag. Since dependencies of dependencies must be specified as well, it can lead to rather large compilation commands. This is intended as a backward-compatibility feature, since hopefully dependency management in OCaml should soon evolve to loading <code>.cmo</code> files from path during linking, if Leo White's proposal for that gets accepted.</li>
</ul>
<p>The changes made to dependency loading involved a bootstrap of the compiler, and a modification of the stdlib makefile (and 3 days of very painful debugging because of a line that hadn't been removed). * A rebase on <code>trunk</code> was performed to avoind falling behind, but some work is necessary to get the native compiler running again (without trying to make it support macros yet) before the testsuite can be run. * Static and runtime declarations can now be interleaved in the REPL. To achieve this, the symbol table used for linking now carries phase information (i.e. the symtable is now mapping (identifier, phase) pairs to positions in the global data array). * Cross-stage identifiers may now be quoted inside toplevel splices. To do that, it was necessary to make the typechecker track the top-levelness of the current environment, but also to propagate upwards the set of cross-stage identifiers encountered in the environment. The only missing form of cross-stage persistence (CSP) left to implement is <em>path closures</em>. * Redaction of a report about macros to motivate a second, 6-month internship, starting in September.</p>
<h4 id="philip-dexter-3">Philip Dexter</h4>
<p>Our perforation system is ready for initial testing so this week I've mostly worked on running experiments. I translated a swaptions program into OCaml. A lot of time was spent fixing bugs in the translation but once everything was set up I ran it through our loop perforation system and have some initial results.</p>
<p>We haven't quite reproduced the results from the C perforation system in the paper I'm referring to. They show results where a 5x speedup is achieved with only a 1% loss in accuracy. Our system can only produce a 1.2x speedup while losing 5% accuracy. We can get to 2x speedup but we have to sacrifice 40% accuracy. We do not perform the same state space searching as the paper version does so when that is all set up we may be able to reproduce the results.</p>
<p>I'm confident that once we perform the same sort of searches as the C version we can gain similar speedups. This will be an immediate goal of next week.</p>
<h3 id="week-25-1">Week 25</h3>
<h4 id="romain-calascibetta-39">Romain Calascibetta</h4>
<ul>
<li>I continue to optimize MrMime and I will use the Bigstring (which is more faster than the String module) with my RingBuffer</li>
<li>I finished to implement the interface (recommended by david) of my parser combinator (it is the same interface as the angstorm library from seliopou but with a different backend - as you know I use a ring-buffer)</li>
<li>So I continue the large background work on MrMime and keep the stability (and avoid any regression) with my unit tests. So, nothing impressive but needed to concurrent any other implementation of email :)</li>
</ul>
<h4 id="philip-dexter-4">Philip Dexter</h4>
<p>Our perforation system allows programmers to annotate looping constructs which they believe can benefit from perforation. Compiling an annotated program into an optimized program which uses loop perforation is not straghtforward.</p>
<p>The most difficult task of this system is in finding the optimal perforation configuration. One solution is to profile every possible permutation of configurations. As this is entirely unfeasible the most truly difficult task is finding a heuristic which allows us to prioritize configurations.</p>
<p>After running some subset of all configurations, there will be a smaller subset of optimal configurations which form a time-error tradeoff curve. Our end result would present this graph to the user, allowing them to choose which tradeoff works best for them.</p>
<p>My time this week has been split between converting a black--scholes C implementation to OCaml and a first draft of our perforation program. The perforation program can successfully run different perforation configurations however there are no heuristics involved yet.</p>
<h3 id="week-24-1">Week 24</h3>
<h4 id="romain-calascibetta-40">Romain Calascibetta</h4>
<p>I did some technical updates in MrMime:<br />
* First, I added an abstraction about the operating system (Windows and Unix) * I reorganized the project to produce a good low-level API to manipulate an email * I finished, as you know, the encoder (and I can produce an email now) * I optimized the Base64 and the QuotedPrintable decoder (with tailcall optimization) * I finished the pretty-printing of an email * I fixed some little bugs between the encoder and the decoder * And I added the support of UTF-8 with the uutfsoftware by daniel - now, I have only 3 errors with 2000 mails (so ~0.15% fails - so MrMime is more resilient) * I talked with Daniel about the API and the support of UTF-8 (because an email can have many encoding data) and the main thing is to normalize the email on one encoding, the UTF-8. But, for that, I need another software to normalize any encoding to UTF-8 (daniel told me who will do) * May be, the next week, I will start the SMTP protocol with the unikernel</p>
<h4 id="olivier-nicole-16">Olivier Nicole</h4>
<ul>
<li>I finally implemented support of static components in coercions. Now, module interfaces can be fully constrained (not only a subset consisting only of runtime values).</li>
<li>As a necessary condition for that change, the code duplication between <code>Translmod</code> and <code>Translstatic</code> was reduced to a minimum. Now, all <code>Translstatic</code> does is create the necessary lambda code to run splices.</li>
<li>When trying to use external static code in REPL, I realized that the it couldn't work because of the coexistence of ambiguous identifiers in the symbol table (e.g. <code>Expr</code> may be bound to the runtime part of the <code>Expr</code> module used in runtime code, or the static part of that module used in static code, a problem that doesn't arise in <code>ocamlc</code> since only the static parts are run). I am currently working on adding phase information to the symbol table to resolve these ambiguities.</li>
</ul>
<h4 id="philip-dexter-5">Philip Dexter</h4>
<p>A user cannot zealously apply approximate computing strategies to every line of every program they write. This week I have looked through three OCaml programs which I believe can benefit from approximation: 1. A ray tracer 2. A H.261 video decoder 3. The black--scholes algorithm for option pricing</p>
<p>Not all three programs have explicit for-loops---OCaml programmers tend to favor recursion---but all three have perforation opportunity.</p>
<p>My next step is to implement an interactive system which will guide a user in approximating their programs. It will first identify all potential loops/recursive calls in a program which allow perforation. Given this set it will then attempt to find the /best/ combination of perforation. Testing all possible combinations of loop perforation is unfeasible so some heuristics must be developed.</p>
<p>I also spent some time this week working on multicore OCaml. I wet my feet by writing a recursive lock implementation. The code can be found on [github] along with the [issue] requesting the implementation.</p>
<p><a href="https://github.com/ocamllabs/reagents/compare/master...philipdexter:recursive">github</a></p>
<p><a href="https://github.com/ocamllabs/reagents/issues/2">issue</a></p>
<h3 id="week-23-1">Week 23</h3>
<h4 id="enguerrand-decorne-1">Enguerrand Decorne</h4>
<ul>
<li>My first step is to take <span class="citation" data-cites="yallop">@yallop</span> script to generate ctypes bindings and make it generate some OCaml parse tree instead of generating OCaml sources so I try to find some ways of integrating it easily in a Reason/OCaml flow. One of the goal would be trying to avoid as much as possible fighting with a build system</li>
<li>I also took some time to finish a Reason js_of_ocaml REPL I started some months ago. We will probably communicate about it soon publicly, but for now it’s available there: https://engil.github.io/reason-web-toplevel/</li>
</ul>
<h4 id="romain-calascibetta-41">Romain Calascibetta</h4>
<ul>
<li>So I focused this week on my abstract for the ICFP (so Richard corrected the paper and I have sent Friday)</li>
<li>I continue to implement the pretty-printer of MrMime (I implemented without regresssion with my unit test)</li>
<li>I start to look S/MIME (secure mail) - so may be I will implement with ocaml-tls the secure mail one time</li>
</ul>
<h4 id="olivier-nicole-17">Olivier Nicole</h4>
<ul>
<li>The integration of Leo White's quoting library, as well as the implementation of top-level splicing, were completed. As a consequence, it is now possible to compile programs containing macros as long as CSP is not needed (except CSP for global identifiers which comes for free), for example:</li>
</ul>
<pre><code>  open ^Pervasives
  static rec power&#39; n x =
    if n = 0 then
      &lt;&lt; 1 &gt;&gt;
    else if n mod 2 = 0 then
      let y = power&#39; (n/2) x in
      &lt;&lt; let z = $y in Pervasives.( * ) z z &gt;&gt;
    else
      &lt;&lt; Pervasives.( * ) $x $(power&#39; (pred n) x) &gt;&gt;

  (* val power&#39; : int -&gt; int expr -&gt; int expr = &lt;fun&gt; *)
  static power n =
    &lt;&lt; fun x -&gt; $(power&#39; n &lt;&lt;x&gt;&gt;) &gt;&gt;
  (* val power : int -&gt; (int -&gt; int) expr = &lt;fun&gt; *)
  let power_five = $(power 5)
  (* val power_five : int -&gt; int = &lt;fun&gt; *)</code></pre>
<ul>
<li>Execution of static bindings and splices was implemented in the REPL. Declaring modules with static components in the REPL is not supported for now.</li>
<li>The <code>Expr</code> module, for phase-invariant <code>'a -&gt; 'a expr</code> conversions, was added. Using this module it is for instance possible to write the following function:</li>
</ul>
<pre><code>  static rec range = function
    | 0 -&gt; &lt;&lt; [] &gt;&gt;
    | n -&gt; &lt;&lt; $(^Expr.of_int n) :: $(range (^Pervasives.pred n)) &gt;&gt;</code></pre>
<ul>
<li>The tracking of stage (defined as the number of surrounding quotes, minus the number of non-top-level splices) was implemented. It makes it possible to tell whether a identifier in a quote will be usable at the splicing point or whether some form of CSP is needed. Since CSP is not implemented at the moment, when encountering a (non-global) identifier of the wrong stage a type error is thrown. (Type errors don't abruptly stop the program but show pretty-printed errors with the location of the problem).</li>
</ul>
<h4 id="philip-dexter-6">Philip Dexter</h4>
<p>My work this summer is about providing approximate programming tools for OCaml programmers. There are several different styles of approximate computing; each requires of their users different technical knowledge of the subject.</p>
<p>As one example, loop perforation is an approximate computing technique where iterations of a loop are skipped in the pursuit of reducing resource usage (be it time or energy). A loop perforation build system will generally have a self tuning step where, given test input and a fitness function from the user, the system can automatically deduce an approximation strategy. Further refinement by the user is indeed an option, but this is a good example of a technique which asks little of its user.</p>
<p>Loop perforation's ease of use leads KC and I to believe that adding a loop perforation system in OCaml is a great first step in the broader plan of supplying a goodie bag of approximation tools.</p>
<p>I have written a ppx extension for loop perforation. It is basic. In writing it I have both learned a lot about ppx extensions and expanded my compiler knowledge. The next steps are to decide whether to implement a self tuning system. If yes: the ppx extension and the self tuning system would make for a decent first release of an approximation system for OCaml. If no: there are other techniques for approximate computing that we can play with before we decide where to spend coding efforts.</p>
<p>We have met with a group in the lab which is interested in prolonging the flight time of their drone operations. It is hard to say whether there is a collaboration opportunity; approximate computing is not always the right tool for the job.</p>
<h3 id="week-22-1">Week 22</h3>
<h4 id="romain-calascibetta-42">Romain Calascibetta</h4>
<ul>
<li>I optimized the Base64 decoder but MrMime is slow with QuotedPrintable (but I have an idea to fix that)</li>
<li>MrMime is more resilient with bad email (like an email without Fromand Dateinformation)</li>
<li>I fixed some little bug (infinite loop, order of meta-data, multipart inception, unstructured data, and raised exception)</li>
<li>I retrieved a regression with my test (so, I have a good tests suite) and I fixed this regression - it's a specific problem with a wrong example from the standard RFC 822</li>
<li>I started the implementation of pretty-printing, so I continue the prototype (I am inspired by the Format module from OCaml standard lib to respect the 80 characters rules)</li>
<li>I will use an archive from the caml-list (from daniel) to have a good tests suit about the parsing of email (it's a huge example about the old/bad emails)</li>
<li>So this week, it's just some fixes and a minimal prototype about the pretty-printing :s</li>
</ul>
<h4 id="olivier-nicole-18">Olivier Nicole</h4>
<ul>
<li>Phase mismatch is now detected in signatures (i.e. the compiler will complain if you try to match a <code>static val</code> and a <code>val</code>).</li>
<li>We are now focusing on quoting and splicing. The splicing part involved quite a lot of refactoring in <code>Translstatic</code>: <code>Translstatic</code> used to translate an implementation file into a lambda creating the module and adding a reference to it in the symtable. Now the lambda generated by <code>Translstatic</code> not only creates the module but also returns an array of untyped ASTs, corresponding to all the splicings of code into phase zero (i.e. splicings that are not inside a quotation).</li>
<li>In a new module <code>Runstatic</code>, this static lambda code is run and the splicings are actually reified. They are then used by <code>Translcore</code> to &quot;fill&quot; phase-zero splicings every time it encounters one. This approach is implemented and compiles, but not yet thoroughly tested, since to test splicing something has to be quoted, and the quoting library is not integrated into the compiler yet.</li>
<li>Finally, I started working on integrating the quoting library written by Leo White. The main function <code>Translquote.quote_expression</code>, takes a typed tree and returns the lambda code that will generate the isomorphic <em>untyped</em> tree at run-time (well, at static run-time). This work is still going on.</li>
</ul>
<p>Limitations:<br />
* As stated above splicing is untested for now. * Because I didn't know whether I should reimplement some parts of <code>Translmod</code> in <code>Translstatic</code>, module coercions are still not handled by <code>Translstatic</code>. So for now, coercing static components of a <code>.ml</code> using a <code>.mli</code> won't work — the fix is easy but I'm focusing on quoting for now.</p>
<h3 id="week-21-1">Week 21</h3>
<h4 id="romain-calascibetta-43">Romain Calascibetta</h4>
<ul>
<li>I updated MrMime with a new program maildir. You can execute this program with ./maildir -p /path/to/your/mails/ -n LFif the newline of your email is LF character (and it's probably your case with mac osx). I retrieve two difficulties about the parsing:</li>
<li>The difficulty to predict the end of the email - so may be you catch an infinite loop when you scan your emails</li>
<li>The latency with Base64 and QuotedPrintable decoder (because, for each character, we need to try the boundary parser to stop the decoder)</li>
<li>So you can use the project on two way. The first way is to use maildirbinary. But if you catch a infinite loop for example (or a weird exception), you can try with a specific email with utop -init test.ml(the second way). At this moment, you can compile the project with debug information (with ./configure --enable-trace and make install) and see where MrMime fails. The parsing is resilient with the malformed header. So now, I will implement the pretty-printing of email and prove if the parsing and pretty-printing is bijective (just to be on the safe side).</li>
</ul>
<p>(you need to configure the project with --enable-teststo get the maildirbinary)</p>
<h4 id="olivier-nicole-19">Olivier Nicole</h4>
<ul>
<li>Support for loading static components of external modules was added. This implied compiling the static part of modules to <code>.cmm</code> files.</li>
<li>When using lifted versions of standard modules (e.g. <code>Printf</code>), the compiler would load the corresponding <code>.cmo</code> file. The problem is that standard modules are already present in the bytecode of <code>ocamlc</code> itself, so lifted standard modules were, in a way, loaded twice. In addition of being useless, this second loading would cause problems with side effects implying buffering (e.g. when using <code>Printf.printf</code>, the ordering of outputs was wrong). This was fixed by adding a function <code>Symtable.init_static ()</code> that simply calls <code>init_toplevel ()</code> and then adds the lifted version of every global identifier (pointing to the same position in the bytecode) directly into the symtable. This way, standard modules are not loaded twice, and their use no longer involves reading an external <code>.cmo</code> file.</li>
<li>At that point the produced lambda code was highly unsafe to use because it pointed to runtime and static fields of external modules as though they were in a same record, which could lead to wrong indexes and segfaults. This was fixed for now by adding 0 as a placeholder for non-static (resp.non-runtime) components in <code>.cmm</code> (resp. <code>.cmo</code>) files. A more sophisticated way might be necessary in the long term.</li>
</ul>
<p>Limitations:<br />
* Constrained internal modules (i.e. <code>module M : sig ... end = struct...</code>) is not supported by <code>Translstatic</code> yet. Nor are functors. These constructions are translated as the unit lambda. * <code>Includemod</code> is still phase-agnostic, so interface mismatches involving values with the right name and the wrong phase will not be detected.</p>
<h3 id="week-20-1">Week 20</h3>
<h4 id="enguerrand-decorne-2">Enguerrand Decorne</h4>
<ul>
<li>TLS: Halfway through the binding implementation, the configuration parsing from libtls is now working for ocaml-tls, only things left is writing and reading on sockets and the binding will be complete.</li>
</ul>
<h4 id="romain-calascibetta-44">Romain Calascibetta</h4>
<ul>
<li>I fixed some little bug with MrMime and the &quot;real world&quot; email</li>
<li>Firstly, I use a script with fetchmail program to download my email</li>
<li>But, I implemented a library to communicate with my GMail (with the POP3 protocol), you can see the project: https://github.com/oklm-wsh/Jackson (it's a little project, and it just a prototype to test MrMime)</li>
<li>So I continue to fix MrMime with the real world and automatize the test suite</li>
<li>At the same time, I look sessions type and GADT in OCaml to create a tool to describe a protocol (like POP3 or SMTP) with GADT (so a typed protocol), may be if I have a good result with GADT (because it's very complex), I use that for Jackson and for the implementation of SMTP</li>
<li>So not specifically productive but, step by step, I have a little prototype to communicate with GMail (or another service) and a resilient implementation of email</li>
</ul>
<h4 id="olivier-nicole-20">Olivier Nicole</h4>
<ul>
<li>Module lifting was implemented, i.e. external modules may now be used in static code by simply adding a caret (<code>^</code>) to their names, e.g.:</li>
</ul>
<p>Lifting of module defined inside the compilation unit (via <code>module M = struct... end</code>) is not supported, as the definition of such modules may depend on values that are only known at runtime. For this reason, only external, compiled modules can be lifted. * Support for accessing static values of internal modules was added, i.e. the following compiles and prints what is expected:</p>
<p>``` module M = struct open ^Pervasives</p>
<pre><code>static rec take n = function
  | [] -&gt; []
  | x :: xs -&gt; if n &gt; 0 then x :: take (n-1) xs else []

module N = struct
  static rec l = &quot;0&quot; :: l&#39;
         and l&#39; = &quot;1&quot; :: l
end</code></pre>
<p>end</p>
<p>open ^Pervasives</p>
<p>static () = print_endline @@ ^String.concat &quot;&quot; @@ M.take 10 M.N.l ```</p>
<p>Limitations:<br />
* Static value description in signatures (i.e. <code>static val x : some_type</code>) are supported by the parser, but not handled by the typechecker for now, as it implies modifying <code>Includemod</code>. Handling static components in signatures will be necessary for the next step, that is, saving and loading static code from/to external files.</p>
<h3 id="week-19-1">Week 19</h3>
<h4 id="enguerrand-decorne-3">Enguerrand Decorne</h4>
<ul>
<li>TLS: Implemented a few simple clients and servers using various C TLS libraries (libtls, mbedtls) to understand their API. Started to implement the binding trying to replicate libtls's interface.</li>
<li>Various things on Canopy (bugfixes)</li>
<li>Spent some time playing with Reason (reading the doc, tried to implement a web toplevel for Reason using js_of_ocaml), tried to debug an issue with ocaml-git</li>
</ul>
<h4 id="romain-calascibetta-45">Romain Calascibetta</h4>
<ul>
<li>As you know, I released Syndic 1.5 with ptime to compile in MirageOS. Hannes merged this change in Canopy</li>
<li>I optimized Decompress and I won 4 MB/s in Inflate</li>
<li>Jeremy Yallop send me a snippet for Decompress to win 2 MB/s (I didn't try this snippet yet but it is my TODO)</li>
<li>I came back to MrMime and fixed little bug in multipart parsing</li>
<li>I reorganized MrMime to have a better interface</li>
<li>I tried to use ocaml-imap to communicate with my GMail and it's work fine</li>
<li>But I'm focussing on the test of parsing now so I think the next, I will do just a many test to prove the maturity of MrMime (I already started)</li>
<li>May be I cook some cookies tomorrow for Monday :)</li>
</ul>
<h4 id="olivier-nicole-21">Olivier Nicole</h4>
<ul>
<li>I implemented the <code>static</code> keyword; all right-hand sides of static bindings will be executed during compilation. So:</li>
</ul>
<pre><code>  static msg = &quot;Hello&quot;
  static () = print_endline msg
  let () = print_endline &quot;runtime!&quot;</code></pre>
<p>will print &quot;Hello&quot; during compilation and &quot;runtime!&quot; when it's run. I only implemented this feature in the bytecode compiler as we decided to focus on it for now.</p>
<p>At that point though, sharing static and runtime values is not explicitely forbidden. So the following program:</p>
<pre><code>  let msg = &quot;let-bound&quot;
  static () = print_endline msg</code></pre>
<p>would make the compiler crash with a non-informative error message. * To address that, I split the environment into a static and a runtime part. So the above program would now be rejected with an &quot;Unbound variable&quot; message. That's not very informative either, but a more explicit staging error should be easy to implement later. * Currently, static bindings cannot refer to other modules than the one being compiled. So the program:</p>
<pre><code>  static () = print_endline A.msg</code></pre>
<p>fails with the error &quot;Undefined global A&quot;, even if the files <code>a.cmi</code> and <code>a.cmo</code> are in the include path. The only exception to this are the stdlib modules (such as <code>Printf</code> and <code>Pervasives</code>), because their bytecode is contained in the ocamlc program. So there needs to be a way to use non-standard modules in static code.</p>
<p>It appears that this triggers not only implementation question, but design issues. For example values from non-static modules should not be usable in static code, but the types exported by these modules should, otherwise lots of useful macros would be ill-formed. For example, when performing a quote:</p>
<pre><code>  module M = struct
    type t = T
    let x = T
  end

  macro m () = (&lt;&lt; M.x &gt;&gt; : M.t expr)</code></pre>
<p>This very simple macro would be rejected if types weren't shared across stages. So there needs to be a distinct treatment between types and values.</p>
<ul>
<li>Finally, the use of lifted modules (i.e. modules exporting non-static values that are used in static code of another module) raises lots of questions, as there can be two versions of a module in the same code: a lifted version and a non-lifted version, as in:</li>
</ul>
<pre><code>  static module M = struct
    type t = T
    let x = T
  end

  module M = struct
    type t = S
    let x = S
  end

  static foo = (M.x : M.t)</code></pre>
<p>In <code>M.x : M.t</code>, <code>M.x</code> refers to the static module, but to which module does <code>M.t</code> refer? Since types are shared across stages, this is ambiguous. There are lot of examples where referring to lifted and non-lifted modules using the same name is a problem. I don't fully understand all these examples yet. ^^</p>
<p>That's why Leo White came up with the proposition to make lifting syntactically explicit. For example, the lifted version of a module <code>Foo</code> would be <code>^Foo</code>.</p>
<p>On the implementation level, this implies to come back on a few changes made previously to the compiler, but it should eventually make implementation easier.</p>
<h3 id="week-17-1">Week 17</h3>
<h4 id="enguerrand-decorne-4">Enguerrand Decorne</h4>
<ul>
<li>ocaml-tls binding: Separating handling of IOs from the OCaml code: now the C program must handle all IOs (networking, file reading)…</li>
<li>As of friday this is mostly finished and the handshake from a simple C TLS client is working.</li>
<li>A working prototype of the binding is to expect by the end of next week.</li>
<li>Worked on Canopy: Improved CSS, various bugfixes and PR reviews</li>
</ul>
<h4 id="romain-calascibetta-46">Romain Calascibetta</h4>
<ul>
<li>I fixed some bug with parsing of email and header</li>
<li>I implemented the RFC 5321 (to have a literal domain in an email) and use Ipaddr library for this part</li>
<li>I implemented the validator website (http://oklm-wsh.github.io/Validator/validator.html) with some tests of email</li>
<li>I implemented the header fields from RFC 2045</li>
<li>I attacked the implementation of RFC 2046 (a multipart email)</li>
<li>I implemented a PPX to inject an IANA database in MrMime project (and I talked about that with Rudy for an integrate of that in Cohttp maybe)</li>
</ul>
<p>I talked with Richard Mortier and I think I will avoid the implementation of RFC 3798 (to permit a long parameter in a Content-Type field) and move fast to the implementation in a unikernel when I finish the multipart. So I think it is the last last RFC (to much RFC ...).</p>
<h3 id="week-16-1">Week 16</h3>
<h4 id="romain-calascibetta-47">Romain Calascibetta</h4>
<ul>
<li>A robust implementation of email (I check with a complete suit test from another implementation in PHP and JavaScript)</li>
<li>A robust implementation of meta-data of email (the header of email), it's compliant with old and new standard - 822, 2822 and 5322)</li>
<li>A beginning implementation of multipart email (I implemented Base64 and QuotedPrintable compute for encoded data)</li>
<li>Implementation of inline encoded data (compliant with the standard 2047)</li>
</ul>
<p>You can see all at: <a href="https://github.com/oklm-wsh/MrMime" class="uri">https://github.com/oklm-wsh/MrMime</a></p>
<h2 id="summary-of-activity-by-author">Summary of activity by author</h2>
<h3 id="author-olivier-nicole">Author Olivier Nicole</h3>
<h4 id="week-19-for-olivier-nicole">Week 19 for Olivier Nicole</h4>
<ul>
<li>I implemented the <code>static</code> keyword; all right-hand sides of static bindings will be executed during compilation. So:</li>
</ul>
<pre><code>  static msg = &quot;Hello&quot;
  static () = print_endline msg
  let () = print_endline &quot;runtime!&quot;</code></pre>
<p>will print &quot;Hello&quot; during compilation and &quot;runtime!&quot; when it's run. I only implemented this feature in the bytecode compiler as we decided to focus on it for now.</p>
<p>At that point though, sharing static and runtime values is not explicitely forbidden. So the following program:</p>
<pre><code>  let msg = &quot;let-bound&quot;
  static () = print_endline msg</code></pre>
<p>would make the compiler crash with a non-informative error message. * To address that, I split the environment into a static and a runtime part. So the above program would now be rejected with an &quot;Unbound variable&quot; message. That's not very informative either, but a more explicit staging error should be easy to implement later. * Currently, static bindings cannot refer to other modules than the one being compiled. So the program:</p>
<pre><code>  static () = print_endline A.msg</code></pre>
<p>fails with the error &quot;Undefined global A&quot;, even if the files <code>a.cmi</code> and <code>a.cmo</code> are in the include path. The only exception to this are the stdlib modules (such as <code>Printf</code> and <code>Pervasives</code>), because their bytecode is contained in the ocamlc program. So there needs to be a way to use non-standard modules in static code.</p>
<p>It appears that this triggers not only implementation question, but design issues. For example values from non-static modules should not be usable in static code, but the types exported by these modules should, otherwise lots of useful macros would be ill-formed. For example, when performing a quote:</p>
<pre><code>  module M = struct
    type t = T
    let x = T
  end

  macro m () = (&lt;&lt; M.x &gt;&gt; : M.t expr)</code></pre>
<p>This very simple macro would be rejected if types weren't shared across stages. So there needs to be a distinct treatment between types and values.</p>
<ul>
<li>Finally, the use of lifted modules (i.e. modules exporting non-static values that are used in static code of another module) raises lots of questions, as there can be two versions of a module in the same code: a lifted version and a non-lifted version, as in:</li>
</ul>
<pre><code>  static module M = struct
    type t = T
    let x = T
  end

  module M = struct
    type t = S
    let x = S
  end

  static foo = (M.x : M.t)</code></pre>
<p>In <code>M.x : M.t</code>, <code>M.x</code> refers to the static module, but to which module does <code>M.t</code> refer? Since types are shared across stages, this is ambiguous. There are lot of examples where referring to lifted and non-lifted modules using the same name is a problem. I don't fully understand all these examples yet. ^^</p>
<p>That's why Leo White came up with the proposition to make lifting syntactically explicit. For example, the lifted version of a module <code>Foo</code> would be <code>^Foo</code>.</p>
<p>On the implementation level, this implies to come back on a few changes made previously to the compiler, but it should eventually make implementation easier.</p>
<h4 id="week-20-for-olivier-nicole">Week 20 for Olivier Nicole</h4>
<ul>
<li>Module lifting was implemented, i.e. external modules may now be used in static code by simply adding a caret (<code>^</code>) to their names, e.g.:</li>
</ul>
<p>Lifting of module defined inside the compilation unit (via <code>module M = struct... end</code>) is not supported, as the definition of such modules may depend on values that are only known at runtime. For this reason, only external, compiled modules can be lifted. * Support for accessing static values of internal modules was added, i.e. the following compiles and prints what is expected:</p>
<p>``` module M = struct open ^Pervasives</p>
<pre><code>static rec take n = function
  | [] -&gt; []
  | x :: xs -&gt; if n &gt; 0 then x :: take (n-1) xs else []

module N = struct
  static rec l = &quot;0&quot; :: l&#39;
         and l&#39; = &quot;1&quot; :: l
end</code></pre>
<p>end</p>
<p>open ^Pervasives</p>
<p>static () = print_endline @@ ^String.concat &quot;&quot; @@ M.take 10 M.N.l ```</p>
<p>Limitations:<br />
* Static value description in signatures (i.e. <code>static val x : some_type</code>) are supported by the parser, but not handled by the typechecker for now, as it implies modifying <code>Includemod</code>. Handling static components in signatures will be necessary for the next step, that is, saving and loading static code from/to external files.</p>
<h4 id="week-21-for-olivier-nicole">Week 21 for Olivier Nicole</h4>
<ul>
<li>Support for loading static components of external modules was added. This implied compiling the static part of modules to <code>.cmm</code> files.</li>
<li>When using lifted versions of standard modules (e.g. <code>Printf</code>), the compiler would load the corresponding <code>.cmo</code> file. The problem is that standard modules are already present in the bytecode of <code>ocamlc</code> itself, so lifted standard modules were, in a way, loaded twice. In addition of being useless, this second loading would cause problems with side effects implying buffering (e.g. when using <code>Printf.printf</code>, the ordering of outputs was wrong). This was fixed by adding a function <code>Symtable.init_static ()</code> that simply calls <code>init_toplevel ()</code> and then adds the lifted version of every global identifier (pointing to the same position in the bytecode) directly into the symtable. This way, standard modules are not loaded twice, and their use no longer involves reading an external <code>.cmo</code> file.</li>
<li>At that point the produced lambda code was highly unsafe to use because it pointed to runtime and static fields of external modules as though they were in a same record, which could lead to wrong indexes and segfaults. This was fixed for now by adding 0 as a placeholder for non-static (resp.non-runtime) components in <code>.cmm</code> (resp. <code>.cmo</code>) files. A more sophisticated way might be necessary in the long term.</li>
</ul>
<p>Limitations:<br />
* Constrained internal modules (i.e. <code>module M : sig ... end = struct...</code>) is not supported by <code>Translstatic</code> yet. Nor are functors. These constructions are translated as the unit lambda. * <code>Includemod</code> is still phase-agnostic, so interface mismatches involving values with the right name and the wrong phase will not be detected.</p>
<h4 id="week-22-for-olivier-nicole">Week 22 for Olivier Nicole</h4>
<ul>
<li>Phase mismatch is now detected in signatures (i.e. the compiler will complain if you try to match a <code>static val</code> and a <code>val</code>).</li>
<li>We are now focusing on quoting and splicing. The splicing part involved quite a lot of refactoring in <code>Translstatic</code>: <code>Translstatic</code> used to translate an implementation file into a lambda creating the module and adding a reference to it in the symtable. Now the lambda generated by <code>Translstatic</code> not only creates the module but also returns an array of untyped ASTs, corresponding to all the splicings of code into phase zero (i.e. splicings that are not inside a quotation).</li>
<li>In a new module <code>Runstatic</code>, this static lambda code is run and the splicings are actually reified. They are then used by <code>Translcore</code> to &quot;fill&quot; phase-zero splicings every time it encounters one. This approach is implemented and compiles, but not yet thoroughly tested, since to test splicing something has to be quoted, and the quoting library is not integrated into the compiler yet.</li>
<li>Finally, I started working on integrating the quoting library written by Leo White. The main function <code>Translquote.quote_expression</code>, takes a typed tree and returns the lambda code that will generate the isomorphic <em>untyped</em> tree at run-time (well, at static run-time). This work is still going on.</li>
</ul>
<p>Limitations:<br />
* As stated above splicing is untested for now. * Because I didn't know whether I should reimplement some parts of <code>Translmod</code> in <code>Translstatic</code>, module coercions are still not handled by <code>Translstatic</code>. So for now, coercing static components of a <code>.ml</code> using a <code>.mli</code> won't work — the fix is easy but I'm focusing on quoting for now.</p>
<h4 id="week-23-for-olivier-nicole">Week 23 for Olivier Nicole</h4>
<ul>
<li>The integration of Leo White's quoting library, as well as the implementation of top-level splicing, were completed. As a consequence, it is now possible to compile programs containing macros as long as CSP is not needed (except CSP for global identifiers which comes for free), for example:</li>
</ul>
<pre><code>  open ^Pervasives
  static rec power&#39; n x =
    if n = 0 then
      &lt;&lt; 1 &gt;&gt;
    else if n mod 2 = 0 then
      let y = power&#39; (n/2) x in
      &lt;&lt; let z = $y in Pervasives.( * ) z z &gt;&gt;
    else
      &lt;&lt; Pervasives.( * ) $x $(power&#39; (pred n) x) &gt;&gt;

  (* val power&#39; : int -&gt; int expr -&gt; int expr = &lt;fun&gt; *)
  static power n =
    &lt;&lt; fun x -&gt; $(power&#39; n &lt;&lt;x&gt;&gt;) &gt;&gt;
  (* val power : int -&gt; (int -&gt; int) expr = &lt;fun&gt; *)
  let power_five = $(power 5)
  (* val power_five : int -&gt; int = &lt;fun&gt; *)</code></pre>
<ul>
<li>Execution of static bindings and splices was implemented in the REPL. Declaring modules with static components in the REPL is not supported for now.</li>
<li>The <code>Expr</code> module, for phase-invariant <code>'a -&gt; 'a expr</code> conversions, was added. Using this module it is for instance possible to write the following function:</li>
</ul>
<pre><code>  static rec range = function
    | 0 -&gt; &lt;&lt; [] &gt;&gt;
    | n -&gt; &lt;&lt; $(^Expr.of_int n) :: $(range (^Pervasives.pred n)) &gt;&gt;</code></pre>
<ul>
<li>The tracking of stage (defined as the number of surrounding quotes, minus the number of non-top-level splices) was implemented. It makes it possible to tell whether a identifier in a quote will be usable at the splicing point or whether some form of CSP is needed. Since CSP is not implemented at the moment, when encountering a (non-global) identifier of the wrong stage a type error is thrown. (Type errors don't abruptly stop the program but show pretty-printed errors with the location of the problem).</li>
</ul>
<h4 id="week-24-for-olivier-nicole">Week 24 for Olivier Nicole</h4>
<ul>
<li>I finally implemented support of static components in coercions. Now, module interfaces can be fully constrained (not only a subset consisting only of runtime values).</li>
<li>As a necessary condition for that change, the code duplication between <code>Translmod</code> and <code>Translstatic</code> was reduced to a minimum. Now, all <code>Translstatic</code> does is create the necessary lambda code to run splices.</li>
<li>When trying to use external static code in REPL, I realized that the it couldn't work because of the coexistence of ambiguous identifiers in the symbol table (e.g. <code>Expr</code> may be bound to the runtime part of the <code>Expr</code> module used in runtime code, or the static part of that module used in static code, a problem that doesn't arise in <code>ocamlc</code> since only the static parts are run). I am currently working on adding phase information to the symbol table to resolve these ambiguities.</li>
</ul>
<h4 id="week-26-for-olivier-nicole">Week 26 for Olivier Nicole</h4>
<ul>
<li>Vast changes in the way dependencies of static code are loaded: although <code>.cmm</code> files are still automatically loaded from the include path (<code>-I</code>), <code>.cmo</code> and <code>.cma</code> dependencies of static code must now be specified using the <code>-m</code> command-line flag. Since dependencies of dependencies must be specified as well, it can lead to rather large compilation commands. This is intended as a backward-compatibility feature, since hopefully dependency management in OCaml should soon evolve to loading <code>.cmo</code> files from path during linking, if Leo White's proposal for that gets accepted.</li>
</ul>
<p>The changes made to dependency loading involved a bootstrap of the compiler, and a modification of the stdlib makefile (and 3 days of very painful debugging because of a line that hadn't been removed). * A rebase on <code>trunk</code> was performed to avoind falling behind, but some work is necessary to get the native compiler running again (without trying to make it support macros yet) before the testsuite can be run. * Static and runtime declarations can now be interleaved in the REPL. To achieve this, the symbol table used for linking now carries phase information (i.e. the symtable is now mapping (identifier, phase) pairs to positions in the global data array). * Cross-stage identifiers may now be quoted inside toplevel splices. To do that, it was necessary to make the typechecker track the top-levelness of the current environment, but also to propagate upwards the set of cross-stage identifiers encountered in the environment. The only missing form of cross-stage persistence (CSP) left to implement is <em>path closures</em>. * Redaction of a report about macros to motivate a second, 6-month internship, starting in September.</p>
<h4 id="week-27-for-olivier-nicole">Week 27 for Olivier Nicole</h4>
<ul>
<li>Testing of rebased branch and subsequent corrections finished. The remaining test failures are (all but one) due to lack of support for recursive modules, except for an unexpectedly long type error, probably due to the twofold compilation.</li>
<li>Alain Frisch's native toplevel (<code>ocamlnat</code>) now compiles again, but has no macro support.</li>
<li>Macro support was added to <code>ocamlopt</code> (careful, not <code>ocamlc.opt</code>). There was almost nothing to do since <code>ocamlopt</code> is a bytecode program.</li>
<li>Installing packages with <code>opam</code> is possible again but the fix is very ugly (<code>ln -s ocamlc ocamlc.opt</code>). <code>opam</code> doesn't seem to support bytecode-only installations.</li>
</ul>
<h4 id="week-28-for-olivier-nicole">Week 28 for Olivier Nicole</h4>
<ul>
<li>Automatic loading implemented in the bytecode linker, both at compile-time and for linking of runtime code. Automatic here means that the needed .cmm, .cmo and .cma file are automatically searched for in the include path. It's mainly for convenience reasons now, if it is too big a change it can be suppressed later.</li>
<li><code>ocamlc.opt</code> should work very soon, I just need to make phase-1 built-in exceptions work.</li>
<li>I experimented a bit, trying to use macros with the Markup.ml library (with HTML templates in mind). The very simple following code runs and prints &quot;
<p>
lol
</p>
&quot;:</li>
</ul>
<pre><code>static identity str =
  let open ^Markup in
  let open ^Pervasives in
  let res =
    (string str |&gt; parse_html |&gt; signals |&gt; write_html |&gt; to_string) in
  Expr.of_string res

let () = print_endline $(identity &quot;&lt;p&gt;lol&quot;)</code></pre>
<p>I will try writing more useful macros ASAP.</p>
<h4 id="week-29-for-olivier-nicole">Week 29 for Olivier Nicole</h4>
<ul>
<li>Macro support has been implemented in <code>ocamlc.opt</code> (bytecode compiler running on the native back-end), after various bug corrections. The execution of macros is as follows:<br />
</li>
</ul>
<ol type="1">
<li>static code is compiled to bytecode and written to a temporary <code>.cmm</code> file<br />
</li>
<li>that <code>.cmm</code> file is linked with its dependencies to make a temporary bytecode executable<br />
</li>
<li>using <code>Sys.command</code>, <code>ocamlrun</code> is called on that file. The executable runs and writes the top-level splices to the file passed as a command-line argument.<br />
</li>
<li>The untyped parse trees are unmarshalled and spliced into the run-time code.</li>
</ol>
<ul>
<li>I pushed further the idea of HTML templates using the Markup.ml library. An example of a code that can be run (and that includes run-time strings in the template) is:</li>
</ul>
<pre><code>open Markup
open Htmltemplate
let par =
  Printf.printf &quot;Please enter a string: &quot;;
  read_line ()
let () =
  $(template [Lit {|
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
      &lt;head&gt;
        &lt;title&gt;Some page&lt;/title&gt;
      &lt;/head&gt;
      &lt;body&gt;
        &lt;h1&gt;Some page&lt;/h1&gt;
        &lt;p&gt;|}; Var &lt;&lt;par&gt;&gt;; Lit {|&lt;/p&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  |} ])
    |&gt; of_list |&gt; pretty_print |&gt; write_html |&gt; to_string
    |&gt; print_endline</code></pre>
<p>The HTML tree is constructed statically, entailing no parsing costs at run-time. The next step is to convert the Markup.ml tree to a TyXML tree to have the typechecker enforce the validity of the HTML tree.</p>
<h4 id="week-39-for-olivier-nicole">Week 39 for Olivier Nicole</h4>
<ul>
<li><dl>
<dt>Monday (2016-10-03)</dt>
<dd>With the help of Leo White, I realised that <code>Int_base</code> (see prev. worklog) should not be set to 0 in the static code. So I just removed the related condition in <code>Translmod</code>, and this segfault went away. But doing that incurred new dependencies from files such as <code>utils/numbers.ml</code> to stdlib <code>cmm</code> files. I moved all <code>stdlib/*.cmm</code> files to <code>boot/</code> (as was already done with <code>stdlib/*.cmi</code>) and it seems to do the trick for now. Today's issue arose in the following code: <code>(* this introduces a module `T` in scope *)   include Identifiable.Make (struct (* ... *) end)   module Pair = Identifiable.Make (Identifiable.Pair (T) (T))</code> Causing a <code>Bytegen.comp_expr: var T_1712</code> error.
</dd>
</dl></li>
<li><dl>
<dt>Tuesday</dt>
<dd>Removing another <code>target_phase</code> condition just made it work. It's quite surprising and I am afraid that something might break if I keep applying fixes that I don't understand, but I'm too lazy to take it seriously right now. But bad news: <code>ocamldoc/odoc_args.ml</code> uses first-class modules in way that makes the current way of translating modules go wrong: <code>module Html = (val  (  match !Odoc_args.current_generator with    None -&gt; (module Odoc_html.Generator : Odoc_html.Html_generator)  | Some (Odoc_gen.Html m) -&gt; m  | _ -&gt;  failwith    &quot;A non-html generator is already set. Cannot install the Todo-list html generator&quot; ) : Odoc_html.Html_generator)   ;;</code> Simply translating module unpacking (<code>Tmod_unpack</code>) fixed that one, but it will probably break in certain cases. Warning: phase not taken into account when typing recursive modules in <code>Typemod</code>. (later note: fixed)
</dd>
</dl></li>
<li><dl>
<dt>Wednesday</dt>
<dd>Basic examples with static modules work. And even static functors! How amazing is that! I implemented phase checks for modules, i.e. the compiler raises an error if a module identifier of the wrong phase is used in a functor application or a binding.
</dd>
</dl></li>
<li><dl>
<dt>Thursday</dt>
<dd>Today, I removed all the debug messages printed by the compiler and started to write a test suite for macros. For now it only contains very basic checks related to static values, quoting, splicing and static modules. I also removed the <code>Translstatic</code> module, which had become unnecessery, and moved its contents to <code>Translmod</code>. Doing that enabled me to make the REPL compile static modules (prior to that, they were just ignored). To-do list for the next days:
</dd>
</dl></li>
<li>make <code>ocamlopt</code> work again by fixing <code>Translmod.transl_store_implementation</code>.</li>
<li>run all tests on both compilers to see if anything is broken.</li>
<li>rebase <code>macros</code> on <code>trunk</code> (ouuuuch) and run the tests again.</li>
<li><dl>
<dt>Friday</dt>
<dd>Remark: one day, I will have to harmonize the behaviour of bytecode and native linker. This is not needed for macros to work, but is necessary to have a consistent user interface between the two compilers. <code>ocamlopt</code> compiles again. Testing time! A bunch of tests failed this time: <code>Summary: 551 tests passed   8 tests skipped  46 tests failed   2 unexpected errors 607 tests considered   List of failed tests:   tests/typing-recmod/t19ok.ml   tests/typing-implicit_unpack/implicit_unpack.ml.reference   tests/parsing/shortcut_ext_attr.ml.reference   tests/lib-format/pr6824.ml   tests/lib-format/tformat.ml   tests/lib-printf/pr6534.ml   tests/lib-printf/tprintf.ml   tests/lib-printf/pr6938.ml   tests/basic-more/testrandom.ml   tests/basic-more/tbuffer.ml   tests/basic-more/opaque_prim.ml   tests/utils/test_strongly_connected_components.ml   tests/typing-recmod/t18ok.ml   tests/basic-more/morematch.ml   tests/no-alias-deps/aliases.ml.reference   tests/typing-recmod/t10ok.ml   tests/lib-scanf   tests/typing-modules/aliases.ml   tests/typing-modules-bugs/pr6572_ok.ml   tests/ppx-attributes/warning.ml   tests/basic-more/tformat.ml   tests/basic-more/if_in_if.ml   tests/lib-threads/torture.ml   tests/translprim/module_coercion.ml.reference   tests/basic-more/pr2719.ml   tests/basic-more/top_level_patterns.ml   tests/typing-recmod/t22ok.ml   tests/no-alias-deps/aliases.cmo.reference   tests/typing-gadts/pr6993_bad.ml   tests/typing-poly/poly.ml   tests/parsing/extensions.ml.reference   tests/parsing/attributes.ml.reference   tests/lib-str/t01.ml   tests/basic-more/sequential_and_or.ml   tests/typing-modules-bugs/pr7182_ok.ml   tests/misc/weaktest.ml   tests/typing-recmod/t03ok.ml   tests/basic-more/function_in_ref.ml   tests/typing-recmod/t16ok.ml   tests/basic-more/bounds.ml   tests/lib-num   tests/utils/edit_distance.ml   tests/basic-more/tprintf.ml   tests/basic-more/pr6216.ml   tests/typing-recmod/t06ok.ml   tests/match-exception/match_failure.ml   List of unexpected errors:   tests/lib-dynlink-bytecode   tests/typing-fstclassmod   List of skipped tests:   tests/lib-dynlink-csharp   tests/unwind   tests/asmcomp/is_static_flambda   tests/asmcomp/unrolling_flambda   tests/lib-bigarray-2</code> In comparison, results on the 5th of July were: <code>Summary:   590 tests passed 8 tests skipped 9 tests failed 1 unexpected errors   608 tests considered   List of failed tests:   tests/typing-recmod/t18ok.ml   tests/typing-recmod/t10ok.ml   tests/typing-modules-bugs/pr6572_ok.ml   tests/ppx-attributes/warning.ml   tests/typing-recmod/t22ok.ml   tests/typing-poly/poly.ml   tests/typing-modules-bugs/pr7182_ok.ml   tests/typing-recmod/t03ok.ml   tests/typing-recmod/t06ok.ml   List of unexpected errors:   tests/typing-fstclassmod   List of skipped tests:   tests/lib-dynlink-csharp   tests/unwind   tests/asmcomp/is_static_flambda   tests/asmcomp/unrolling_flambda   tests/lib-bigarray-2</code> By taking the diff, I can see that no errors fixed themselves, and which ones are new: <code>8a9,22   &gt;     tests/typing-recmod/t19ok.ml   &gt;     tests/typing-gadts/pr7230.ml   &gt;     tests/typing-implicit_unpack/implicit_unpack.ml.reference   &gt;     tests/parsing/shortcut_ext_attr.ml.reference   &gt;     tests/lib-format/pr6824.ml   &gt;     tests/lib-format/tformat.ml   &gt;     tests/lib-printf/pr6534.ml   &gt;     tests/lib-printf/tprintf.ml   &gt;     tests/lib-printf/pr6938.ml   &gt;     tests/basic-more/testrandom.ml   &gt;     tests/basic-more/tbuffer.ml   &gt;     tests/basic-more/opaque_prim.ml   &gt;     tests/utils/test_strongly_connected_components.ml   9a24,25   &gt;     tests/basic-more/morematch.ml   &gt;     tests/no-alias-deps/aliases.ml.reference   10a27,28   &gt;     tests/lib-scanf   &gt;     tests/typing-modules/aliases.ml   12a31,38   &gt;     tests/basic-more/tformat.ml   &gt;     tests/tool-ocaml/t330-compact-2.ml   &gt;     tests/basic-more/if_in_if.ml   &gt;     tests/lib-threads/torture.ml   &gt;     tests/translprim/module_coercion.ml.reference   &gt;     tests/basic-more/pr2719.ml   &gt;     tests/basic-more/top_level_patterns.ml   &gt;     tests/typing-extensions/extensions.ml.reference   13a40,41   &gt;     tests/no-alias-deps/aliases.cmo.reference   &gt;     tests/typing-gadts/pr6993_bad.ml   14a43,47   &gt;     tests/parsing/extensions.ml.reference   &gt;     tests/parsing/attributes.ml.reference   &gt;     tests/lib-str/t01.ml   &gt;     tests/typing-warnings/application.ml.reference   &gt;     tests/basic-more/sequential_and_or.ml   15a49   &gt;     tests/misc/weaktest.ml   16a51,59   &gt;     tests/typing-gadts/pr5906.ml   &gt;     tests/basic-more/function_in_ref.ml   &gt;     tests/typing-recmod/t16ok.ml   &gt;     tests/basic-more/bounds.ml   &gt;     tests/lib-num   &gt;     tests/typing-gadts/pr7269.ml   &gt;     tests/utils/edit_distance.ml   &gt;     tests/basic-more/tprintf.ml   &gt;     tests/basic-more/pr6216.ml   17a61   &gt;     tests/match-exception/match_failure.ml   19a64   &gt;     tests/lib-dynlink-bytecode</code> Several failures seem due to include path problems, causing <code>Unbound modules</code> errors.
</dd>
</dl></li>
</ul>
<h4 id="week-40-for-olivier-nicole">Week 40 for Olivier Nicole</h4>
<ul>
<li>Monday (2016-10-10)</li>
</ul>
<p>Added static modifiers where appropriate in reference files to fix three <code>parsing/</code> tests. More importantly, fixed <code>bytecomp/bytelink.ml</code> so that <code>std_exit.cmo</code> is linked last, which was not the case until then. Number of failed tests fell to 20.</p>
<pre><code>  Summary:
    577 tests passed
      8 tests skipped
     20 tests failed
      2 unexpected errors
    607 tests considered
  List of failed tests:
      tests/typing-recmod/t19ok.ml
      tests/typing-implicit_unpack/implicit_unpack.ml.reference
      tests/basic-more/testrandom.ml
      tests/typing-recmod/t18ok.ml
      tests/no-alias-deps/aliases.ml.reference
      tests/typing-recmod/t10ok.ml
      tests/typing-modules/aliases.ml
      tests/typing-modules-bugs/pr6572_ok.ml
      tests/ppx-attributes/warning.ml
      tests/translprim/module_coercion.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-gadts/pr6993_bad.ml
      tests/typing-poly/poly.ml
      tests/typing-modules-bugs/pr7182_ok.ml
      tests/typing-recmod/t03ok.ml
      tests/typing-recmod/t16ok.ml
      tests/lib-num
      tests/typing-recmod/t06ok.ml
      tests/match-exception/match_failure.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
      tests/typing-fstclassmod
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<p>Note: the current linker may load/link object files in a different order from that given on the command line. That should be avoided.</p>
<ul>
<li>Tuesday</li>
</ul>
<p>Fix the linker to guarantee that object files are linked in the same order as specified on the command line (provided that the command-line arguments are topologically-sorted). Removed 2 errors.</p>
<pre><code>  Summary:
    579 tests passed
      8 tests skipped
     18 tests failed
      2 unexpected errors
    607 tests considered
  List of failed tests:
      tests/typing-recmod/t19ok.ml
      tests/typing-implicit_unpack/implicit_unpack.ml.reference
      tests/typing-recmod/t18ok.ml
      tests/no-alias-deps/aliases.ml.reference
      tests/typing-recmod/t10ok.ml
      tests/typing-modules/aliases.ml
      tests/typing-modules-bugs/pr6572_ok.ml
      tests/ppx-attributes/warning.ml
      tests/translprim/module_coercion.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-gadts/pr6993_bad.ml
      tests/typing-poly/poly.ml
      tests/typing-modules-bugs/pr7182_ok.ml
      tests/typing-recmod/t03ok.ml
      tests/typing-recmod/t16ok.ml
      tests/typing-recmod/t06ok.ml
      tests/match-exception/match_failure.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
      tests/typing-fstclassmod
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<p>Fixed segfaults by lifting &quot;CamlinternalMod&quot; module name in <code>Translmod</code>, when appropriate. Only 6 failures left, even less than after the last testing session!</p>
<pre><code>  Summary:
    592 tests passed
      8 tests skipped
      6 tests failed
      1 unexpected errors
    607 tests considered
  List of failed tests:
      tests/no-alias-deps/aliases.ml.reference
      tests/translprim/module_coercion.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-poly/poly.ml
      tests/match-exception/match_failure.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<ul>
<li>Wednesday</li>
</ul>
<p>Two other fixes (see commit logs):</p>
<pre><code>  Summary:
    594 tests passed
      8 tests skipped
      4 tests failed
      1 unexpected errors
    607 tests considered
  List of failed tests:
      tests/no-alias-deps/aliases.ml.reference
      tests/typing-recmod/t22ok.ml
      tests/no-alias-deps/aliases.cmo.reference
      tests/typing-poly/poly.ml
  List of unexpected errors:
      tests/lib-dynlink-bytecode
  List of skipped tests:
      tests/lib-dynlink-csharp
      tests/unwind
      tests/asmcomp/is_static_flambda
      tests/asmcomp/unrolling_flambda
      tests/lib-bigarray-2</code></pre>
<p>With the help of Leo, I changed the placeholder for classes in static code to make <code>typing-recmod/t22ok.ml</code> work.</p>
<ul>
<li>Thursday</li>
</ul>
<p>: Managed to fix all the tests (including the unexpected error), see commit logs. Started rebasing on branch <code>4.04</code>.</p>
<ul>
<li>Friday</li>
</ul>
<p>: Mark Shinwell remarked that in the case of a branch with so many changes on it, doing a rebase is extremely long: conflicts need to be resolved on a per-commit basis, and almost all commits trigger conflicts. So I decided to rather do a merge. The merge is at about 30% progress (building and testing not included).</p>
<h4 id="week-41-for-olivier-nicole">Week 41 for Olivier Nicole</h4>
<p>: I finished merging branch <code>4.04</code> into <code>macros</code>, but the repo is not functional yet: I get a segfault on <code>utils/clflags.ml</code> when bootstrapping. Strangely, printf-debugging pointed the segfault to happen on a call to <code>open_in_bin</code> inside <code>Bytelink.load_object</code>, although several successful calls have been made to <code>open_in_bin</code> during the execution. This suggests that the global data containing the Pervasives module has been somehow corrupt. * Tuesday<br />
: A lot of time spent fighting with the built system and trying to find the cause of my bug(s), without success. * Wednesday<br />
: Since <code>macros</code> was based on <code>trunk</code>, I shouldn't have used <code>merge</code> to rebase it on <code>4.04</code>, since changes from <code>trunk</code> have been introduced on <code>4.04</code>. In order to rebase macros on <code>4.04</code> without having to resolve conflicts on each commit (which would be necessary to keep the commit history), I had to squash all the macro-related commits into one commit, and cherry-pick that commit onto <code>4.04</code>. * Thursday<br />
: Conflicts solved and <code>.depend</code> files updated. <code>make coreall</code> works but the segfault on <code>open_in_bin</code> is back. What's more, when trying to compile some dummy file with a static printf in it, the compiler segfaults in <code>Symtable.update_global_data</code>, more specifically on the operation: <code>glob.(slot) &lt;- transl_const cst</code> where <code>glob</code> is <code>Meta.global_data ()</code>. I checked, it's not an out-of-bounds segfault. Another segfault I'm currently tracking is on a call to <code>Pervasives.output_string</code> (or <code>output_char</code>, one of the two). * Friday<br />
: Today, meeting with Mort and Anil to check the progress of macros. I need to start writing down ideas of applications. The runtime segfaults on the following line while executing the instruction APPTERM2: <code>pc = Code_val(accu);</code> Where <code>accu</code> has been set by the previous instruction: <code>PUSHGETGLOBALFIELD Pervasives, 48</code></p>
<h4 id="week-42-for-olivier-nicole">Week 42 for Olivier Nicole</h4>
<ul>
<li><dl>
<dt>Monday (2016-10-24)</dt>
<dd>Still tracking that bug. The facts are the following: the program segfaults when trying to dereference a <code>code_t*</code> pointer. The value of this pointer has been set by the instruction <code>PUSHGETGLOBAL Pervasives, 48</code>. The fact that this instruction was executed without segfault shows that accessing the field labelled <code>Pervasives</code> (at that moment) is not an issue. What is an issue is the value of field 48. Ok, so the problem is that the slot 41, corresponding to <code>Pervasives</code>, is erased. So an invariant has been violated. I understood what the problem is, it's actually very simple: I've tried to execute bytecode (using <code>reify_bytecode</code>) with a fresh symtable. But that resulted in the erasing of the compiler's global data in <code>Symtable.update_global_table</code>. So it can be stated that: &quot;to execute bytecode directly, the symtable needs to be shared between the executer and the executed&quot;. This bug was introduced by the change I made last Thursday, when I turned an <code>init_static</code> in <code>Runstatic</code> into <code>init</code>. I did that for the sake of bootstrapping, which otherwise would fail with an <code>Undefined global</code> error on a built-in exception.
</dd>
</dl></li>
<li><dl>
<dt>Tuesday</dt>
<dd>The bug was fixed, along with a few others (see commits for details), and all the tests are passed again.
</dd>
</dl></li>
<li><dl>
<dt>Wednesday, Thursday, Friday</dt>
<dd>Spent some time working on a staged regular expression matcher, to try macros in a &quot;real-world&quot; situation. I simply staged a very simple, higher-order representation of regular expressions with continuations. It allowed for some compile-time optimizations like: <sub>~</sub> # static f = compile @@ (lit &quot;John&quot; +.+ lit &quot;Kevin&quot;) <em>.</em> lit &quot; likes apples&quot;;; val f : (str -&gt; bool) expr = &lt;&lt; fun cs_1 -&gt; (cs_1 = &quot;John likes apples&quot;) || (cs_1 = &quot;Kevin likes apples&quot;) &gt;&gt; # static f = compile @@ maybe (lit &quot;A&quot;) <em>.</em> lit &quot;A&quot; <em>.</em> lit &quot;B&quot;;; val f : (str -&gt; bool) expr = &lt;&lt; fun cs_2 -&gt; (cs_2 = &quot;AB&quot;) || (cs_2 = &quot;AAB&quot;) &gt;&gt; <sub>~</sub>
</dd>
</dl></li>
</ul>
<p>The performance is unfortunately quite poor, due to the naiveness of the initial, higher-order algorithm. In particular, the code size for concatenated regexp increases exponentially with the number of regexps. But it has had the merit to demonstrate the tractability of macros, since no problem related to the macro system arose during development.</p>
<h4 id="week-45-for-olivier-nicole">Week 45 for Olivier Nicole</h4>
<ul>
<li><dl>
<dt>Monday (2016-11-07)</dt>
<dd>Laptop still in repair, spent all day trying to get a desktop PC as a replacement. Will use one of the lab shared computers from now on.
</dd>
</dl></li>
<li><dl>
<dt>Tuesday</dt>
<dd>Added a new <code>value_kind</code> for macros and made the typechecker tag macros with it.
</dd>
</dl></li>
<li><dl>
<dt>Wednesday</dt>
<dd>Stopped keeping track of cross-stage identifiers in the typing environment. Instead, iterate through the typed tree to find them in a expression when needed.<br />
During the Compiler hacking event at Pembroke, paired with Maxime to work on signatured opens (https://github.com/ocamllabs/compiler-hacking/wiki/Things-to-work-on#signatured-open-command); we're about halfway through it.
</dd>
</dl></li>
<li><dl>
<dt>Thursday</dt>
<dd>Add support (parser and typechecker) for macros in signatures.
</dd>
</dl></li>
<li><dl>
<dt>Friday</dt>
<dd>Add a closure argument to macros, yet unused.
</dd>
</dl></li>
</ul>
<h4 id="week-46-for-olivier-nicole">Week 46 for Olivier Nicole</h4>
<p><strong>Monday (2016-11-14)</strong></p>
<p>Specification of macro closures: the result of translating a macro into lambda code should be:<br />
* if the target phase is 1: the code of the macro itself;<br />
* if the target phase is 0: the closure, i.e. a block containing pointers to the cross-stage, phase-0 identifiers used in the macro's body.</p>
<p>Unrelatedly: discovered a bug in our early form of CSP. This &quot;weak&quot; CSP enabled the programmer to quote non-global identifiers <em>if</em> the quote was &quot;trapped&quot; inside a top-level splice. The current implementation is faulty, as it allows to quote simple identifiers like <code>y</code>, but not compound paths like <code>M.y</code>, e.g. the following does not work:</p>
<pre><code>  # module M = struct let y = 42 end;;
  (seq
    (apply (field 1 (global Toploop!)) &quot;M/1388&quot;
      (pseudo //toplevel//(1):11-32 (makeblock 0 0)))
    (makearray[addr]))
  (apply (field 1 (global Toploop!)) &quot;M/1388&quot;
    (let (y/1389 =[int] 42)
      (pseudo //toplevel//(1):11-32 (makeblock 0 y/1389))))
  module M : sig val y : int end
  # let x = $(&lt;&lt;M.y&gt;&gt;);;
  &gt;&gt; Fatal error: No global path for identifier
  Fatal error: exception Misc.Fatal_error</code></pre>
<p>Although this early form of CSP should be made redundant by path closures, I note this here for future reference. Improved printing of macros in signatures (<code>macro</code> instead of <code>static val</code>).</p>
<ul>
<li><p>Tuesday<br />
Generation of <code>Lfrommacro</code> identifiers by macro expansion works. Now working to make the type-checker handle <code>Lfrommacro</code> properly. Quite nicely, there is no need to add a constructor to the <code>Path.t</code> type, since <code>Path.Pdot</code> already has an integer field that can be used to represent closure fields. Also, the compiler now shows the results of splicing when the options <code>-dsource</code> or <code>-dparsetree</code> are set.</p></li>
<li><p>Wednesday<br />
Note: when modifying <code>CamlinternalQuote</code> it might be necessary to do <code>make   install</code> to have the changes taken into account in <code>Translquote</code>, since <code>Translquote</code> loads <code>^CamlinternalQuote</code> from the standard path unless otherwise specified.<br />
First examples with path closures working. Deactivated all warnings during compilation of splices.<br />
Nested macros now work as well.</p></li>
<li><p>Thursday</p></li>
</ul>
<p>Fix quoting of identifier so that globals are spliced as <code>Lglobal</code>. That incidentally fix the issue with compound paths (see Monday). Fix bug with macro numbering that would trigger segfaults when mixing macros and the <code>include</code> keyword. Replace previous warning deactivation with something cleaner. Discovered a bug in the REPL that raises problems with values that exist in two phases (i.e. currently, macros and modules that contain static values). The current mechanism is:<br />
1. The static lambda is compiled and executed and its result is stored in the global map of the REPL via <code>Toploop.set_value</code><br />
2. The run-time lambda of the same phrase is compiled and executed and its result is stored in the same place, thus erasing the previous result.<br />
This is fine for entirely static or entirely run-time values, because they are &quot;associated&quot; an identifier in one phase only. But it makes macros and two-phase modules unusable.<br />
To fix that, it was sufficient to split the global map by phase (just as what has been done with the symtable).<br />
I also ran the test suite and after a few minor fixes all tests are successful. There is not yet a proper testing of path closures though. Added a string component to <code>Lfrommacro</code> to print the name of field (along with its position) in a macro closure, for debugging and clarity purposes. The drawback is that it exposes internal names that depend on the implementation and might confuse the user.</p>
<ul>
<li>Friday<br />
Talked with Leo about future plans.<br />
Banned quoting from outside of macros and splices. As a direct consequence, turned <code>Expr.of_*</code> functions into macros.</li>
</ul>
<h4 id="week-48-for-olivier-nicole">Week 48 for Olivier Nicole</h4>
<ul>
<li>Remove &quot;zero&quot; placeholders for other-phase values in the lambda code. This took me most of the week, as I had to phase information to <code>Path.t</code>, but also to <code>module_coercion</code>s. This modification should avoid over-approximating the static dependency tree as is currently the case. Currently, every run-time dependency is a static dependency. Since static dependencies must be compiled before there parent in the tree can be compiled, this limitation would break most OCaml projects. I expect this work to be finished, I'll do the tests later tonight.</li>
<li>Talked with Leo about linking and side effects. Maybe, at some point, it will be necessary to ban the <code>static</code> keyword, unless the effect system is integrated into OCaml soon enough.</li>
<li>In addition to switching the quoting library to producing lambda code, it would be good to detect scope extrusion. This would be done by passing <code>CamlinternalQuote.Var.t</code> to macros, instead of the current <code>Longident.t loc</code>.</li>
<li>Note for later: rename <code>CamlinternalQuote.Ident</code> to <code>CamlinternalQuote.Global</code> and move <code>lfrommacro</code> to <code>Exp</code>.</li>
</ul>
<h4 id="week-49-for-olivier-nicole">Week 49 for Olivier Nicole</h4>
<p><strong>Compiler</strong></p>
<ul>
<li>The compiler &quot;without placeholders&quot; (and thus without useless static dependencies) now broadly works, i.e. I was able to bootstrap (necessary because adding an argument to one constructor of <code>Path.t</code> changed the cmi format) and compile <code>re</code> (a regexp library that previously didn't compile because of dependency issues).</li>
<li>Fixed some tests, including <code>warnings/w53.ml</code> and other easy things. My changes appear to have broken recursive modules again (assertion failed in <code>CamlinternalMod</code>).</li>
<li>Fixed some tests involving recursives modules, but not all of them, by fixing the <code>init_shape</code> function.</li>
<li>Changed the lifting symbol to <code>~</code> (which unlike <code>^</code> should be non-breaking) in order to break less Opam packages.</li>
<li>Fixed various issues and bugs with the new system of coercion. It seems quite robust, all tests are passed (except <code>no-alias-deps/aliases.cmo</code> but that's for a completely different reason, and was expected), and a lot of code from Opam compiles fine.</li>
<li>Fixed priority of &quot;illegal quoting&quot; errors over phase errors after drup's remarks</li>
</ul>
<p><strong>Examples using macros</strong></p>
<ul>
<li>I try to make a fork of camlp4 compile again, but I encountered a bug that wasn't caught by the tests.</li>
<li>A segfault occurs when running static code for the main source file of camlp4. Investigating on the issue.</li>
<li>Started to look at the Flick network DSL, and its OCaml implementation Motto, and whether it can benefit from compile-time metaprogramming.</li>
<li>Menhir is a dependency of motto, and doesn't compile because of wrong dependency tree — can be fixed by not translating type extensions into static code</li>
<li>Talked with Mort about networking examples. It would be nice to be able to optimize a packet stream processor like POF or P4 using staging (maybe trying to use or get inspiration from strymonas).</li>
</ul>
<h4 id="week-2-for-olivier-nicole">Week 2 for Olivier Nicole</h4>
<p>Start working on &quot;lambda quoting&quot; again.</p>
<p>Added the <code>CamlinternalLambda</code> file, contains a <code>lambda</code> type that resembles <code>Lambda.lambda</code>.</p>
<p>WARNING: Unlike with <code>CamlinternalAST</code> types, we do not necessarily want <code>CamlinternalLambda.lambda</code> to be isomorphic to <code>Lambda.lambda</code>! E.g. the <code>Ident.t</code> in <code>Lambda.lambda</code> is replaced with a simple string in <code>CamlinternalLambda</code>. Instead, we will rely on a trivial function to transform a <code>CamlinternalLambda.lambda</code> into a <code>Lambda.lambda</code>. This approach is simpler than the one used in <code>CamlinternalAST</code>.</p>
<ul>
<li>Re-read Oleg's paper about BER MetaOCaml to understand scope extrusion detection checks.</li>
</ul>
<p>It has been decided that for now, we will leave those checks in Parsetree quoting and not try to replicate them in Lambda quoting.</p>
<ul>
<li><p>Flick: read stuff about ctypes, try to figure out how to represent processes and command blocks.</p></li>
<li><p>Add the <code>iterate</code> combinator (translation of Flick for loops) and start building the blocks of processes.</p></li>
<li><p>Compiler: add more lambda quoting combinators and move all combinators in a Lambda module in <code>CamlinternalQuote</code>.</p></li>
<li><p>Fix bug with phase of type extensions, improved the compilation of menhir (in the sense that the first error occurs later in the build process). Menhir is necessary to build motto.</p></li>
<li><p>Now having a problem with module type discovery. Recall that, for compatibility reasons, each module declared in a source file must be deeply inspected in case it exports static values or macros. If it is not the case, then it is safe not to include it in the static code. This way, we don't add useless static dependencies, so that dependency trees are backward-compatible.</p></li>
<li><p>Here, some module types are not found for an unknown reason, entailing irrelevant static dependencies and preventing the compilation of Menhir.</p></li>
<li><p>Update other files to Parsetree quoting combinators being moved in a new module.</p></li>
<li><p>Keep working on interface discovery.</p></li>
<li><p>Start working on using the lambda combinators to actually construct lambda quotes in <code>Translquote</code>.</p></li>
<li><p>There is little documentation on the syntax and semantics of Flick. All that is available is documentation about Crisp, and sometimes the designs of these two languages diverge. For instance, in Crisp, two expressions at the same level of indentation separated by a newline, e.g.: <code>expr1   expr2</code> are evaluated in parallel, whereas in Flick they are evaluated sequentially.</p></li>
</ul>
<p>After speaking with Nik, it would be useful to keep a kind of log of such remarks that could be included in Flick's documentation.</p>
<ul>
<li>FINALLY found the bug in deep interface inspection: in <code>Includemod</code>, the environment used for building module coercions should know about the largest signature (using <code>Env.add_signature</code>), but it wasn't the case.</li>
</ul>
<p>Menhir now compiles on the macro switch, and so does motto.</p>
<h4 id="week-3-for-olivier-nicole">Week 3 for Olivier Nicole</h4>
<ul>
<li><p>Work done on lambda quoting: combinators are in place, now Translquote has to use them properly, i.e. the path arguments given to macros must become <code>lambda</code> instances (and not <code>Longident.t</code> instances).</p></li>
<li><p>After the last fixes on module type discovery, it seems that the compiler is now fully (except for syntax) backward-compatible, in the sense that projects that don't use macros should have the same dependency tree in 4.04 and in 4.04+macros.</p></li>
<li><p>My fork of Camlp4 now compiles on the macro switch.</p></li>
<li><p>Some reflexion on Flick and looking at the code of motto.</p></li>
<li><p>Flick: added a few elements in the DSL for channel declarations. For now, channels are implemented as a <code>'i option ref * 'o option ref</code> in the interpreter (i.e. a 1-capacity channel). Trying to replicate the program (https://github.com/NaaS/motto/blob/master/tests/runtime/factorial.ml)[factorial.ml].</p></li>
<li><p>Flick: add operations on channels, temporarily implement channels in terms of two references on lists (for incoming and outgoing data) and write my first &quot;embedded&quot; Flick program using the unstaged interpreter. This program doesn't use processes.</p></li>
<li><p>Macros: Introduced a new constructor <code>Lescape</code> to denote when a piece of lambda code should not be lifted when constructing a lambda quote. My current problem is: how to construct Parsetree quotes and lambda quotes in the same recursion without doing a lot of pairing/unpairing?</p></li>
</ul>
<h4 id="week-4-for-olivier-nicole">Week 4 for Olivier Nicole</h4>
<ul>
<li>Diagnosis of a &quot;problem&quot; with generation of Parsetrees and Lambdas in parallel by macros. To quote Leo:</li>
</ul>
<blockquote>
<p>the best thing to do would be to start by making lambda quoting work on its own without worrying about creating an AST Step two would be to make the extrusion errors in terms of source variables with locations And step three would be to start building the AST again The final version would, instead of producing:</p>
<pre><code>let splice1 = ... in
let splice2 = ... in
let ast = ... Field(0, [splice1]) ... Field(0, [splice2]) ... in
let lambda = ... Field(1, [splice1]) ... Field(1, [splice2]) ... in
  Makeblock [ast; lambda]</code></pre>
<p>produce something like:</p>
<pre><code>let splice1 = ref null in
let splice2 = ref null in
let lambda =
  ... (let res = ... in splice1 := Field(1, res); Field(0, res)) ...
  ... (let res = ... in splice2 := Field(1, res); Field(0, res)) ...
in
let ast = ... !splice1 ... !splice2 ... in
  Makeblock [lambda; ast]</code></pre>
<p>This would give us ASTs without any renaming of variables With a bit more work we could probably get renaming as well</p>
</blockquote>
<ul>
<li>Jeremy and Leo discovered three bugs, noted here for future reference:</li>
</ul>
<p><code>$ ocaml -dsource   # static r = ~Pervasives.ref None;;   static r = (~Pervasives).ref None ;;   static val r : '_a option ~Pervasives.ref = {~Pervasives.contents = None}   # let f () = let x = 10 in $(let c = &lt;&lt;x&gt;&gt; in ~Pervasives.(:=) r (Some c); c);;   let f () =  let x = 10  in $(let c = &lt;&lt; x &gt;&gt;  in (~Pervasives).(:=) r (Some c); c) ;;   splice #1: x val f : unit -&gt; int = &lt;fun&gt;   # let g () = let x = &quot;Hello world&quot; in $(let open ~Pervasives in match !r with Some c -&gt; c | None -&gt; &lt;&lt; 0 &gt;&gt;);;   let g () = let x = &quot;Hello world&quot; in $(let open ~Pervasives in match !r with Some c -&gt; c | None -&gt; &lt;&lt; 0 &gt;&gt;);;   Warning 26: unused variable x. splice #1: x val g : unit -&gt; int = &lt;fun&gt;   # g () + 5;;   - : int = 70275569256653</code></p>
<p><code>CamlinternalQuote.Exp.Local</code> should be used for all identifiers quoted in toplevel splices.</p>
<p><code>module M = struct $(&lt;&lt;()&gt;&gt;) end;;</code></p>
<p>results in an &quot;index out of bounds&quot; exception.</p>
<p><code>static print x = ~Pervasives.print_endline x;;   $(print &quot;one&quot;; &lt;&lt;()&gt;&gt;);;   $(print &quot;two&quot;; &lt;&lt;()&gt;&gt;);;</code></p>
<p>results in a segfault when put in a file and compiled with <code>ocamlc</code>.</p>
<ul>
<li>Lambda quoting now works, including path closures but without scope extrusion detection. There are still a few bugs to fix in the REPL but the tests show that all the other functions have been preserved. It is nice to see that macros are quite orthogonal to other features.</li>
</ul>
<h4 id="week-5-for-olivier-nicole">Week 5 for Olivier Nicole</h4>
<ul>
<li>Fixed small bugs with lambda quoting, bootstrapped the compiler.</li>
<li>Added some (hopefully temporary) code to print lambda quotes in the REPL.</li>
<li>Fixed a bug on <code>macros_unstable</code> that caused the compiler to crash when encountering a structure item with more than one splice in it.</li>
<li>On the way of fixing the bug that makes codes like: <code>module M = struct $ &lt;&lt; () &gt;&gt;   end</code> segfault.</li>
</ul>
<h3 id="author-liang-wang">Author Liang Wang</h3>
<h4 id="week-42-for-liang-wang">Week 42 for Liang Wang</h4>
<p>This week I have been working on the Plot module in Owl library by adding more basic plotting functions. Currently the Plot module supports many widely used plots. There are still many minor things in the module can be improved, but I will do that slowly in the future. I also wrote a tutorial on how to use the plot module and sent it to the ocamllabs mailing list.</p>
<p>Besides the Plot module, I am also focusing on the Stats module because GSL only provides very basic ones and there are many useful statistical functions are missing. I will implement most of them by myself in OCaml since I do not want to introduce too many dependency in the library. So far, I have implemented z-test, t-test, jb-test, chi2-test, and so on. Based on the feedback, it becomes clearer now that Owl will evolve into a numerical library for OCaml and Matrix, Maths, Stats, Regression, and Plot will be the core modules.</p>
<h4 id="week-43-for-liang-wang">Week 43 for Liang Wang</h4>
<ol type="1">
<li><p>I have implemented complex number support in Owl. The Dense module now have two submodules: Real and Complex which support dense matrices of real number and complex number respectively.</p></li>
<li><p>I also split the current Sparse module into two parts to support both real and complex sparse matrices. The real number is already supported but the complex number support in Sparse module is still missing.</p></li>
<li><p>I removed the dependency on Ctypes.Foreign module in Owl and change completely to stub generation as suggested by Yallop. So the interface to GSL is supposed to be faster and type safer.</p></li>
<li><p>I tested using functor to generalise some matrix operation, it worked fine but caused some performance penalty in certain operations that I am still trying to figure out the reason.</p></li>
<li><p>I gave a pitch of my kvasir project last night in Petershouse last night, since it entered into Cambridge Enterprise Business Plan competition. However, I didn’t win the first prize in the end but nice experience and received a lot of publicity.</p></li>
</ol>
<h4 id="week-44-for-liang-wang">Week 44 for Liang Wang</h4>
<ol type="1">
<li><p>I have optimised the performance of sparse complex matrix module. Many operations are much faster than before now. I think this module is mostly done.</p></li>
<li><p>I have implemented a module for Fast Fourier Transforms with basic operations. I still need some time to finalise this module next week.</p></li>
<li><p>I start writing up some documents to prepare for an opam release in the following weeks.</p></li>
<li><p>I start allocating more time on the distributed data processing framework again this week. The progress on this was slow due to the distraction from Owl.</p></li>
</ol>
<h4 id="week-45-for-liang-wang">Week 45 for Liang Wang</h4>
<ol type="1">
<li><p>I realised the first version of Owl to OPAM with the help of others, also included it in the MirageOS documentation.</p></li>
<li><p>I started shifting more efforts back to the distributed data processing framework. I rewrote the part of the data parallel and model parallel engine and wrapped them into a separate core module. On top of that, I implemented the one stochastic gradient decedent algorithm using model parallel engine.</p></li>
<li><p>I have been investigating the Latent Dirichelet Analysis model and identified some potential research questions. Me and mort met the student (Ben Caterall) who will work with on his part III project. He will also contribute to Owl.</p></li>
<li><p>I also implemented a simple LDA model using Owl, I hope Ben and me together can make a topic module for Owl.</p></li>
</ol>
<h4 id="week-46-for-liang-wang">Week 46 for Liang Wang</h4>
<p>For this week, I have been focusing on the development of the data processing framework. I have done the following things:</p>
<ol type="1">
<li><p>I implemented a very simple DHT for the framework.</p></li>
<li><p>I finished the first version of peer-to-peer model parallel engine, on top of which I also implemented a SGD algorithm.</p></li>
</ol>
<p>Besides these, not much, the P2P model turned out to be much more complicated than the map reduce and parameter server models. Currently, I am focusing on the barrier control implementation in the framework.</p>
<h4 id="week-47-for-liang-wang">Week 47 for Liang Wang</h4>
<ol type="1">
<li><p>I kept working on the P2P engine, and I implemented a distributed LDA atop of P2P engine in my data processing framework. I spent about two days in debugging it and finally managed to make it work.</p></li>
<li><p>I had a meeting with Mort to refine our thinking on the data framework and identified a couple of interesting research questions: barrier control, and model consistency.</p></li>
<li><p>I had a couple of meetings with those who are interested in owl and identified some potential directions: more advanced support for multi-dimensional array, and auto gradient derivation functions. I will focus on these two and try to get them ready by the end of this year.</p></li>
<li><p>I wrote a separate post for using owl to manipulate matrices, in case you didn’t notice before, here is the link: https://github.com/ryanrhymes/owl/wiki/Manipulate-Matrices-in-Owl</p></li>
</ol>
<h4 id="week-48-for-liang-wang">Week 48 for Liang Wang</h4>
<p>Sorry for the late email this time, I was travelling on Friday. For the last week, I had been only focusing on the N-dimensional array in Owl.</p>
<ol type="1">
<li><p>I implemented the first version of N-dimensional array, atop of which, I also implemented a N-dimensional view module which can pipeline some operations on the array to speed up the performance.</p></li>
<li><p>I later find a better way to further optimise the performance of ndarray by using blas/lapack library. I am currently rewriting some code for better performance.</p></li>
</ol>
<h4 id="week-49-for-liang-wang">Week 49 for Liang Wang</h4>
<ol type="1">
<li><p>I finished the first version of n-dimensional array in Owl, including some optimisation and the full documentation.</p></li>
<li><p>I also wrote a tutorial on Ndarray which you can find here: https://github.com/ryanrhymes/owl/wiki/Tutorial:-N-Dimensional-Array</p></li>
<li><p>I did some initial comparison to numpy and julia, it looks promising at the moment, and I will do more thorough evaluation next week.</p></li>
<li><p>I also talked to kc and michel and discussed about further optimisations on owl, I will look into the directions they suggested in the following weeks.</p></li>
</ol>
<h4 id="week-50-for-liang-wang">Week 50 for Liang Wang</h4>
<p>I have been working on the following things.</p>
<ol type="1">
<li><p>I received a lot of feedback of Owl via github and emails from different people. Based on the feedback, I decided to restructure the Owl a bit by providing a more general matrix module using GADT. I already finished the initial version of Dense.Matrix module. In the near future, it will replace the current Dense.Real and Dense.Complex to provide matrix support for more types and precisions.</p></li>
<li><p>I met Huawei people with Jon and presented Owl and Actor (the data processing system) I developed. They showed some interests which is a good sign (maybe:)</p></li>
<li><p>For Actor, I have been collecting papers and doing literature survey to formulate the idea.</p></li>
</ol>
<p>For next week, I will fly back to Helsinki so I cannot attend the meeting any more this year. I will see you guys next year in January :)</p>
<h4 id="week-1-for-liang-wang">Week 1 for Liang Wang</h4>
<ul>
<li>Owl</li>
<li>Implement the module of sparse matrices.</li>
<li>Implement the module of sparse n-dimensional array.</li>
<li>Add the unit tests for Dense.Matrix, Dense.Ndarray, Sparse.Matrix, and Sparse.Ndarray modules using Alcotest.</li>
<li>Add the performance tests for the aforementioned four modules.</li>
</ul>
<h4 id="week-2-for-liang-wang">Week 2 for Liang Wang</h4>
<ul>
<li>Split out Owl's interface to Eigen3 as a standalone library: <a href="https://github.com/ryanrhymes/eigen">Github Repo</a></li>
<li>Manage to learn how to interface between OCaml and C++ template library using Ctypes when interfacing to Eigen3.</li>
<li>Submit Eigen OCaml library to OPAM on Friday and wait for approval now.</li>
</ul>
<h4 id="week-3-for-liang-wang">Week 3 for Liang Wang</h4>
<ul>
<li>Release Owl 0.2.0 to OPAM. The new release contains a lot of significant changes in the fundamental data structures in Owl. The number types and precision can be passed in as parameters in creation functions. Meanwhile, the interface remains compatible with the old <code>Dense.Real</code> and <code>Dense.Complex</code> modules, the latter two have default 64-bit precision.</li>
<li>Write a tutorial on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Basic-Data-Types">Basic Data Types in Owl</a></li>
<li>Write a tutorial on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Metric-Systems">Metric Systems in Owl</a></li>
<li>Ben Caterall implemented a topic modelling algorithm (SparseLDA) using Owl, the pull request has been merged. This actual application of Owl will help in refining the interface of Owl. The code can be found <a href="https://github.com/ryanrhymes/owl/blob/master/lib/topic/owl_topic_lda.ml">here on github</a>.</li>
<li>LDA code revealed a problem of Sparse module in Owl. The new implementation of Sparse module actually slows down the LDA algorithm a lot. The reason is current matrix storage format (CRS) is not ideal for random access of matrix elements (even tough it speed up many linear algebra operations), whereas my previous implementation uses a combination of hash table and CRS. This needs to be solved in future.</li>
</ul>
<h4 id="week-4-for-liang-wang">Week 4 for Liang Wang</h4>
<ul>
<li>Study automatic algorithmic derivation, prepare for the implementation.</li>
<li>Work on distributed data processing system (Actor System), document what has been done so far.</li>
<li>Refine and formulate the idea of a new barrier control technique in distributed machine learning, write the initial draft, plan the evaluation.</li>
</ul>
<h4 id="week-5-for-liang-wang">Week 5 for Liang Wang</h4>
<ul>
<li>Implement a simple prototype of forward AD, but it does not support higher order derivatives. I need to read a bit more on algorithmic differentiation.</li>
<li>Try to test some barrier control logic in distributed learning.</li>
<li>Refactor the topic modeling module in Owl.</li>
</ul>
<h4 id="week-6-for-liang-wang">Week 6 for Liang Wang</h4>
<ul>
<li>I re-implemented the forward mode of algorithmic differentiation [<a href="https://github.com/ryanrhymes/owl/blob/master/lib/owl_algodiff_forward.ml">code</a>]. Now the Algodiff supports higher-order derivatives now, check <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Algorithmic-Differentiation">here</a> please.</li>
<li>To support higher-order derivatives, Algodiff uses many recursive functions and also recursive modules. However, I was told recursive module is not a good option in OCaml due to losing the capability of compiler optimisation. I do not have a solution at the moment.</li>
<li>I overloaded some common math operators in Algodiff module. However, some matrix operations still need to be implemented.</li>
<li>I did some barrier control experiments in distributed learning. The simulator and result analysis are all done on top of Owl. The current results look good, Actor system seems more scalable than other barrier control. But I need to investigate a more into the accuracy.</li>
</ul>
<h4 id="week-7-for-liang-wang">Week 7 for Liang Wang</h4>
<ul>
<li>I added several more functions into Owl module such as tile, repeat, and etc.</li>
<li>I added matrix type into current AD forward mode to support simple linear algebra.</li>
<li>I started to re-design another AD module in order to have better supports for both forward and backward AD (to be implemented). Moreover, in new AD implementation, I change from recursive modules to a chain of recursive functions.</li>
</ul>
<h4 id="week-8-for-liang-wang">Week 8 for Liang Wang</h4>
<ul>
<li>The first version of backward AD was implemented in Algodiff module. I overloaded most of the commonly used math operators.</li>
<li>I added another sub-module in Algodiff which is able to provide numerical differentiation. This can be used to cross-validate the results from Algodiff.AD module.</li>
<li>I added more functions (softplus, softsign, sigmoid, softmax, etc.) to Owl to provide better support for machine learning algorithms.</li>
<li>I have been doing experiment for Paar paper, and at the same time we have been trying to make ARM-based docker image for Owl so that we can run it on Raspberry Pi.</li>
</ul>
<h4 id="week-9-for-liang-wang">Week 9 for Liang Wang</h4>
<ul>
<li>We finalised the paper on privacy-preserving model training paper and submitted to PoPETs.</li>
<li>I worked with Jianxin to installed Owl on Raspberry PI and did some topic modelling experiment. There is an ARM-based docker image for Owl now.</li>
<li>I spent a couple of days in studying the software licensing stuff and made a new plan for Owl development. I will gradually remove the dependency on GSL to make sure Owl will remain MIT licence.</li>
<li>I start building an extension atop of Owl so that different types of math objects (scalar, matrix, ndarray) can interoperate.</li>
</ul>
<h4 id="week-10-for-liang-wang">Week 10 for Liang Wang</h4>
<ul>
<li>The GSL dependency has been removed from the core components in Owl.</li>
<li>Current modules (partly) rely on GSL are Maths, Stats, FFT. I am currently wrapping up Cephes to replace GSL-based modules.</li>
<li>I spend some time in refining the AD interface. The <a href="https://gist.github.com/ryanrhymes/582e1d1a5f3cd47a6b96fe5bed4914e8">code here</a> show how to build a trivial neural network with AD (from scratch). Comments are welcome.</li>
<li>However, I noticed the memory consumption grows really fast in the previous naive neural network experiment. The allocated memory did not seem to be correctly released after usage. I still try to identify the (possible) memory leak issue. Let me know if anyone has any idea about this.</li>
</ul>
<h4 id="week-11-for-liang-wang">Week 11 for Liang Wang</h4>
<ul>
<li>I had been dealing with high memory consumption issue of AD module in Owl last week. In the end, the issue was identified: calling <code>Bigarray.Genarray.change_layout</code> function will cause OCaml unable to free the memory allocated for the variable.</li>
<li><code>change_layout</code> functions have been called a lot in order to pass variables to Lacaml. Because of the aforementioned issue, I had to remove all these calls. In the end, I rewrote many maths function locally in <code>c</code> so Owl does not depend on Lacaml any longer.</li>
</ul>
<h4 id="week-12-for-liang-wang">Week 12 for Liang Wang</h4>
<ul>
<li>The memory issue of Owl was completely addressed. Now the MNIST example only consumes about 400MB memory and GC works fine. AD module can now be used in practice.</li>
<li>The <code>change_layout</code> function was completely removed from Owl since Owl does not depend on Lacaml any longer. All the vectorised math functions were reimplemented in c last week.</li>
<li>The module structure was also significantly changed, now different number types are wrapped into corresponding modules (S, D, C, Z, Generic). This makes the API even simpler in programming.</li>
<li>I published a new release Owl 0.2.2 this Friday. The tutorials are also updated to be consistent with the new changes in Owl, also added AD stuff in readme.</li>
</ul>
<h4 id="week-13-for-liang-wang">Week 13 for Liang Wang</h4>
<ul>
<li>I made an experimental module called <a href="https://github.com/ryanrhymes/owl/tree/master/lib/ext">Owl_ext</a> which allows interoperation of different number types. This should make analytical app easier to write and the code should be more concise. I finished the first version and here is an <a href="https://gist.github.com/ryanrhymes/f9cce1afcd06a5f4683aae45be01bdbe">example</a>. <strong>Please do let me know if you have any comments on the design.</strong></li>
<li>I made several c functions in Owl to cast bigarray between different number types. These functions serve Owl_ext module for converting number types whenever necessary during interoperation.</li>
<li>I start building neural network module atop of current Owl's functionality and AD module. I think Owl's future development should be motivated by the realistic applications. I will start looking into various application scenarios and neural network seems a good starting point.</li>
<li>I start working on the actor system and barrier control again, pushing forward the experiment to get more results out.</li>
</ul>
<h4 id="week-14-for-liang-wang">Week 14 for Liang Wang</h4>
<ul>
<li>I have been working on the neural network module in Owl. Currently, I am focusing on various gradient descendent and learning rate algorithms. AD turns out to be really powerful in simplifying the design of neural network module.</li>
<li>For barrier control in actor system, I am still working on the experiments. The results reported by Ben seem really promising.</li>
</ul>
<h4 id="week-15-for-liang-wang">Week 15 for Liang Wang</h4>
<ul>
<li>I updated the slicing function in Owl. It is more flexible than the previous version but can still be improved.</li>
<li>I released Owl.0.2.3. The current focus of the development is on neural network and nlp modules.</li>
<li>I did some experiments for actor system, this will continue and will be my focus in the following weeks.</li>
</ul>
<h4 id="week-16-for-liang-wang">Week 16 for Liang Wang</h4>
<ul>
<li>I have been working on the nlp module in Owl. The nlp module aims to provide stronger supports to deal with large text corpus. With Owl's numerical functions, I hope people can build up topic model easily.</li>
<li>I have been studying latest ocaml-tensorflow binding, and other libraries for fast prototyping such as keras.io, to see what Owl can learn from them.</li>
</ul>
<h4 id="week-17-for-liang-wang">Week 17 for Liang Wang</h4>
<ul>
<li>I have been working on the redesign of math operators in Owl. I have looked into multiple implementations in different languages such as numpy, julia, and R.</li>
<li>I have been improving the NLP module, include Corpus, TFIDF, and Vocabulary modules.</li>
</ul>
<h4 id="week-18-for-liang-wang">Week 18 for Liang Wang</h4>
<ul>
<li>The operators are re-designed last week with some newly added ones. The Ext module is also finished. I then released the version 0.2.4 on OPAM.</li>
<li>The work on neural network module continues, at the same time I add more functions into Owl's core.</li>
<li>I wrote two tutorials: one is on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Operators-and-Ext-Module">operators and ext module</a>; one is on <a href="https://github.com/ryanrhymes/owl/wiki/Tutorial:-Algorithmic-Differentiation">algorithmic differentiation</a>.</li>
</ul>
<h4 id="week-19-for-liang-wang">Week 19 for Liang Wang</h4>
<ul>
<li>I spent the whole week in studying convolution neural network stuff. I have looked into code in Tensorflow and implemented a convolution function in OCaml. I will do some comparison next week and focus on the implementation of convolution layer.</li>
</ul>
<h4 id="week-20-for-liang-wang">Week 20 for Liang Wang</h4>
<ul>
<li>More types of layers have been added in neural module: convolution 2D, convolution 3D, maxpool, fully_connected, lambda layer, and etc.</li>
<li>A large part of the code in neural module was also refactored. Now, Owl is able to validate every layer in a network having consistent input and output shape when constructing a Feedforward network.</li>
<li>Algodiff module is able to support (partially though) N-dimensional array now.</li>
</ul>
<h4 id="week-21-for-liang-wang">Week 21 for Liang Wang</h4>
<ul>
<li>I publish a new release for both Eigen.0.0.4 and Owl.0.2.5 on OPAM.</li>
<li>I am still focusing on the neural network module in Owl. I finished <code>Dropout</code>, <code>Reshape</code>, and <code>Flatten</code> layers this week. With these new layers, I implemented a convolutional version of the previous MNIST example which used simple Feedforward network.</li>
<li>I added a new <code>concatenate</code> function to Ndarray and Matrix module, this function is able to concatenate a list of ndarrays/matrices based on the specified axis.</li>
</ul>
<h4 id="week-22-for-liang-wang">Week 22 for Liang Wang</h4>
<ul>
<li>I spent a lot of time in refactoring the API in neural module, and added several merge layers (add/mul/dot) into the module.</li>
<li>I finished the first version of <code>Owl_neural_graph</code> module. Owl can make a neural network of DAG topology. The new api is also easier to use. For example, making a convolutional neural network as below ```ocaml open Owl_neural;; open Owl_neural_feedforward;;</li>
</ul>
<p>let nn = input [|28;28;1|] |&gt; conv2d [|5;5;1;32|] [|1;1|] ~act_typ:Activation.Relu |&gt; max_pool2d [|2;2|] [|2;2|] |&gt; conv2d [|5;5;32;64|] [|1;1|] ~act_typ:Activation.Relu |&gt; max_pool2d [|2;2|] [|2;2|] |&gt; dropout 0.1 |&gt; fully_connected 1024 ~act_typ:Activation.Relu |&gt; linear 10 ~act_typ:Activation.Softmax in print nn;; ```</p>
<h4 id="week-23-for-liang-wang">Week 23 for Liang Wang</h4>
<ul>
<li>I studied how the primitives of distributed computing are designed in Julia.</li>
<li>I implemented the experimental feature of distributed computing in Owl: for neural module and ndarray module.</li>
<li>I implemented ndarray.any module, it is an n-dimensional array module that supports any types besides numerical types.</li>
</ul>
<h4 id="week-24-for-liang-wang">Week 24 for Liang Wang</h4>
<ul>
<li>I had been working on interfacing to CBLAS and LAPACKE last week. I wrote a parser to generate the interface automatically from cblas.h and lapacked.h. I also used Ctypes but the giant &quot;foreign&quot; function makes compilation extremely slow. I tried a couple of solutions then ended up using the c_stub code generated by ctypes but generate ocaml_stub myself in the parser. The parser also generates mli file to make sure the type signature is correct. This solution achieves both the strictness on type and efficiency on compiling.</li>
<li>Currently, Owl implements a full interface to all CBLAS and LAPACKE functions (over a thousand). These code are generated automatically, but I will write high level interface myself later this month.</li>
</ul>
<h4 id="week-25-for-liang-wang">Week 25 for Liang Wang</h4>
<ul>
<li>I spent a lot of time in writing the interface between Owl and low-level interface to CBLAS and LAPACKE.</li>
<li>I started rebuilding the documentation of Owl, studied some new tools and also tried to find a new place to host the docs.</li>
<li>I have improved several functions in matrix module.</li>
</ul>
<h4 id="week-26-for-liang-wang">Week 26 for Liang Wang</h4>
<ul>
<li>Most of the time was spent in redesigning the linear algebra module. The new module is built atop of Owl's native interface to CBLAS and LAPACKE.</li>
<li>I was enhancing Owl's core functions: most of the vectorised math functions now support complex numbers.</li>
</ul>
<h4 id="week-27-for-liang-wang">Week 27 for Liang Wang</h4>
<ul>
<li>I have been working on Owl's dependency last week. Due to the recently added interface to CBLAS and LAPACKE, Owl relies on OpenBLAS. However, CentOS does not provide the corresponding binary format of OpenBLAS. Building from source code using conf-openblas seems tricky. Anil suggested submitting an RPM.</li>
<li>I enhanced core functions in Owl, e.g., by add a new function to generate magic square matrix.</li>
<li>Owl was posted on Hacker News. This brought in a lot of publicity so I improved the documentation a bit.</li>
</ul>
<h4 id="week-28-for-liang-wang">Week 28 for Liang Wang</h4>
<ul>
<li>I have been experimenting how to share small code snippets to extend Owl's numerical functionality. I implemented a &quot;zoo&quot; directive to let user share code snippets through gist.</li>
</ul>
<h4 id="week-29-for-liang-wang">Week 29 for Liang Wang</h4>
<ul>
<li>I spent most of my time last week in enhancing the neural network module. The code in neural_graph module has been refactored and feedforward module will become obsoleted in the future version.</li>
</ul>
<h4 id="week-30-for-liang-wang">Week 30 for Liang Wang</h4>
<ul>
<li>I migrated the examples and performance tests in Owl to the newly introduced zoo system.</li>
<li>The indexing and slicing functions in Owl still needs enhancement. I also started studying the extension points in OCaml.</li>
</ul>
<h4 id="week-31-for-liang-wang">Week 31 for Liang Wang</h4>
<ul>
<li>Enhance neural network modules, try to recreate Google's Inception for image classification.</li>
</ul>
<h4 id="week-32-for-liang-wang">Week 32 for Liang Wang</h4>
<ul>
<li>Refactor neural network module using functor, the new neural network module supports both single and double precision.</li>
<li>Replace Owl's old optimisation engine with the one in neural module.</li>
</ul>
<h4 id="week-33-for-liang-wang">Week 33 for Liang Wang</h4>
<ul>
<li>Refactor the CBLAS interface, the number of functions is significantly reduced by providing a generic interface for S/D/C/Z types.</li>
<li>Optimise the core functions in Ndarray. I did some experiments trying to unifying matrix and ndarray types. It is doable but the current concern is then performance. Some operations like broadcast is faster in Matrix module than in Ndarray module.</li>
<li>Tune the interface between Actor and Owl, did some distributed learning experiments.</li>
</ul>
<h3 id="author-romain-calascibetta">Author Romain Calascibetta</h3>
<h4 id="week-16-for-romain-calascibetta">Week 16 for Romain Calascibetta</h4>
<ul>
<li>A robust implementation of email (I check with a complete suit test from another implementation in PHP and JavaScript)</li>
<li>A robust implementation of meta-data of email (the header of email), it's compliant with old and new standard - 822, 2822 and 5322)</li>
<li>A beginning implementation of multipart email (I implemented Base64 and QuotedPrintable compute for encoded data)</li>
<li>Implementation of inline encoded data (compliant with the standard 2047)</li>
</ul>
<p>You can see all at: <a href="https://github.com/oklm-wsh/MrMime" class="uri">https://github.com/oklm-wsh/MrMime</a></p>
<h4 id="week-17-for-romain-calascibetta">Week 17 for Romain Calascibetta</h4>
<ul>
<li>I fixed some bug with parsing of email and header</li>
<li>I implemented the RFC 5321 (to have a literal domain in an email) and use Ipaddr library for this part</li>
<li>I implemented the validator website (http://oklm-wsh.github.io/Validator/validator.html) with some tests of email</li>
<li>I implemented the header fields from RFC 2045</li>
<li>I attacked the implementation of RFC 2046 (a multipart email)</li>
<li>I implemented a PPX to inject an IANA database in MrMime project (and I talked about that with Rudy for an integrate of that in Cohttp maybe)</li>
</ul>
<p>I talked with Richard Mortier and I think I will avoid the implementation of RFC 3798 (to permit a long parameter in a Content-Type field) and move fast to the implementation in a unikernel when I finish the multipart. So I think it is the last last RFC (to much RFC ...).</p>
<h4 id="week-19-for-romain-calascibetta">Week 19 for Romain Calascibetta</h4>
<ul>
<li>As you know, I released Syndic 1.5 with ptime to compile in MirageOS. Hannes merged this change in Canopy</li>
<li>I optimized Decompress and I won 4 MB/s in Inflate</li>
<li>Jeremy Yallop send me a snippet for Decompress to win 2 MB/s (I didn't try this snippet yet but it is my TODO)</li>
<li>I came back to MrMime and fixed little bug in multipart parsing</li>
<li>I reorganized MrMime to have a better interface</li>
<li>I tried to use ocaml-imap to communicate with my GMail and it's work fine</li>
<li>But I'm focussing on the test of parsing now so I think the next, I will do just a many test to prove the maturity of MrMime (I already started)</li>
<li>May be I cook some cookies tomorrow for Monday :)</li>
</ul>
<h4 id="week-20-for-romain-calascibetta">Week 20 for Romain Calascibetta</h4>
<ul>
<li>I fixed some little bug with MrMime and the &quot;real world&quot; email</li>
<li>Firstly, I use a script with fetchmail program to download my email</li>
<li>But, I implemented a library to communicate with my GMail (with the POP3 protocol), you can see the project: https://github.com/oklm-wsh/Jackson (it's a little project, and it just a prototype to test MrMime)</li>
<li>So I continue to fix MrMime with the real world and automatize the test suite</li>
<li>At the same time, I look sessions type and GADT in OCaml to create a tool to describe a protocol (like POP3 or SMTP) with GADT (so a typed protocol), may be if I have a good result with GADT (because it's very complex), I use that for Jackson and for the implementation of SMTP</li>
<li>So not specifically productive but, step by step, I have a little prototype to communicate with GMail (or another service) and a resilient implementation of email</li>
</ul>
<h4 id="week-21-for-romain-calascibetta">Week 21 for Romain Calascibetta</h4>
<ul>
<li>I updated MrMime with a new program maildir. You can execute this program with ./maildir -p /path/to/your/mails/ -n LFif the newline of your email is LF character (and it's probably your case with mac osx). I retrieve two difficulties about the parsing:</li>
<li>The difficulty to predict the end of the email - so may be you catch an infinite loop when you scan your emails</li>
<li>The latency with Base64 and QuotedPrintable decoder (because, for each character, we need to try the boundary parser to stop the decoder)</li>
<li>So you can use the project on two way. The first way is to use maildirbinary. But if you catch a infinite loop for example (or a weird exception), you can try with a specific email with utop -init test.ml(the second way). At this moment, you can compile the project with debug information (with ./configure --enable-trace and make install) and see where MrMime fails. The parsing is resilient with the malformed header. So now, I will implement the pretty-printing of email and prove if the parsing and pretty-printing is bijective (just to be on the safe side).</li>
</ul>
<p>(you need to configure the project with --enable-teststo get the maildirbinary)</p>
<h4 id="week-22-for-romain-calascibetta">Week 22 for Romain Calascibetta</h4>
<ul>
<li>I optimized the Base64 decoder but MrMime is slow with QuotedPrintable (but I have an idea to fix that)</li>
<li>MrMime is more resilient with bad email (like an email without Fromand Dateinformation)</li>
<li>I fixed some little bug (infinite loop, order of meta-data, multipart inception, unstructured data, and raised exception)</li>
<li>I retrieved a regression with my test (so, I have a good tests suite) and I fixed this regression - it's a specific problem with a wrong example from the standard RFC 822</li>
<li>I started the implementation of pretty-printing, so I continue the prototype (I am inspired by the Format module from OCaml standard lib to respect the 80 characters rules)</li>
<li>I will use an archive from the caml-list (from daniel) to have a good tests suit about the parsing of email (it's a huge example about the old/bad emails)</li>
<li>So this week, it's just some fixes and a minimal prototype about the pretty-printing :s</li>
</ul>
<h4 id="week-23-for-romain-calascibetta">Week 23 for Romain Calascibetta</h4>
<ul>
<li>So I focused this week on my abstract for the ICFP (so Richard corrected the paper and I have sent Friday)</li>
<li>I continue to implement the pretty-printer of MrMime (I implemented without regresssion with my unit test)</li>
<li>I start to look S/MIME (secure mail) - so may be I will implement with ocaml-tls the secure mail one time</li>
</ul>
<h4 id="week-24-for-romain-calascibetta">Week 24 for Romain Calascibetta</h4>
<p>I did some technical updates in MrMime:<br />
* First, I added an abstraction about the operating system (Windows and Unix) * I reorganized the project to produce a good low-level API to manipulate an email * I finished, as you know, the encoder (and I can produce an email now) * I optimized the Base64 and the QuotedPrintable decoder (with tailcall optimization) * I finished the pretty-printing of an email * I fixed some little bugs between the encoder and the decoder * And I added the support of UTF-8 with the uutfsoftware by daniel - now, I have only 3 errors with 2000 mails (so ~0.15% fails - so MrMime is more resilient) * I talked with Daniel about the API and the support of UTF-8 (because an email can have many encoding data) and the main thing is to normalize the email on one encoding, the UTF-8. But, for that, I need another software to normalize any encoding to UTF-8 (daniel told me who will do) * May be, the next week, I will start the SMTP protocol with the unikernel</p>
<h4 id="week-25-for-romain-calascibetta">Week 25 for Romain Calascibetta</h4>
<ul>
<li>I continue to optimize MrMime and I will use the Bigstring (which is more faster than the String module) with my RingBuffer</li>
<li>I finished to implement the interface (recommended by david) of my parser combinator (it is the same interface as the angstorm library from seliopou but with a different backend - as you know I use a ring-buffer)</li>
<li>So I continue the large background work on MrMime and keep the stability (and avoid any regression) with my unit tests. So, nothing impressive but needed to concurrent any other implementation of email :)</li>
</ul>
<h4 id="week-26-for-romain-calascibetta">Week 26 for Romain Calascibetta</h4>
<ul>
<li>I continue to improve the interface of MrMime</li>
<li>I succeed to use the interface of david (it's the same of angstorm project) - now, the user can produce its parser</li>
<li>I find some littles regressions with my big test (my 2000 emails) - I will fix that</li>
<li>We can use the bigstring instead the string module now (so, possibly, we can improve the performance - but I need some tests about that)</li>
<li>I continue to documente the project and after we can have a release of MrMime</li>
<li>For this week, I will work on Decompress (as Richard advise me) about the performance, I already a PoC from zlib so I will test it.</li>
<li>I think I continue to work the morning on MrMime (because is just some fixes) and after I work on Decompress.</li>
</ul>
<h4 id="week-27-for-romain-calascibetta">Week 27 for Romain Calascibetta</h4>
<ul>
<li>I defunctorized Decompress, so the API is more simply and I won 2 Mb/s for the inflate but I losted 2 Mb/s for the deflate</li>
<li>Now Decompress uses memcpy function instead memmove (standard function used by OCaml), it's a technical aspect but a big technical point about the portability on Decompress (on Xen architecture specifically). So, I talk about that with Jeremy and we think we have no problem and may be it's a good change to improve the performance of Decompress</li>
<li>I used a project from LexiFy, landmarks (Thomas advised me to use that), and Spacetime from Mark to find the bottleneck in Decompress and I found this Friday. I have an idea to optimize Decompress (again and again) but I think, we found the the big problem about the performance in Decompress (and it converges with Jeremy's idea)</li>
</ul>
<h4 id="week-28-for-romain-calascibetta">Week 28 for Romain Calascibetta</h4>
<ul>
<li>I push my big change to MrMime, so Richard launched a test with ~18 000 emails and all emails are ok (we catch no error).</li>
<li>We find a performance problem (with the multipart and the quoted-printable encoding) but it's a specific problem (so when I have a time, I will fix this problem)</li>
<li>But, overall, MrMime is more faster (it's the result of improvement of internal buffer)</li>
<li>After, I worked on Decompress and I defunctorized the project, I optimized the translation between op-code and character and I avoided some closures allocations, but, with all this point, with Jeremy, we can't notice any imrpovement :disappointed:</li>
<li>So, I will try a deforestation of Decompress and we will see if we have a good result</li>
<li>For the hackaton, I worked on Decompress, but, as I said, no big change and just some experimentals modifications.</li>
<li>For the next week, I will start to fix some bug in ocaml-git as Richard advised me. Voilà!</li>
</ul>
<h4 id="week-29-for-romain-calascibetta">Week 29 for Romain Calascibetta</h4>
<ul>
<li>I finished fixing some bugs with Decompress, so we have a stable version after many optimization. As I explained, we don't have a big improvement on the performance but Jeremy will take the relay</li>
<li>After Richard focused me on a performance problem in MrMime, so I fixed the bug. It's a technical point bug I wait Richard to launch an other test</li>
<li>I started a little library to see any differences between an email before and after decoding/encoding, I think, I will finish this mini-project this week-end - and may be it's a useful project for irmin</li>
</ul>
<h4 id="week-30-for-romain-calascibetta">Week 30 for Romain Calascibetta</h4>
<ul>
<li>I just improved (again!) the interface of MrMime:</li>
<li>So the design of the API is approved by Daniel and I wait a feedback of Richard to know if we will release a new version or not</li>
<li>After, I did go to docker to meet Thomas and prepare a TODO list for ocaml-git. Now, I have a clear idea to what I need to do for this project.</li>
</ul>
<p>Not a big week so, but a good week to clarify some points about MrMime and ocaml-git.</p>
<h4 id="week-31-for-romain-calascibetta">Week 31 for Romain Calascibetta</h4>
<ul>
<li>I talked with Christophe about the optimization, I have not yet advised Jeremy about the benchmark but I keep this thing when Jeremy will try to optimize Decompress</li>
<li>I move Decompress to topkg because Anil wanted a Dockerfile inside the project</li>
<li>Richard retested MrMime and I fixed some bugs and optimized some computations. Now, we compute 180 mails per second and MrMime fails on 500 emails with 815 000 emails! So it's not bad, we will fix the rest with Richard when he comes back</li>
<li>I fixed a little bug for Qi Li on the Xen librairies</li>
<li>I continue to document MrMime</li>
<li>And I looked inside ocaml-git to understand where I need to start but I does not do revelant something for the moment.</li>
</ul>
<h4 id="week-32-for-romain-calascibetta">Week 32 for Romain Calascibetta</h4>
<ul>
<li>I continue to document MrMime, you can see the documentation at this link: http://oklm-wsh.github.io/MrMime/ (not very exciting)</li>
<li>I started a new prototype for ocaml-git, the name is sirodepac, you can see the reopository at this link: https://github.com/dinosaure/sirodepac For the sirodepac, the goal is to created a non-blocking encoder/decoder. So, Thomas follows the project and it's works for the moment despite some little bugs.</li>
</ul>
<h4 id="week-33-for-romain-calascibetta">Week 33 for Romain Calascibetta</h4>
<ul>
<li>I continue to work on a prototype of ocaml-git. I just finished the decoder for the IDX file, I will try the implementation next week.</li>
<li>I continue to document MrMime - Richard showed me some emails when MrMime fails. These emails are wrong and the thing is, if you use MrMime by the best effort way, you can extract all information from the email, so MrMime can parse these email by the hard way - not the simple way.</li>
</ul>
<h4 id="week-5-for-romain-calascibetta">Week 5 for Romain Calascibetta</h4>
<h4 id="work-on-the-implementation-in-decompress-3">Work on the implementation in Decompress</h4>
<p>Move the implementation of the compression (deflate) in the same way of the decompression. With the work of Yallop, the implementation of <em>blosclz</em> and the advises of Thomas, I try to use a pure state for the Lz77 compression (first layer of Decompress) and the Zlib compression (second layer of Decompress) to use this implementation in <code>ocaml-git</code> to pack a git state.</p>
<p>For the moment, I have a non-blocking implementation of the Lz77 compression with theses changes: * pure state * non-blocking computation * remove a compute of a window - that means when the algorithm search a pattern, we limit to the input of the user. So, if the user compute the compression with a chunk of 4096 bytes (for example), we search a pattern only on this chunk (but theorically, we can keep ~ 28671 bytes) and the ratio between the literal and the distance for this compression will be bad. But, in a practical world, we compute the compression with a chunk of 32K bytes - and in this way, we have an optimal compression.</p>
<p>Finally, for a file (like an executable), we have a ratio about 1/3 for literals and 2/3 for matches - so 2/3 of compression without Huffman compression.</p>
<p>Now, I attack the Zlib (Huffman) compression in the same way (pure state and non-blocking) to get the new release of Decompress.</p>
<h4 id="ocaml.org-1">ocaml.org</h4>
<p>I try to find a bug inside ocaml.org about the feed generator (OCaml Planet). In the same time, I found lot of website with a bad or unaccesible feed. So, I sent an e-mail to advise some persons about that - like the website of Mirage or ocaml.io.</p>
<p>Chris00 fixed the bug (server side bug).</p>
<h4 id="encoding-and-mr.-mime-2">Encoding and Mr. MIME</h4>
<p>It's about the UTF-7. Some e-mails don't respect the encoding described by the standard (RFC 6532). The point is to create a library (but I already discuss about that with Daniel) to convert any encoding to UTF-8.</p>
<p>Mr. MIME has this problem, we respect the standard but not the practical e-mail, we need to be more resilient about that.</p>
<h4 id="week-6-for-romain-calascibetta">Week 6 for Romain Calascibetta</h4>
<h4 id="work-on-the-implementation-in-decompress-4">Work on the implementation in Decompress</h4>
<p>I continue to implement the compression. Good news, the dynamic compression works with the dbuenzli's interface and the static compression should work too. The first layer (Lz77 compression) is done - the question is, it's good to functorize the implementation of the Lz77 or not ? I need to fix a bug in the flat compression - but it's very easy, may be one or two hours to fix that. Then, I will polish the interface. So, the second layer (Zlib compression) is most done.</p>
<p>Now, we have a complete interface for Decompress (with differents flush methods, like <code>partial</code> for SSH, <code>full</code> and <code>sync</code>). It's possible to change the frequencies before than Decompress computes a canonic Huffman tree. That means, it's possible to specialize the canonic Huffman tree with an external database of frequencies.</p>
<p>After polishing, I will do some benchmark with <code>landmarks</code> and try to compare with <code>zlib</code>. And, I will make the new release of Decompress (tagged 1.0). Then, I will attack the serialization to a PACK file.</p>
<p>UPDATE: I finish to fix the flat compression bug, I will make a good test suites.</p>
<p>UPDATE: I just add a test suites and <code>decompress.ml</code> works!</p>
<h4 id="encoding-and-mr.-mime-3">Encoding and Mr. MIME</h4>
<p>I don't have internet for now (for two weeks) so I can't see the database about the translation between an encoding and utf-8. But when I can get this database, I will start the new library (the name will be <code>uuuu</code>) and normalize all output of Mr. MIME to utf-8.</p>
<hr />
<p>May be, I will push (I can't for the moment because I don't have internet) my work in <code>dinosaure/sirodepac</code> repository in few days.</p>
<h4 id="week-7-for-romain-calascibetta">Week 7 for Romain Calascibetta</h4>
<h4 id="work-on-the-implementation-in-decompress-5">Work on the implementation in Decompress</h4>
<p>I finish to polish Decompress (test and documentation). So all is ok and the new version of Decompress (0.5) is ready. I choose to create the 0.5 version (and not the 1.0) because I insert an experimental thing in API and I would like to create a new test and prove that is more reliable to get the 1.0 version.</p>
<p>Indeed, I inserted the flush methods (<code>partial</code>, <code>full</code> and <code>sync</code>) and you use Decompress without these flush methods. After, all code is in OCaml (<code>alder32</code> compute and <code>memcpy</code> implementation).</p>
<p>Apparently, Decompress works with solo5, so it's a good news!</p>
<p>May be, I will push the new version in the hackathon because I don't have a good internet for the moment.</p>
<h4 id="ocaml-git-and-sirodepac-1"><code>ocaml-git</code> and <code>sirodepac</code></h4>
<p>I continue to work on the <code>sirodepac</code> at the same time. I just create a mini non-blocking decoder. May be I will implement a little fun interface with <code>ocaml-d3</code>. So I have a full deserialization of PACK and IDX git file and we can make easily the glue between <code>sirodepac</code> and <code>ocaml-git</code>.</p>
<p>So, I will create a mini non-blocking encoder now and after I will attack the main purpose of my mission, the create of the PACK file - to fix the <code>git push</code>. Thomas point me some bug, so I will focus now on this :) !</p>
<h4 id="mr.-mime-and-the-buffer-1">Mr. MIME and the buffer</h4>
<p>When I create the mini non-blocking decoder, I find a new way to handle the buffer and let the user to grow the buffer. It's the best choice (about the security) to let the user to grow the buffer. For the moment, it's Mr. MIME to grow the buffer and you can observe that but not precisely.</p>
<p>So, I push this big thing in my TODO. It's not complex but this idea changes the API a lot.</p>
<p>Voilà!</p>
<h4 id="week-8-for-romain-calascibetta">Week 8 for Romain Calascibetta</h4>
<h4 id="decompress-19">Decompress</h4>
<p>I rework on the interface and add some conveniences functions to manipulate an integer (<code>int16</code>, <code>int32</code>, <code>int64</code>) with a string or a bigstring. And I put in the interface the definition of the type <code>st</code> and <code>bs</code> to prove the exhaustivness of the GADT <code>B.t</code> outside the library.</p>
<h4 id="sirodepac-and-ocaml-git-1"><code>sirodepac</code> and <code>ocaml-git</code></h4>
<p>I start the encoding of the meta-data, so I find a way to serialize the data, so I start to serialize the user, the commit, etc. But I don't have a relevant result for the moment. I think a lot about the optimization and try to implement an amortized data structure.</p>
<p>I create a mini-encoder in the same way as <code>faraday</code> but with my GADT between <code>string</code> and <code>bigstring</code>. Then, I create a little library like a <code>printf-like</code> for <code>faraday</code> where is possible to specify an optimized <code>blitter</code>.</p>
<p>I need to explain, for example a tag data can be described by a format for the deserialization, like that:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> binding ~key ~value = <span class="dt">string</span> key *&gt; sp *&gt; value &lt;* lf
<span class="kw">and</span> tag =
  binding ~key:<span class="st">&quot;object&quot;</span> ~value:hash
  &gt;&gt;= <span class="kw">fun</span> obj -&gt; binding ~key:<span class="st">&quot;type&quot;</span> ~value:kind
  ...</code></pre></div>
<p>So I would like the same for the encoder. I looked the article about the GADT from <span class="citation" data-cites="drup">@drup</span> and I create an convenience interface with GADT to describe how to serialize a data with <code>faraday</code> and for the same example, we have:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> tag =
  (Const<span class="kw">.</span><span class="dt">string</span> <span class="st">&quot;object&quot;</span>) ** sp ** <span class="dt">string</span> **! lf **
  (Const<span class="kw">.</span><span class="dt">string</span> <span class="st">&quot;type&quot;</span>) ** sp ** <span class="dt">string</span> **! lf **
  ... nil</code></pre></div>
<p>This formatter expect somes arguments and you can decide to write or to schedule the writing in the buffer. Another fix is to specify a fast <code>blit</code> function to my GADT if you want - but I don't find a relevant example. It's like <code>printf</code> but for <code>faraday</code>.</p>
<p>I informed Spiros about that but he does not talk to me yet so I don't know if I extract this module in a new library (I can) or if I let this as an internal things for <code>sirodepac</code>/<code>ocaml-git</code>.</p>
<p>I <em>optimize</em> <code>sirodepac</code> and use only a <code>bigstring</code>, may be a good way is to test with spacetime to know how many <code>bigstring</code> I use. But, I found a bug, I can't reach a valid SHA1 hash when I deserialize the pack file. So, I will inspect that and I inform Thomas about that to know more precisely how to hash a git object. But a good things is that I start the encoding of <code>sirodepac</code> know.</p>
<p>In the same time, I look about the Merkle tree. It's a structure used by Git and the P2P protocol to provide a reliable data. I look a C implementation, and containers to propose an implementation.</p>
<p>About <code>ocaml-d3</code>, I don't have any work about that but it's just for fun. May be in hackathon, I will play with that but not for this moment.</p>
<h4 id="mr.-mime-6">Mr. MIME</h4>
<p>Nothing this week about Mr. MIME, I continue to keep in my head the TODO.</p>
<h4 id="next-things-1">Next things</h4>
<p>Now, I will create a test suites for <code>sirodepac</code> to prove that it works :) ! And, if I have a time, I will create a test suit for Decompress, specifically about the flush method.</p>
<h4 id="week-9-for-romain-calascibetta">Week 9 for Romain Calascibetta</h4>
<h4 id="decompress-20">Decompress</h4>
<p>I fix a bug about the window bits. Indeed, the zlib format only allow a window bits between 8 and 15. Then, I launched a test about that and we have a big bug, I put this in my TODO. In fact, when we work on a zlib flow with a specific window bits (&lt;&gt; 15), the inflater (the decompression) does not works with my deflater (the compression). But (and it's why it's very weird), <code>camlzip</code> works with my input - so the bug is only available for the inflater and we need to keep the size of the window to <code>1 &lt;&lt; 15</code> bytes and not to the <code>1 &lt;&lt; window_bits</code> (with <code>window_bits</code> is a value from the zlib header). So it's about the window inside the inflater.</p>
<p>Another weird things is with this change, the inflate for a flat flow (no compression, so no distance, so no need to use the window) does not work. So, yes, it's w.t.f and I need to focus on that one big time - because the bug is very deep.</p>
<p>But, I did a release of Decompress now. It's stable and I integrate this change in Canopy!</p>
<p>I test by my hand the window size/level/flush method with my alcotest to avoid any write in any file. So I launched like 35 000 tests with Decompress and compare with camlzip and all is ok. I think Decompress is robust :) .</p>
<h4 id="ocaml-gitsirodepac-1"><code>ocaml-git</code>/<code>sirodepac</code></h4>
<p>I find an another serious bug about <code>ocaml-git</code> and <code>sirodepac</code>. It's about the size of the pack-file. In fact, the offset delivered by the IDX file can be stored inside a int64 variable. That means the offset can be huge and can be upper than what OCaml can store inside a bigstring/string.</p>
<p>I found this problem in <code>cohttp</code> when it's possible to send a huge file by the HTTP protocol (like a video of Game Of Thrones). So, by this constraint, it's mandatory (if we want to compute all PACK file) to work on a flow of chunk of a PACK file - because the PACK file can be (easily) bigger than [Sys.max_string_length] and in this case, we need to compute the PACK to some chunk of [Sys.max_string_length].</p>
<p>But <code>sirodepac</code> handles that! When we compute a PACK file, we can compute this by some chunk. However, it's about the delta-fied object. In this case, we need to compute entirely the PACK file because the offset can be absolute (if the hunks refer to a hash) but in the main case, the offset is relative and we need to know if this relative offset can't be bigger than [Sys.max_string_length].</p>
<p>It's a complexe problem and I will discuss in the hackaton about that with Thomas to know what is the best way to compute an huge PACK file.</p>
<p>About the Merkle tree, I don't find a good case to use that so ... I go away from that.</p>
<p>About <code>ocaml-d3</code>, no time.</p>
<p>I fix the bug with SHA1 and I verify my implementation with the encoder/decoder. All is ok and I test <code>sirodepac</code> with a big PACK file from linux. That means the decoder and the encoder are good - we produce a good output from a good input and the SHA produced is correct, another thing, the offset of the SHA1 (from the IDX file) correspond to the offset of my parser. So, my program is reliable :) !</p>
<p>I will retake an old project, <code>Digestif</code> to implement the digest function for the new Hash of <code>git</code>. I spoke with Thomas about that and we find a mail to explain what happens for <code>git</code> after we can break the SHA1 and the new hash is BLAKE2b. So, for the hackathon, I will implement that. I spoke with hannes to know if it's cool to insert this new hash in Nocrypto but we think it's a bad idea (and, obviously, I don't find any BLAKE2b implementation in OCaml).</p>
<h4 id="farfadet-12">Farfadet</h4>
<p>I spoke with Seliopou and we fixed somethings in <code>Farfadet</code>. It's an high level interface of <code>Faraday</code>. So we decided to create a new repository about that in top of <code>Faraday</code>.</p>
<p>You can look the project at: https://github.com/oklm-wsh/Farfadet</p>
<h4 id="mr.-mime-7">Mr. MIME</h4>
<p>Nothing about that. I spoke with rgrinberg about the interface and I keep all things of my TODO.</p>
<h4 id="week-10-for-romain-calascibetta">Week 10 for Romain Calascibetta</h4>
<h4 id="decompress-21">Decompress</h4>
<p>Decompress is released in version 0.5. So, it seems work (no issue for this moment). I have a bug about the opam file and hannes just fixed that. I will report this change in opam-repository.</p>
<p>Finally, I decided to let 6 months to get the new release (1.0) of Decompress.</p>
<h4 id="sirodepacocaml-git-1"><code>sirodepac</code>/<code>ocaml-git</code></h4>
<p>I started the implementation of the BLAKE2B hash function. I send a message to david to know if it's the best to integrate this hash function inside nocrypto or outside (and if the best is to create a new library, may be the best is to locate all common hash function inside a new library).</p>
<p>So, fortunately, Eyyub (a friend) created a projet inside the <code>oklm-wsh</code> repository to aggregate the common hash function (like SHA1, SHA256, etc.). So, I will reuse this project to provide the BLAKE2B hash function.</p>
<p>For this moment, I look the reference implementation of BLAKE2B and the SSE implementation (to compute the hash fastly). So, I think, I can do a release this next week.</p>
<p>Nothing else about <code>ocaml-git</code>. I met in the hackthon a manager of a dev team for a git project in go. So I explained what is git and why is the best to store a data, a commercial job :p .</p>
<h4 id="farfadet-13">Farfadet</h4>
<p>So, I created the new repository <code>Farfadet</code>. I spoke with Spiros about the API and we fixed together the API.</p>
<p>Another good news is from <span class="citation" data-cites="Drup">@Drup</span>. In fact, I improved the API after my release and it seems good. So, I need to read the code and write the documentation now (and provide a good example - asked by KC) but I'm focus on the BLAKE2B hash now.</p>
<h4 id="mr.-mime-8">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="week-11-for-romain-calascibetta">Week 11 for Romain Calascibetta</h4>
<h4 id="decompress-22">Decompress</h4>
<p>I fix the distribution of Decompress noticed by <span class="citation" data-cites="hannes">@hannes</span>.</p>
<h4 id="blake2b-digestif-8">BLAKE2B / Digestif</h4>
<p>I just finish the implementation of BLAKE2B in C. I did not received yet a response of David about <code>nocrypto</code> and where is the best place to find the implementation of BLAKE2B (inside <code>nocrypto</code>, in a new library and if we choose this case, may be it's better to extract the Hash function of <code>nocrypto</code> in the new library).</p>
<p>So, the implementation works. I did not do any benchmark but may be it's good to put this thing in my TODO. May be, if I have a time, I will implement the same hash but in pure OCaml (to compile to JavaScript) and let the user to choose the C stub or the OCaml code.</p>
<p>And, in my TODO, I keep the SSE implementation.</p>
<p>If I have no response of David for the next month, I will release <code>Digestif</code> as a common library for the hash function. I will keep obsiously the Copyright Header inside <code>Digestif</code> for David (and Vincent Hanquez) for some parts of the code. But, for me, this project can be a redundant project. I prefer to discuss before but ...</p>
<h4 id="sirodepac-ocaml-git-7">sirodepac / ocaml-git</h4>
<p>I put an exhaustive explanation of a the previous big problem inside <code>sirodepac</code>/<code>ocaml-git</code> about the limitation of OCaml for the mapped file and how to fix that and how <code>git</code> fix this problem. But ... the comment is in french - it's hard for me to explain that in english. The most important point is to keep in my mind the problem for a long time (because, I think, if we want to fix that, we need to implement a complexe cache system).</p>
<p>I fix the implementation about the endianess too.</p>
<p>And I start the serialization of the IDX file. I will create a test between the encoder and the decoder to check if my implementation is good.</p>
<p>The next goal is to implement a patience diff and look how <code>git</code> produce (in the detail) a PACK file.</p>
<h4 id="farfadet-14">Farfadet</h4>
<p><span class="citation" data-cites="Drup">@Drup</span> looked the code and developped a new (seems good) API for Farfadet. I wait the release of <span class="citation" data-cites="seliopou">@seliopou</span> to look the code of <span class="citation" data-cites="Drup">@Drup</span> and decide to merge or not - but I think I will merge. In the same moment, I will write the documentation as KC expected.</p>
<p>So same as the previous week.</p>
<h4 id="mr.-mime-9">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="week-12-for-romain-calascibetta">Week 12 for Romain Calascibetta</h4>
<h4 id="decompress-23">Decompress</h4>
<p>Nothing to do. <span class="citation" data-cites="engil">@engil</span> found a bug in Canopy but I think, it's not about Decompress. Indeed, I use Decompress in <code>sirodepac</code> and all is ok. But I will inspect what is wrong - because, may be it's <code>ocaml-git</code>.</p>
<h4 id="blake2b-digestif-9">BLAKE2B / Digestif</h4>
<p>I continue to polish this package. I try to provide an interface with the <code>Bytes.t</code> modules and break the <em>hard</em> dependency with <code>cstruct</code>. But, in fact, the end-user can use <code>cstruct</code> if he wants (<code>cstruct</code> is a <code>bigstring</code> and by default, the API provide a <code>bigstring</code> compute). Another point is to separate the pure implementation of the hash function in OCaml (in Digestif library) and a C implementation with an OCaml interface (in Rakia library). So, Digestif can be used in Mirage, JavaScript and OCaml - but I need to work a long time in this project.</p>
<p>I just finish to create a generic test suite between <code>bigstring</code> and <code>bytes</code> and I need to fix the problem with the <code>bytes</code> in the Rakia library. Then, I will re-implement the hash function in pure OCaml.</p>
<h4 id="sirodepac-ocaml-git-8">sirodepac / ocaml-git</h4>
<p>I finished the serialization of the IDX file. I talked with <span class="citation" data-cites="samoth">@samoth</span> about that and all works fine. To test, I deserialize an IDX file, serialize the IDX file, and deserialize the output and compare the result. I use a radix tree to store the IDX file and I have a lazy implemenation (like <code>ocaml-git</code>).</p>
<p>I try to implement the patience diff (without <code>core_kernel</code> package) to try to serialize the PACK file. Indeed, inside the PACK file, all git object was compressed by Decompress and by a diff function. So, I already have a PoC in <code>sirodepac</code>. I don't know if I need to create a new package for this thing but the good thing is that we have no dependencies. When I check my implementation, I will implementation the core of the serialization of the PACK file.</p>
<h4 id="farfadet-15">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="mr.-mime-10">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="week-13-for-romain-calascibetta">Week 13 for Romain Calascibetta</h4>
<h4 id="decompress-24">Decompress</h4>
<p>Polish the documentation.</p>
<h4 id="blake2b-digestif-10">BLAKE2B / Digestif</h4>
<p>I just fixed the problem with <code>Bytes.t</code> in <code>Digestif</code>. So, I let the projet in my side but I keep in my head to implement the hashes functions in pure OCaml.</p>
<h4 id="sirodepac-ocaml-git-9">sirodepac / ocaml-git</h4>
<p>I move the internal structure to <code>Cstruct.t</code> to move my work in <code>ocaml-git</code> easily. The patience diff worked (without any other dependancies). I need to optimize a part of the algorithm (about the implementation of Dequeue from Simon Cruanes) but we can use it to serialize the PACK file.</p>
<p>Then, I looked a long time in <code>git</code> to understand the serialization. I talked with <span class="citation" data-cites="samoth">@samoth</span> about some informations and now all was clear to implement the serialization. My question was about the order of the git object before the serialization. Indeed, git has an heuristic to order the git object inside the PACK file and believe than this order is the best to apply a diff between the git objects.</p>
<p><code>sirodepac</code> (and <code>ocaml-git</code>) will follow this heuristic obviously.</p>
<p>Another good point was: I fixed the big bug about the limitation of OCaml for the huge PACK file. It's a complex point because it's about the architecture (32 / 64 bits) and the limitation of the native integer in the OCaml's runtime. I followed the implementation in <code>git</code> and it works! The solution is to map only a limited area of the PACK file, save this area as a <em>Window</em> and compute the object. If the requested object was not available in the current, we create a new <em>Window</em> and <em>map</em> a new area of the PACK file (and, obviously, this area contains the requested object).</p>
<p>Then, we keep a fixed-size bucket of <em>Window</em>s (that means, if we need a new window and the bucket is full, we will remove the oldest window) and we can compute any git object without any limitation!</p>
<p>So all continue to work and I will move my implemenation of the serialization of the git object to <code>Faraday</code> (because <span class="citation" data-cites="seliopou">@seliopou</span> will do a release).</p>
<h4 id="farfadet-16">Farfadet</h4>
<p>I will do a release of <code>Faradet</code> and check the PR of <span class="citation" data-cites="Drup">@Drup</span>.</p>
<h4 id="mr.-mime-11">Mr. MIME</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-8">TypeBeat</h4>
<p>So, it's new library to respond about <span class="citation" data-cites="dsheet">@dsheet</span> and a problem in <code>cohttp</code>. TypeBeat is a ligth library to parse the value of the <code>Content-Type</code>. This project was just a part of Mr. MIME but with the <code>Angstrom</code> dependancy.</p>
<p>However, I can't use <code>TypeBeat</code> in Mr. MIME. In fact, I need to know the implementation of the type <code>Angstrom.t</code> to do some mandatory optimisations.</p>
<p>I released the library, so I let <span class="citation" data-cites="rgrinberg">@rgrinberg</span> or <span class="citation" data-cites="dsheet">@dsheet</span> to use it in <code>cohttp</code>. I don't have a time to insert <code>TypeBeat</code> in <code>cohttp</code>.</p>
<p>Voilà!</p>
<h4 id="week-14-for-romain-calascibetta">Week 14 for Romain Calascibetta</h4>
<h4 id="decompress-25">Decompress</h4>
<p>I fixed the bug in Canopy about Decompress. As I said, the problem is come from the implementation of <code>inflator.ml</code>. It's a good new, that means than Decompress has no discovery bug.</p>
<p>This assumption is come from <code>sirodepac</code>. Indeed, I use a lot Decompress to deserialize/serialize the PACK file and I did not find a bug.</p>
<p>I created some issues in Decompress to show what is my goal for the next release.</p>
<h4 id="blake2b-digestif-11">BLAKE2B / Digestif</h4>
<p>Nothing to do.</p>
<h4 id="farfadet-17">Farfadet</h4>
<p>I released the first version of Farfadet (after the release of Faraday). I looked the implementation provided by <span class="citation" data-cites="Drup">@Drup</span> and I choose this one. This implementation is more confortable for any futur extension (we don't need to create a new GADT constructor to add a new writer).</p>
<p>So, I provided a good example, a serializer of JSON. It's just a example, I don't about the standard but the usability of Farfadet is very powerful!</p>
<p><span class="citation" data-cites="Drup">@Drup</span> told me to add a PPX then, I will think but not yet.</p>
<p>And, I provided a good documentation (I think). So, it's usable now.</p>
<h4 id="typebeat-9">TypeBeat</h4>
<p>Good news, <span class="citation" data-cites="seliopou">@seliopou</span> improved a lot <code>TypeBeat</code> and remove redundant code (came from Mr. MIME). I created a suit test. So, all is ok. I will do a new release in few weeks.</p>
<p>I improved the documentation and nothing else.</p>
<p>I asked to <span class="citation" data-cites="dbuenzli">@dbuenzli</span> if he wants a RFC822 date parser but I said no (and I know why :D). So, TypeBeat is finished.</p>
<h4 id="sirodepac-ocaml-git-10">sirodepac / ocaml-git</h4>
<p>After the release of Farfadet, I decide to use it in <code>sirodepac</code>. Obviously, it's not a mandatory part of the serializer/deserializer and, when I finish, we will talk about these dependancies.</p>
<p>The point is the deserialization/serialization of a git object is provided by Angstrom and Faraday/Farfadet library. It's an easiest way for me to maintain the serialization/deserialization, the code is much cleaner and we respect, again, the non-blocking assumption.</p>
<p>However, as I said, it's not mandatory to use it. In fact, I don't use the non-blocking assumption for the git object in my algorithm - I can but, it's not necessary (and may be not good about the performance).</p>
<p>I create a PoC of a function to get directly the git object without any compute with delta thing. So, you have directly the git object. I need to improve this function again (about the allocation) but it seems to be good as an API <em>easy-to-use</em>. Indeed, you just need the hash and some temp buffer to make the git object - but internnally, I create a big buffer and I think it's not mandatory so I will delete that and improve the performance (and the allocation).</p>
<p>I start the serialization. After the talk with <span class="citation" data-cites="samoth">@samoth</span>, I have a global and precise view of what we need to do. I implemented the <em>Window</em> other thing (not like my precedent report) and start the serialization without the delta thing for this moment.</p>
<p>But I sorted correctly the collection of the git object and compress correctly the git object with Decompress. I just need to know the politic treatment about the level of the compression. Indeed, I saw the git object was not compressed in the uniq and same way, it's depends on the kind of the git object and the size may be. I will look in <code>git</code> how to do this choice.</p>
<h4 id="ps-2">PS</h4>
<p>This week, I took a plane to Ho Chi Minh in Vietnam to go then to Cambodia (as you know), so I did not work this Thuesday (a little but not a lot, I was so tired by the plane). It's why I was not so productive this week. Voilà!</p>
<h4 id="week-15-for-romain-calascibetta">Week 15 for Romain Calascibetta</h4>
<h4 id="decompress-26">Decompress</h4>
<p>I found a bug in Decompress about a far distance and the window. It's about the <code>blit</code> function and the <code>Inflate</code> algorithm (the good news is that the <code>Deflate</code> algorithm has no error). Indeed, when we have a distance we can have 3 cases:</p>
<ul>
<li>the first is when the content of the window overlap the result. That means: the byte is not set yet, but when we advance in the window to write the new byte (from a old byte in window), we set the futur byte in the window. So, the all pattern is available only at the end of the <code>blit</code>.</li>
</ul>
<p>In this case, it's why we can't use <code>memmove</code> but <code>memcpy</code>.</p>
<ul>
<li>the second is when it's a far distance. When we <code>blit</code>, may be we delete some bytes considered as a pattern and these bytes was not saved in the output. It's happen because the result overlap the content of the window. In this case, we need to write at the same time in the window and in the output.</li>
</ul>
<p>So, we create a function <code>blit2</code> and write from a <code>src</code> to 2 <code>dst</code> (in this case, the window and the output).</p>
<p>A good news is that, when I fixed this bug, I fixed another bug. Indeed, in the <code>Deflate</code> algorithm, I avoid a compute of a far pattern because, when I try to inflate the result, I had some errors. Now, because I fixed the <code>Inflate</code>, I don't have error with a far pattern.</p>
<p>So, I need to do a new release now. But not yet, if I find a new bug, I don't want to release all the time. So, when I will make the PR in <code>ocaml-git</code>, I will release Decompress.</p>
<h4 id="blake2b-digestif-12">BLAKE2B / Digestif</h4>
<p>Nothing to do but need to be released.</p>
<h4 id="farfadet-18">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-10">TypeBeat</h4>
<p>Merge some PR from <span class="citation" data-cites="seliopou">@seliopou</span>, need to be released but not very important.</p>
<h4 id="sirodepac-ocaml-github-1">sirodepac / ocaml-github</h4>
<p>So the serialization is done as the half. Indeed, we produce a PACK file with the IDX file and we can recompute these (so, it's a big check to see if all is ok). I add some check like the hash of the IDX file and the hash of the PACK file.</p>
<p>I took my patience diff algorithm to try to apply a delta. I implement the window (in an optimal way) and compute the diff between 2 git objects by the line - before, I computed by the character but it's very slow.</p>
<p>So some good news: * the heuristic about the sort of the git object works! Indeed, when I try to apply a delta in a git object with the previous computed git object, I have some good ratio. * The performance is not killed. I don't say, I'm faster than git but the compute take a average time to make the PACK file. * The deserialization of the serialization of a PACK file produce the same result, we lost nothing when we deserialize and when we serialize.</p>
<p>So, I will implement the Hunk thing now to write the delta applied in the PACK file and optimize the size of this file. But the core of the serialization is already done.</p>
<p>Then, I will do some bench and make a PR to ocaml-git and, it's done :) ! But need a time to do all correctly :p !</p>
<h4 id="ps-3">PS</h4>
<p>I'm in Cambodia, I miss one day this week (the bus) but I will work this week end. it's the cambodia new year so all people come to home.</p>
<h4 id="week-16-for-romain-calascibetta-1">Week 16 for Romain Calascibetta</h4>
<h4 id="decompress-27">Decompress</h4>
<p>Nothing to do.</p>
<h4 id="blake2b-digestif-13">BLAKE2B / Digestif</h4>
<p>Used in <code>sirodepac</code> with no bug. Update the interface (and add the <code>type t</code>) but not very much more work.</p>
<h4 id="farfadet-19">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-11">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="sirodepac-ocaml-git-11">sirodepac / ocaml-git</h4>
<p>2 good news. I finish to implement the serialization of the PACK file and use my patience diff to try to compress the PACK file. Now, the result is: we produce a PACK file of 13MB and before, the length was ~21MB. So we reduce the length by 2 times! But it's not the best, [git] produced a PACK file with length: 2MB. I will try to find why we are wrong and I think, it's about the patience diff. But we are in the good way and now, we just need to improve and optimize the serialization.</p>
<p>In other side, I optimized the deserialization. Now, when you want a Git object from a PACK file, you just need to allocate 4 buffers (2 to inflate and 2 to undelta-ified the git object).</p>
<p>This result is possible because:</p>
<ul>
<li><p>we have a non blocking interface so we can start at any position of the PACK without a complexe description of a context (the state)</p></li>
<li><p>we compute the PACK file as the way than [git]. Indeed, [git] does not open the PACK file but some part of the file. We do the same to avoid the OCaml limitation about the native integer (and compute a huge PACK file firstly) and limit the allocation of what is needed to get the object. So, we avoid an attack by allocation.</p></li>
<li><p>we externalize all big allocation from the decoder state. The state is pure and don't have any internal buffer inside. The user need to specify 2 buffers (to inflate the git object) and can decide the length of these buffers. Then, the decoder handles these buffers without any problem but the purpose of the state is: it stores only some integers! So, obvisouly, it is located in the minor heap (like Decompress), I just follow some advises from Jeremy Yallop about that.</p></li>
<li><p>The 2 other buffers is about the undelta-ification of a PACK object to a git object. We can know the length needed to store a git object. So we just try to find the max length needed to undelta-ified a PACK object firstly.</p></li>
</ul>
<p>Undelta-ified means take a git object, a hunk (which it's list containing a data or an offset and a length to copy from the base git object to the new git object) and try to apply the hunk with the base git object to produce a new git object.</p>
<p>Obviously, we can have a delta of a delta of ... a delta of a git object. So we need to follow the chain and get the max length of all base git object needed to undelta-ified the git object requested.</p>
<p>Then, we just need to use 2 buffers and flip one to other for each undelta-ification. At the end, one of these buffers contains the git object requested.</p>
<p>So, it's a good optimization.</p>
<p>Finally, my last work is a functorization of the hash function (like ocaml-git) and an application with <code>Digestif</code>. I write a documentation too about the decoder firstly but I think is useless.</p>
<p>The next job is to try to optimize the serialization and understand how git can produce a small PACK file. But I think, I have an idea about that.</p>
<h4 id="week-17-for-romain-calascibetta-1">Week 17 for Romain Calascibetta</h4>
<h4 id="decompress-28">Decompress</h4>
<p>Nothing to do.</p>
<h4 id="blake2b-digestif-14">BLAKE2B / Digestif</h4>
<p>Nothing to do.</p>
<h3 id="farfadet-20">Farfadet</h3>
<p>Nothing to do.</p>
<h4 id="typebeat-12">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="sirodepac-ocaml-git-12">sirodepac / ocaml-git</h4>
<p>Previously, I told about the final implementation of serialization and try to find a good heuristic to make a small PACK file.</p>
<p>I have some goods results and now, I produce a PACK file with ~5MB when git produces ~2MB. So we are very close to git but not yet. At this time, it's complex to find a good way because git use an heuristic to compress the PACK file. I don't use the same because I can't reproduce exactly what git doing on the PACK file.</p>
<p>So, for this week, it's a deep introspection and a reverse engineering about what git do. And I'm focus on two problems:</p>
<ul>
<li><p>the sort algorithm. I follow the description of the sort in the git's documentation and, if I understand correctly, it's a lexicocagraphic compare between the kind of the object, the basename and, finally the size. I copy/paste the code from git to my project but my production of the sorted list object is different. This is a big problem because it's the main assumption to compress a PACK file</p></li>
<li><p>the compression method. To produce a 5MB pack file, I re-implemented the patience diff from the Jane Street library patience_diff (to avoid the dependency with Core). But git don't use the patience diff when it computes a PACK file. And I know why: because it's slow. Indeed, when I try to generate a PACK file, I maked a (patience) diff between 2 files by the line because if I try to diff by character, the algorithm is <strong>very</strong> slow. However, when I diff by line, the compression is not optimal for thow reason:</p></li>
<li><p>a diff by line is only relevant for a blob (which contains the file) but it's unoptimal for tree, commit and tag because these are not organized by line (but by LF character). I try to specialize the split and I produce a PACK file with 4.3MB but I can't do a better.</p></li>
<li><p>for a blob, sometimes, is not relevant to split by line because sometimes, only one character change between these files.</p></li>
</ul>
<p>Finally, git does not split by line to produce a diff. So, I looked what git do to compress and he uses a rabin's fingerprint to make an <code>index</code> and uses this <code>index</code> to make a diff with another file.</p>
<p>Now, I produce the same <code>index</code>, so I implemented the rabin's fingerprint and try to implement the delta-ification between an <code>index</code> and a file. But, just to notice, it's a clever solution for 2 reasons:</p>
<ul>
<li><p>we do a real compression like Decompress but with another algorithm (not the Lz77 algorithm - but I can use it to compress ...)</p></li>
<li><p>we can reuse the index for multiples files and it's what git do. When I computed some PACK files, I see the delta-ification for some file with one same file/<code>index</code>. It's to make the serialization more faster because, to make an <code>index</code> we need a time.</p></li>
</ul>
<p>So, I continue to implement the rabin's fingerprint and the compression with this - and continue to follow what git do.</p>
<p>Good news, git can recognize my PACK file with no problem (I fixed a bug about the hash). So we can considere than the project works but Thomas want a project which produces the same PACK file (in size terms). So, I continue to optimize <code>sirodepac</code>.</p>
<h4 id="week-18-for-romain-calascibetta">Week 18 for Romain Calascibetta</h4>
<h4 id="decompress-29">Decompress</h4>
<p>Prepare next 0.6 release.</p>
<h4 id="blake2b-digestif-15">BLAKE2B / Digestif</h4>
<p>Prepare release 0.1.</p>
<h4 id="farfadet-21">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="typebeat-13">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="sirodepac-ocaml-git-13">sirodepac / ocaml-git</h4>
<p>It's DONE! I just finished to implement the git heuristic in <code>sirodepac</code> and the result is: - we produce a PACK file with 1.3MB - git produces a PACK file with 1.2MB</p>
<p>So, yes ... now all is done. <code>sirodepac</code> is finished and, we can start the integration in <code>ocaml-git</code>.</p>
<p>So I need to explain by step what I did:</p>
<ul>
<li>Firstly, I functorize the <em>packer</em> by a zlib implementation module. Now, we can use <code>decompress</code> or <code>camlzip</code>. I did that because <code>decompress</code> is not the best to inflate (the diff is about some bytes) and to follow exactly what git does, I decide to functorize the implementation.</li>
</ul>
<p>The diff between a <em>packer</em> with <code>decompess</code> and <code>camlzip</code> is about 0.1MB. So, it's ok.</p>
<ul>
<li><p>I reproduce exactly the same sort as git. This is the core of the PACK algorithm to find the best diff between 2 git objects.</p></li>
<li><p>I finish to implement the Rabin's fingerprint and the diff with that. I optimized the compute to avoid any allocation of <code>Cstruct.t</code>. The result is exactly the same as git.</p></li>
<li><p>I switch the window implementation of the <em>packer</em> to the <code>lru</code> project from David. So, I add a dependency but it's ok. It's to follow, again, what git does and when git find a good delta, it promotes this delta in the window.</p></li>
<li><p>I seperate the serialization from the compute of the delta-ification. A good point is to let a new optimization and thread the compute of the delta-ification. This is what git does but need lot of work. So, for the moment, the algorithm is sequential but we can improve independantly than the serializer.</p></li>
<li><p>Implement topological sort to ensure we don't miss any diff for all git object.</p></li>
<li><p>Handle a diff with an object outside the PACK file.</p></li>
<li><p>Clean all</p></li>
</ul>
<h4 id="week-19-for-romain-calascibetta-1">Week 19 for Romain Calascibetta</h4>
<h4 id="digestif-9">Digestif</h4>
<p>I did the release but I spoke with daniel about the interface and the organization of the library. So I just change the API. I reimplemented the SHA1 and the SHA256 in OCaml. I will push all the next monday.</p>
<p>We moved this repository in mirage organization.</p>
<h4 id="decompress-30">Decompress</h4>
<p>I did the release of 0.6. This release fixed a bug about the decompression but nothing change about the API.</p>
<p>We moved this repository in mirage organization.</p>
<h4 id="typebeat-14">TypeBeat</h4>
<p>Nothing to do.</p>
<h4 id="farfadet-22">Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="ocaml-git-sirodepac-10">ocaml-git / sirodepac</h4>
<p>With Thomas, we push some PRs like the integration of decompress by default and the integration of digestif by default - but we keep all functors. Then, I fixed some bugs in sirodepac about the memory and integrate the optionnal usability of a cache (like a LRU cache) and an access of a hash by the offset.</p>
<p>Thomas sended me a huge PACK file (~ 4 000 000 commits, 10 Go), so I will try to generate a new PACK file from this source. However, the compute is very low and may be crash because I launched the process in my server (and it's not my best machine).</p>
<p>I wrote a documentation about <code>sirodepac</code> but only in french. When I finish, I will ask to fix some errors (in french), then I will try to translate to english - and publish an article :) !</p>
<p>Finally, with Thomas, we think about an abstraction and apply the generation of the PACK for something different than <code>git</code> object and I think it's possible, I have an idea about that. But I'm focus to integrate my work in ocaml-git for the moment.</p>
<h4 id="week-20-for-romain-calascibetta-1">Week 20 for Romain Calascibetta</h4>
<h4 id="digestif-10">Digestif</h4>
<p>So I push a new PR to follow my change in digestif. We have two implementation now, a C and an OCaml implementation and they share the same interface. So you just need to link to the implementation you want.</p>
<p>I will look the go digest interface to do the same. But I think, we close to a good API. I asked to Andres Hauptmann to talk about cryptohash. Indeed, it's another project to provide some hashes functions and I ask to integrate this work inside Digestif. So, he agreed with me and when I have the time, I will integrate this work.</p>
<h4 id="decompress-31">Decompress</h4>
<p>I found a bug about one information available in Decompress, so I fixed it in a new PR. This change does not impact the API. So, I will wait the next release of Decompress to merge this PR.</p>
<h4 id="typebeat-farfadet-1">TypeBeat / Farfadet</h4>
<p>Nothing to do.</p>
<h4 id="angstrom-2">Angstrom</h4>
<p>I just try to optimize Angstrom from <span class="citation" data-cites="seliopou">@seliopou</span> just for my curiosity and try to use the <code>[@@unboxed]</code> tag to the representation of a parser. But it seems to not be good. When I launch the benchmark, I noticed regression about performance. I don't know why but I noticed <span class="citation" data-cites="seliopou">@seliopou</span> about that in Slack.</p>
<h4 id="ocaml-git-sirodepac-11">ocaml-git / sirodepac</h4>
<p>I tried to control the memory consumption of <code>sirodepac</code> to try to compute a huge PACK file (like the PACK file from datakit). So, I try to limit the allocation of the deserialization and the serialization.</p>
<p>The problem is simply. Sometimes, <code>git</code> computes a huge git object. The problem is: we can't store all of this git object in memory (like if this huge object has 1 Go, we may be catch a <code>Out_of_memory</code>). This situation appear when we compute the PACK file in a <em>stop the world</em> context. We loaded all the git object inside the memory, then we compute the git object.</p>
<p>My idea and for the context of datakit is to continue to follow the non-blocking implementation and avoid any <em>stop the world</em> computes in the serialization and deserialization.</p>
<p>For the deserialization, it's already done. You can write directly step by step a huge git object with a fixed size buffer (and avoid to load all the git object inside memory). The API is very close to the non-blocking API from Mr. Mime, Decompress or dbuenzli's library. The state/context needed to deserialize a git object does not allocate any buffer. You need to notice which buffer the state can use (so we let the user to allocate the buffer needed to deserialize any git object). So, obviously, it's not easy-to-use (like the API of Decompress) because we let the user to control the memory fingerprint of this specific compute.</p>
<p>It's what git does. It prefers to use the file system instead the memory because it know than it's possible to have a huge git object. So it uses a lot of the <code>mmap</code> syscall. <code>sirodepac</code> do the same.</p>
<p>About the serialization, it's complex but not impossible. Firstly, I separate the compute of the delta-ification from the deserialization. The bad point is, the delta-ification is a <em>stop-the-world</em> algorithm (the Rabin's fingerprint is a <em>stop-the-world</em> algorithm specifically). So, the point is continue to let the user to control the memory fingerprint of this compute and it's possible by the <code>lru</code> library from David. Indeed, with this library we can control how many bytes you allow for this cache.</p>
<p>The point is, with the <code>git</code> algorithm, we need a cache/window to try to delta-ify the current git object with a previous git object. So the cache/window can be huge (because, it contains, by default, 10 git object, and these git objects can be huge). Then, we update this cache/window but we allocate a lot just to store the previous git object.</p>
<p>So, I decide to separate this compute from the serialization for two reasons:</p>
<ul>
<li>Firstly, because it's a <em>stop-the-world</em> algorithm, we can't consume step by step a git object and need to store all of some git objects.</li>
<li>Secondly, to let a optimization without any dependence with the serialization (like try to paralyze this compute, like <code>git</code>).</li>
</ul>
<p>So, we can change the serialization to be a non-blocking implementation and use a fixed size buffer to contain an huge git object step by step. The idea, then, is use the characteristic of the non-blocking axiom of the deserialization inside the non-blocking axiom of the serialization. That means:</p>
<p>When you try to serialize a PACK file, we need to serialize all git object inside this PACK file. One way (the previous way) is load all git objects inside memory and serialize all of these inside the PACK file but the memory consumption is too huge.</p>
<p>The new implementation asks the user which git object it wants to serialize. Then, we have a fixed size buffer to store a part of this specific git object. So step by step, we fill this buffer, we let the serializer to compute this buffer, we flush the buffer and continue to fill it while we are not finish to compute all data from this git object.</p>
<p>One point is, a git object is commonly come from another PACK file. So we deserialize in a fixed size buffer what the serializer wants and at the same time, we serialize this fixed size buffer and continue to the end of this git object. So, it's very complex because inside the serialization, we have a deserialization ... And we need to synchronize contexts used for serialization and the deserialization together to not lost any data. it's complex to deal with it but it's possible and it's what I did this week - I did a part, not all.</p>
<p>Then, we have a technical point about a git object provided by the deserialization delta-ified. In this context, you need to load the source git object inside the memory to construct the git object requested ... But you can limit the memory assumption to <code>max_int32 + 0x10000</code> because the Rabin's fingerprint is done only on this area. So, we continue to control precisely the memory consumption.</p>
<p>Voilà voilà :D !</p>
<h4 id="week-21-for-romain-calascibetta-1">Week 21 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-12">ocaml-git / sirodepac</h4>
<p>So I most done my last task about <code>sirodepac</code> and control the memory consumption. But I found a bug and it's about the serialization of a hunk. I created a mini hunks decoder to help to find the bug. And now, I know precisely where is it. So I will fix this and continue to test some others PACK files with an implementation of <code>zlib</code> and <code>decompress</code>.</p>
<p>I hope, I finish this week this bug, it's a very deep bug but it's ok, in same time, I put some useful comments to help me to understand my code and check my implementation.</p>
<h4 id="conferences-1">Conferences</h4>
<p>So, I created a new talk for the Functional Conference in India and my talk was accepted! Then, Mark Li asked me to do a CUFP tutorial about Git in OCaml. I think about this and OCaml labs was agreed to do this. So, I prepare in my mind what I will do and ship an abstract before the deadline.</p>
<h4 id="week-22-for-romain-calascibetta-1">Week 22 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-13">ocaml-git / sirodepac</h4>
<p>Previously, I found a bug in my implementation. Now all is ok we can serialize all git object with a fixed size memory consumption. It's done by a deserialization with a fixed size memory consumption. So I played with some buffer between the serialization and the deserialization and all is fine. The produced PACK file work and we keep the integrity of the data.</p>
<p>I asked to Gemma to have an access to a machine to run some huge tests about the compression.</p>
<p>Then, I finish to write the documentation for ALL modules. All modules are explained and some tricks and implementation specified are described inside the ML file. I hope all is clear and someone can read and understand the code.</p>
<p>I started to integrate all in ocaml-git. So, I did some big change.</p>
<ul>
<li><p>I replaced the LRU module from Simon Cruanes by the implementation provided by David as the <code>lru</code> package in OPAM. A good point about this library is to control precisely the memory consumption of your object (and no how many object you can store). This point is good to keep the precise control about memory consumption because when we store some git object inside the cache, may be one took 1 Go and one other took 100 Ko. So, instead to keep these 2 objects, we keep one of them if we limit the memory consumption by 5 Go for example.</p></li>
<li><p>I cleaned the interface of the CRC-32 checksum and provide a new type <code>t</code> which one is a <code>private int32</code>. So we keep the abstraction about the CRC-32 (and don't do a mistake with the <code>int32</code>) and optimize the the computation when we want to serialize to an <code>int32</code> (by the sub-typing: <code>v :&gt; int32</code>).</p></li>
</ul>
<p>I go to take my car to Sieam Reap sorry ...</p>
<h4 id="week-23-for-romain-calascibetta-1">Week 23 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-14">ocaml-git / sirodepac</h4>
<p>I continue to integrate my work in ocaml-git. I decided to do a change <em>bottom-to-top</em> replacement: that means, I keep the interface of the Git module but I create a new implementation. Why ? ocaml-git is based on a stop the world serialization and we can see this constraint for the File System interface (which implements <code>read</code> and <code>write</code> but not on a non-blocking interface).</p>
<p>I believe is that why ocaml-git consumes a lot memory because it does not work on a fixed size buffer. So I decide to add a non-blocking interface to the File System signature required.</p>
<p>Then, I provide an Angstrom parser and a top layer to de-serialize a non-blocking input from an Angstrom parser. We have a limitation but I explain precisely why this limitation exists.</p>
<p>So, I re-implement the loose file firstly and I will add my work then. It's a deep work, so when I have a result, I will notice. Another point is about the Hash. At this moment, we store the hash inside a bigarray (located directly in the major heap). May be we need to change this to a bytes to optimize the memory consumption (because the client should use a lot of hashes).</p>
<p>Voilà, not so much this week to show but a deep work :) !</p>
<h4 id="week-24-for-romain-calascibetta-1">Week 24 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-15">ocaml-git / sirodepac</h4>
<p>I continue to integrate my work in ocaml-git. So, the integration of the decoding is close to be done. Indeed, I can read any object from any PACK file with the same API. I decided to provide an <em>easy-to-use</em> API (same as the previous API of ocaml-git) and a more complex API to control precisely the allocation. With this API, we can compute in a parallel way the git object if we have some specific buffers available, otherwise, we can compute step by step each objects with a <em>global</em> buffer.</p>
<p>So, now, I need to integrate the serialization inside ocaml-git and think about a good API.</p>
<p>I continue to check my work step by step, try with <code>decompress</code> and <code>camlzip</code> to keep the compatibility. I put a documentation for all and describe some complex process inside the ML file to keep an understable code for other user.</p>
<p>So, for this moment, all seems to be good and, I think, we will have a good API.</p>
<h4 id="cufp-1">CUFP</h4>
<p>I send my proposal after a review with Thomas, Gemma, Anil and KC, at the next CUFP, I'm waiting now the response :) !</p>
<h4 id="ocaml-network-1">OCaml network</h4>
<p>I'm currently in Singapore and met all people from Ahrefs. Obviously, I met Enguerrand (and he is good) but I met other people from this corporation and speak about ICFP, OCaml and other stuff.</p>
<p>A good news, some people from this corporation keep an eye in the MirageOS project - and think that the unikernel is the future!</p>
<h4 id="week-25-for-romain-calascibetta-1">Week 25 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-16">ocaml-git / sirodepac</h4>
<p>I still in the integration of the sirodepac code-base inside the ocaml-git project. About all read operation, all is good, I found a bug in the beginning of this week but I fixed this quickly. Then, I continue to try to integrate the serialization.</p>
<p>So, previously, I said I used the couple Angstrom/Faraday from Seliopou. Angstrom is perfect but Faraday is specialized to serialize and write directly to an output (by iovec). However, by the API, I'm not free to decide how to write a Git object.</p>
<p>Firstly because iovec is not available with lwt (and we have a strong dependency with lwt) and because the way to serialize with Faraday is to up two process. One to write inside the Faraday encoder and the second to write to the output. In the ocaml-git context, it's better to let the user to do this choice.</p>
<p>But sometime, internally, I need to serialize a Git object to obtain a digest for example - but we have some other use-case when the serializer does not interact directly with the output (and the PACK file serializer is another good example).</p>
<p>So, I decide to provide at the same time a little encoder (minienc) to serialize a Git object correctly in a fixed size buffer (I use a ring-buffer and a queue in a limited context). The good point is, to digest (or serialize in the PACK), we continue to control the memory consumption strictly. So this encoder is done. However, it's may be better to provide an interface « à la Farfadet » or « à la Printf-like » for this encoder and improve the re-usability of the code. But I want to move fast, so not yet.</p>
<h4 id="digestif-11">Digestif</h4>
<p>I implemented the MD5 hash function in OCaml and rename the library. So if you want to use the C implementation of the hash, you just need to link with <code>digestif.c</code>. Otherwise, for the OCaml implementation, you can link with <code>digestif.ocaml</code>.</p>
<h4 id="radixpatricia-tree-1">Radix/Patricia tree</h4>
<p>When I worked on sirodepac, I re-used a code from BeSport about the implementation of a tree to store some object binding with a key. <span class="citation" data-cites="g2p">@g2p</span> seems to want the same but with a remove operation.</p>
<p>So, may be I will start a benchmark to compare my implementation with standard implementation of Map in OCaml - I already did a benchmark between my implementation and the implementation of the Thomas and I'm more fast (but use a lot of memory).</p>
<h4 id="week-26-for-romain-calascibetta-1">Week 26 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-17">ocaml-git / sirodepac</h4>
<h5 id="encoder-1">Encoder</h5>
<p>I finish to integrate the core part of sirodepac inside ocaml-git. In the previous week, I explained that the couple Angstrom/Faraday is good about the serialization/deserialization. However, I have some bit problem with Faraday. The context of the serialization in ocaml-git is not the same than httpaf. The first difference is about where we serialize a Git object.</p>
<p>Faraday was thinked to write directly to a file descriptor/socket. It was thinked to be share between 2 process, one to write in the internal buffer, the next to write to the file descriptor. But, in ocaml-git, we use the serialization of a Git object in a other case. One of this case is about the serialization to feed a context and get, at the end, an hash. So, the target of the serialization is not a file descriptor but an internal buffer.</p>
<p>So, I decided to create a mini non blocking encoder with a fixed size memory fingerprint. And I finished in few day. It's used to produce the same as Faraday but with some news constraints. This is work perfectly and we keep a control about the memory consumption.</p>
<h5 id="write-a-pack-file-1">Write a PACK file</h5>
<p>Then, we can write a PACK file now but I need to polish deeply the API. This is the end thing to do. Before, I want to try my PACK file in the real world.</p>
<h5 id="smart-git-protocol-1">Smart Git Protocol</h5>
<p>To test my deserialization/serialization of the PACK file, I decided to interact with a Git server with the Smart Git Protocol. I saw the Sync.ml module, which implements all things about the communication. However, this module was thinked in the same way as the previous implementation of ocaml-git.</p>
<p>So, I fund the same problem before and I decided to take down all. I re-implement the Smart Git Protocol in same way than ocaml-imap. I described why in a long comment (and why I don't choose Angstrom/Faraday). So, I can clone now and for this week I'm focus about the negociation with a Git server.</p>
<h4 id="week-27-for-romain-calascibetta-1">Week 27 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-18">ocaml-git / sirodepac</h4>
<h5 id="about-the-mini-encoder-1">About the mini-encoder</h5>
<p>As I said previously, I re-implement a mini encoder to provide an API « à la Faraday » but this API was constrained by the memory. In fact, Faraday is a encoder which one has no limit to save what you want to encode. The internal buffer can growth and, if we don't have an other concurrency thread to consume the internal buffer of the Faraday state, we will have a problem with the memory consumption for some cases (like when we want to digest a huge blob).</p>
<p>So, in the previous week, I finished the implementation and now, all is good. The mini encoder works perfectly.</p>
<h5 id="about-the-smart-protocol-1">About the Smart protocol</h5>
<p>In previous week, I spoke about the Smart protocol with Git to clone/fetch/push a PACK file and test my implementation. I said than the current implementation of the Smart protocol in ocaml-git does not provide a good API to play with it - it's like some common operation but you can manipulate in the details what is going on the exchange with a Git daemon.</p>
<p>So, I decided to re-implement the Smart protocol in other way and I finished the implementation with a close user-friendly operation with my PACK decoder.</p>
<p>More precisely, I catch a memory bug when we try to clone a big repository. Indeed, in a specific (but common) context, we need to undelta-ify some objects stored in the PACK file received. The big problem is, for each delta-ification, we need to save a list of hunk to re-construct the requested object.</p>
<p>So, previously, for each hunk, I allocate a little string and keep all as long as we deserialize the object. At the end, I use these hunks to reconstruct the current object. However, the base of the requested object can be delta-ified too. Finally, we can have 50 level of delta-ification and to reconstruct the final object, we need to keep all hunks at each level of each base object. And, we literally use a lot of memory for that.</p>
<p>So, I decided to undelta-ify the object against an heuristic described in the technical document of git. The point is, the base of an object must be before the object (inside the PACK file). So, I can calculate for the first pass the biggest depth of the PACK file. Then, in the second pass, when we delta-ify the rest of the object, I allocate n buffer (n = max_depth) and for each undelta-ification, I used these buffer to store hunks (instead to allocate).</p>
<p>So, we allocate, one time, a big buffer, and re-use this buffer as long as we undelta-ify the delta-ified objects.</p>
<p>This is needed to calculate the hash for each object and produce an IDX file, which will be saved in the file-system.</p>
<p>I tested this approach and, to clone ocaml-git for example, I use 1~2 % of my memory (4 GB) to deserialize all object of the PACK file received. However the process is little bit slow. Another point is, when I try to clone a repository with a huge file, I use lot of memory but all the time, the OCaml GC can compact the area and we are not close to the [Out_of_memory] problem now.</p>
<p>Now, I focus on the push command.</p>
<h4 id="week-28-for-romain-calascibetta-1">Week 28 for Romain Calascibetta</h4>
<h4 id="ocaml-git-sirodepac-19">ocaml-git / sirodepac</h4>
<h5 id="about-fetch-a-repository-1">About fetch a repository</h5>
<p>So, first, I re-implement a negotiation engine about fetch. It follows the current non-optimal implementation of Git. I saw the paper about the bloom filter to optimize the negotiation but I don't have a time to implement this.</p>
<p>The good point is the modularization of the fetch compute in ocaml-git. Indeed, we can change the negotiation engine by another engine easily.</p>
<p>About the PACK file received, with Thomas Gazagnaire, we catch a weird compute from Git. In fact, when we receive a <em>thin-pack</em> (which contains some externals references), Git took it and make a new canonical PACK file (which does not contain any external reference). Then, Git saves it in the store.</p>
<p>It's weird because if we store directly the <em>thin-pack</em> and avoid the next compute, all works. So, Thomas and me decide to let the choice to avoid the next compute and store directly the <em>thin-pack</em> or generate a new canonical PACK file. This is prove my implementation of the encoder of the PACK file.</p>
<h5 id="about-push-to-a-repository-1">About push to a repository</h5>
<p>I continue to focus my work on the push command. When I try to understand what Git does, I saw a little DSL about set of commits (we can see this DSL with <code>git parse-rev</code>). This DSL is a key of which commit we need to send to the server. So, I implement this and some other stuff about reference.</p>
<p>Then, I implement the smart protocol about the push command but I did not yet test the command. I think, it's done today or tomorrow :) !</p>
<h4 id="week-37-for-romain-calascibetta">Week 37 for Romain Calascibetta</h4>
<h4 id="decompress-32">Decompress</h4>
<p>I just started to test decompress with afl, we found 41 tests cases where decompress fails. So we can start to fix bugs. See the PR:</p>
<p>https://github.com/mirage/decompress/pull/35</p>
<h4 id="angstrom-3">Angstrom</h4>
<p>When I tried to produce a dot file for a git repository, I found a bug in Angstrom available in this issue:</p>
<p>https://github.com/inhabitedtype/angstrom/pull/104</p>
<h4 id="digestif-12">Digestif</h4>
<p>I just finished the implementation of the RIPEMD160 hash algorithm (asked by <span class="citation" data-cites="vbmithr">@vbmithr</span>) in C and in OCaml. The implementation is available in this PR:</p>
<p>https://github.com/mirage/digestif/pull/12</p>
<p><span class="citation" data-cites="hannesm">@hannesm</span> points a problem about the license, so I wait a response from Antoon Bosselaers to use freely the C implementation.</p>
<h4 id="ocaml-git-7">OCaml Git</h4>
<p>The PR#227 continues. I move the core library to <code>jbuilder</code>, implement a top-level and a program which produce a dot file of a Git repository - to test the current implementation.</p>
<p>With these, I found some bugs and fixed all - bugs from the PR when I polished warnings.</p>
<p>I found a segfault (which show me the bug in Angstrom) in ocaml+4.03.0. It's about a non-exhaustive pattern-matching on exceptions. Then, Angstrom raises an <code>Index out of bounds</code> and, because the pattern-matching is not exhaustive, we have an undefined behaviour (instead an exception from the OCaml runtime) and we finish to a segfault with a block with the tag 1002 (which should not appear after 3.11).</p>
<p>I met Pierre Chambart and we discussed about that. When I handle the exhaustiveness of the pattern-matching, all is ok in ocaml+4.03.0 and in 4.04.0, OCaml raises a runtime exception about the exhaustiveness of the pattern-matching.</p>
<p>Finally, I put an new issue in OCaml about warnings and the PPX, see #MPR7624.</p>
<h4 id="type-beat-1">type-beat</h4>
<p>I updated type-beat to use the last version of Angstrom.</p>
<h4 id="week-38-for-romain-calascibetta">Week 38 for Romain Calascibetta</h4>
<h4 id="decompress-33">Decompress</h4>
<p>I launched the afl test and fixed the bug founded. It's about a special case of decompress when it deflates a data. Indeed, when we deflates a input lowest than 12 bytes, we launched a specific algorithm which does not need some assumptions to work.</p>
<p>The bug appears in this case and I fixed it easily. Then, I relaunched the afl test and, now from 4 days, alf did not catch an error yet.</p>
<h4 id="digestif-13">Digestif</h4>
<p><span class="citation" data-cites="hannesm">@hannesm</span> showed me a code which is freely licensed (public domain) about the implementation of the RIPEMD160 hash algorithm. So, I integrated this code in Digestif, passed all tests and merge it in master. It's ready for a next release.</p>
<p>However, <span class="citation" data-cites="cfcs">@cfcs</span> asked me to implemente the BLAKE2s hash algorithm. So, when I finish this implementation, I will do a benchmark and release it.</p>
<p>In fact, at the same time, I asked to Louis some benchmark to compare with <code>ocp-sha</code>. I did not look the implementation but I keep it in my TODO list of Digestif.</p>
<h4 id="ocaml-git-8">OCaml Git</h4>
<p>Polishing and debugging. In fact, the <code>git</code> core library did not change a lot but I figure about the API all the time. I worked to provide the git-unix implementation, a git-http implementation which uses <code>cohttp</code> (but it can use <code>cohttp-js</code>) and reorganize the project under the <span class="citation" data-cites="samoht">@samoht</span>'s advise.</p>
<p>In the details, I integrated <code>read_inflated</code> and <code>write_inflated</code> as a part of the shared API between the memory back-end and the file-system back-end.</p>
<p>I linted the API of the web abstraction needed by the git-http implementation - I think about cohttp/httpaf. The point is, git-http uses the cohttp-lwt implementation but not the cohttp-lwt-unix implementation. git-unix/ogit-http-clone uses the cohttp-lwt-unix but we can use with the memory back-end (which restricted with the minimal interface) the cohttp-js implementation.</p>
<p>Finally, sync_http, the main module which implements the Smart HTTP protocol (encode/decode) does not need <code>cohttp</code> but a implementation which respects the interface <code>s.web</code>.</p>
<p>Finally, I found 2 bugs about the sync_http implementation: * The first is a <em>sattelite</em> bug. I mean, it's about how to use cohttp with the Smart HTTP protocol. Indeed, the POST request which <em>negociates</em> with the server need to not be chunked. * The second bug it's about a missing implementation of the side-band but it's not so big.</p>
<h4 id="week-39-for-romain-calascibetta">Week 39 for Romain Calascibetta</h4>
<h4 id="decompress-34">Decompress</h4>
<p>Simple afl test finished, I will start a complex test which test level, window size and others parameters of decompress.</p>
<h4 id="digestif-14">Digestif</h4>
<p>I push a mlilib branch to explain to thomas what is the problem to have a <code>digestif</code> library which contains only the mli file.</p>
<h4 id="ocaml-git-9">OCaml Git</h4>
<p>So from the last discussion we show a problem about the minimal API and how to store a PACK file for the memory back-end and the file-system back-end.</p>
<p>From a discussion with <span class="citation" data-cites="samoht">@samoht</span>, we decide to abstract the PACK file for the shared interface as a stream. In the file-system back-end, we took the stream, do some computation (like if the PACK file is a /thin/ PACK file or not) and, produce the IDX file and save it in the .git/objects/pack/ directory.</p>
<p>This is a big change from the previous API which populate the git repository with /loose/ files.</p>
<p>From this big change, I reorganize the PACK engine which takes care about how to handle available PACK files of the git repository in the file-system back-end. I optimized the memory consumption when we need to undelta-ify an object.</p>
<p>The process now is more clear and documented: * Firstly, we load only the IDX file to know which Git objects are available in which PACK file * Then, when the user request a Git project stored in a PACK file, we start to compute some informations - like the biggest object, the max depth, how many bytes we need to store hunks, etc.</p>
<p>From these informations, we grow the state-defined buffer to allow to undelta-ify any object from the specific PACK file without any allocation.</p>
<p>However, we continue to have a <em>memory leak</em> (it's not but the memory consumption is not predictable at this point) we the pack file need an external ressource (so, a thin pack). * Finally, we can do a second pass to know if the pack file is a thin pack or not (and grow the state-defined buffer in consequence)</p>
<p>In memory back-end, we continue to populate from the pack stream, the git repository. We don't have yet an abstraction of the pack file in the memory back-end.</p>
<p>However, and it's the purpose of the new API, because we abstract a PACK file received by the external world as a stream, we let the back-end to choose the best way to store the pack file (in memory, it will be a [Cstruct.t] and in file-system, it's a file).</p>
<p>I switched the [Sync_http] protocol to use this abstraction and now it's more easy to handle a PACK file in the protocol - because, now, the back-end handles the pack file and not the protocol.</p>
<p>I will switch the [Sync] protocol too but it will be easy.</p>
<p>Finally, for the file-system back-end, when it receives a PACK file, it tries to know if the pack file is thin or not. In the first case, we generate a new non-thin pack file (as git) and in the second case, we just generate the IDX file and move from the temporary directory the pack file to the git repository.</p>
<p>However, about all, I catched a bug about the CRC-32 checksum and try now to fix the bug. I did not push my change because I want to fix this weird bug because.</p>
<h4 id="week-40-for-romain-calascibetta">Week 40 for Romain Calascibetta</h4>
<h4 id="decompress-35">Decompress</h4>
<p>From the last complete afl fuzzer (which add the level and the windows bits argument), all looks fine. I catched a bug but it seems this bug is come from afl (and not decompress) which described by the issue #8.</p>
<p>I talk with Mindy about that, she already know this bug and ask me to try the fuzzer with an other version of afl-persistent.</p>
<p>So, I wait the end of the fuzzer to make a release as I said but nothing to declare about bugs in decompress for the moment!</p>
<h4 id="digestif-15">Digestif</h4>
<p>So, the implementation of BLAKE2s appeared in the PR #14, it should works from some local tests. <span class="citation" data-cites="cfcs">@cfcs</span> ask me to add some tests from the reference implementation of BLAKE2s, some tests about RIPEMD160 and others useful inputs. However, he found a <em>bug</em> about the build system. Indeed, the test can not be automated easily if we want to test with the C implementation and the OCaml implementation. He suggere in the PR #16 to test the OCaml implementation.</p>
<p>So, I will figure about this when jbuilder#136 is done.</p>
<p>Then, <span class="citation" data-cites="samoht">@samoht</span> found a way to provide a mli library and use it to link with a library (like ocaml-git). Then, the git library need to be linked with <code>digestif.c</code> or <code>digestif.ocaml</code> to provide the implementation.</p>
<p>This PR waits the jbuilder#136 issue again.</p>
<h4 id="farfadet-23">Farfadet</h4>
<p>Update to the new API of Faraday and add a constraint in the opam repository.</p>
<h4 id="typebeat-15">TypeBeat</h4>
<p>Update to the new API of Angstrom.</p>
<h4 id="ocaml-git-10">OCaml Git</h4>
<p>I added the fold function (come from the Irmin implementation) to traverse a Git repository and complete an accumulator (specially to generate a list of entries to pack then). So, it's a function provided in the minimal API - the implementation is the same between the file-system back-end and the memory back-end to avoid any semantic diff between back-end and this function.</p>
<p>Then, I tested the <code>git-bomb</code> repository with ocaml-git. I fixed some bugs about the URI and we can clone, read, write in this repository without memory leak. I generated a dot file of this git repository then. So, no problem about this repo for ocaml-git!</p>
<p>I added the ogit-cat-file and the ogit-http-ls binary as ogit did previously and clear some module like the Revision module and the Sync module to use the minimal interface instead the file-system back-end.</p>
<h4 id="week-41-for-romain-calascibetta">Week 41 for Romain Calascibetta</h4>
<h4 id="decompress-36">Decompress</h4>
<p>I released the new 0.7 version of decompress. I currently work on a good API about javascript. I found some API in the npm repository but these API seems to be imperative - and it's not the case decompress.</p>
<p>NOTE: I think, it's imperative because it's just a FFI with zlib directly (without convenience computation).</p>
<h4 id="digestif-16">Digestif</h4>
<p>I just finish to implement the BLAKE2S function and test it and merge it. I currently look about benchmark with Louis and provide something to test and compare with ocp-sha.</p>
<p>About the test, I just look what is it exactly and we have lot of litterature to test SHA-*, BLAKE2{b,s} and RIPEMD160 implementation. So, I will integrate all.</p>
<h4 id="callipyge-1">Callipyge</h4>
<p>cfcs catched a bug about Callipyge, it does not work. So, I think, I will re-implement it from the reference implementation.</p>
<h4 id="ocaml-git-11">OCaml Git</h4>
<p>I just implemented the fetch command on the HTTP protocol. Now, I can start to implement the push command on the HTTP protocol. Louis asks me about the current implementation of my PR and he tried to test it.</p>
<p>Obviously, I did not work yet on the polishement of opam file and we need to pin digestif and a specific version of angstrom (which has my fix). Then, he compiled ocaml-git without error but it's not easy, I started to figure about opam file.</p>
<p>Again, I fixed some bugs specifically about reference (between absolute path of the reference and relative path) and the PACK decoder which handles an empty PACK file now.</p>
<p>I cleaned the smart decoder and delete the redundant code and understand what is specifically the diff between the Smart protocol and the Smart HTTP protocol - because, in the Git documentation, we don't have any explanation about that.</p>
<h4 id="week-42-for-romain-calascibetta">Week 42 for Romain Calascibetta</h4>
<h4 id="decompress-37">Decompress</h4>
<p>Find a way to provide a JS API of Decompress with a mutable state.</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">type</span> inflator = { <span class="kw">mutable</span> contents : (B<span class="kw">.</span>st, B<span class="kw">.</span>st) Inflate<span class="kw">.</span>t }</code></pre></div>
<p>So, the code is specialized to manipulate only a bytes (but still ok where the JS world does not provide an equivalent of Bigarray - in performance).</p>
<h4 id="digestif-17">Digestif</h4>
<p>Find a new way to test the C implementation and the OCaml implementation with travis.</p>
<p>Fixed a bug about the RIPEMD160 implementation in OCaml.</p>
<p>Put some other tests (from the BLAKE2{b,s} reference implementation, and the RIPEMD160).</p>
<p>Benchmark on the C implementation and the OCaml implementation with <code>core_bench</code>. However, I did not compare with <code>ocp-sha</code>, firstly because I lost my time to make a package for ocp-sha (Louis provides only a Makefile). And because ocp-sha was thinked to hash a file (not a stream or a buffer) and tricks on to be fast - however, I can not say ocp-sha is faster than digestif when ocp-sha uses some syscall like lseek.</p>
<p>So, if we want to compare digestif and ocp-sha, it's about program which take a file but it's not very relevant when ocp-sha map the file and digestif could compute a stream of this file.</p>
<p>Finally, make a release.</p>
<h4 id="ocaml-git-12">OCaml Git</h4>
<p>Try to move the test implementation on the new API. Nothing change a lot, I missed some conveniences accessors and use infix operator of Lwt_result instead Lwt.</p>
<h4 id="week-43-for-romain-calascibetta">Week 43 for Romain Calascibetta</h4>
<h4 id="ocaml-git-13">OCaml Git</h4>
<p>Focus on the test of OCaml Git (the common part). So, I put some constraints to prove the equality of the type Value.t between 2 implementation of the Git repository with the same Hash module.</p>
<p>I added some conveniences functions again (like Git.Ref.exists or Reference.head_contents).</p>
<p>I fixed 2 bugs: - one about the semantic of <code>Mem.read_inflated</code> which differ from the <code>FS.read_inflated</code>, the first one put the header and the last one not. But we expect the last semantic. - A deep bug about the abstract serialization of a value</p>
<p>Then, I test the Git.Pack.make function and add a returned value which is a protected variable to get the IDX tree - only available when we consume all of the stream.</p>
<p>I implemented the push function for the Sync_http module (so the Smart HTTP protocol) but not test it yet. And finally put some /easy-to-use/ functions on the provided CoHTTP implementation of the Smart HTTP protocol (for Camelus).</p>
<p>Louis reported to me a bug about fetch, I will fix it.</p>
<h3 id="author-david-allsopp">Author David Allsopp</h3>
<h4 id="week-51-for-david-allsopp">Week 51 for David Allsopp</h4>
<p><strong>OCaml</strong> Various mildly time-consuming bits 'n bobs: - Testsuite hardening to improve CI (GPR#974, GPR#975) - CI tweaks (GPR#978, GPR#979) - Windows asmrun build system merge test+review (GPR#941) - GPR#980 test+review</p>
<h4 id="week-1-for-david-allsopp">Week 1 for David Allsopp</h4>
<p><strong>General</strong> - Settling into the lab</p>
<p><strong>OPAM-on-Windows</strong> - MSR meeting. Immediate things to note: - Once rebase complete, liaise with <span class="citation" data-cites="protz">@protz</span> on package requirements to eliminate MSR internal OPAM scripts - Andreas Hauptmann (fdopen) has stopped (is stopping) supporting his Windows opam-repository</p>
<p><strong>OCaml 4.05</strong> - Reviewing &quot;my&quot; [GM]PRs and devising workplan ready for 1 Feb freeze</p>
<h4 id="week-2-for-david-allsopp">Week 2 for David Allsopp</h4>
<p>(reduced week)</p>
<p><strong>OCaml 4.05</strong> - Change Log Processor</p>
<h4 id="week-3-for-david-allsopp">Week 3 for David Allsopp</h4>
<p>(reduced week)</p>
<p><strong>OCaml 4.05</strong> - Change Log Processor - Various GPR reviews</p>
<h4 id="week-4-for-david-allsopp">Week 4 for David Allsopp</h4>
<p>(reduced week)</p>
<p><strong>OCaml 4.05</strong> - Change Log Processor merge - failed to reach consensus. Shelved for now - will hopefully get turned into a Git merge driver instead. - Various GPR reviews - PR#7373, fixing a bug (of my own) in the FlexDLL bootstrap part of the build system. Tacking on some improvements to that which will feed into OPAM.</p>
<h4 id="week-5-for-david-allsopp">Week 5 for David Allsopp</h4>
<p><em>Away for most of the week</em></p>
<p><strong>OCaml 4.05</strong> - Work on GPR#1010 (Prefixing the OCaml Standard Library</p>
<h4 id="week-6-for-david-allsopp">Week 6 for David Allsopp</h4>
<p><em>On &quot;holiday&quot; this week</em></p>
<h4 id="week-7-for-david-allsopp">Week 7 for David Allsopp</h4>
<p>** OPAM ** - First attempt at rebasing onto Beta 2 (stuck at lib-pkg merge)</p>
<p>** OCaml 4.05** - Reviewing fix for GPR#861 relating to a DST-bug in Unix.stat on Windows. Far too much time spent reading MSDN and grep'ing source code of old CRTs... - Cygwin-32 fork crash. Moving mmap functions from Bigarray to Unix has broken Cygwin fork (reliable test case). Far too much time spent reading Cygwin source code - it's not yet clear whether this is a Cygwin bug, a FlexDLL bug or an OCaml bug...</p>
<h4 id="week-8-for-david-allsopp">Week 8 for David Allsopp</h4>
<p>** OCaml 4.05 ** - Cygwin-32 fork issue ongoing - identified that the problem is DLL load order, but not yet clear why this only affects Cygwin-32 or what the fix should be. - OCaml Developers' Meeting - a number of old GPRs discussed and triaged. Plea from Xavier that each dev triage, and preferably resolve, 5 Mantis PRs pcm.</p>
<h4 id="week-9-for-david-allsopp">Week 9 for David Allsopp</h4>
<p><em>Ill for most of the week :( </em></p>
<p>** OCaml Labs ** - Preliminary discussions with <span class="citation" data-cites="avsm">@avsm</span>, <span class="citation" data-cites="gemmag">@gemmag</span> on moving the CI into the lab.</p>
<p>** OCaml 4.05 ** - Cygwin fork issue fixed! Patch accepted upstream to the Cygwin DLL. Issue was that when DLLs are dlopen'd using FlexDLL, the dependencies between them are not known to Cygwin/Windows. Cygwin contained a dependency-based topological sort which was unstable for DLLs with no dependencies: the effect was that even calls to fork would work (as the list is reversed each time). DLL rebasing meant that the problem wasn't apparent on Cygwin64, but with correctly based DLLs, the same problem occurred. OCaml docs will be updated once the new Cygwin DLL has been released to note that the minimum version.</p>
<h4 id="week-10-for-david-allsopp">Week 10 for David Allsopp</h4>
<p>** OCaml 4.05 ** - Fixed the FlexDLL bootstrap allowing ocamlmklib to work correctly (GPR#1023). The fix is targeted for 4.04.1 and required a separate version for 4.05/trunk owing to the (very welcome) build system alterations. Lots of test cases... - Spent arguably too much time working on a test-case for the Unix.stat bug in GPR#1057. Interesting foray into kernel trickery on Windows (polite way of referring to disgusting code injection and re-writing tricks...)</p>
<h4 id="week-11-for-david-allsopp">Week 11 for David Allsopp</h4>
<p>** OPAM ** - Completed rebase and update of windows-build branch on to master. OPAM compiles, but the good stuff still needs cherry-picking/updating!</p>
<p>** OCaml ** - Finally set-up a proper test-bed for parallel testing Windows ports - Started Visual Studio 2017 testing for OCaml</p>
<h4 id="week-12-for-david-allsopp">Week 12 for David Allsopp</h4>
<p>** OCaml ** - Windows testing of 4.04.1/4.05.0 revealed a few issues with the CI (GPR#1115, GPR#1116) - AppVeyor testing is sooo slow - GPR#1116 in particular took ages to prepare waiting for CI results! - Supporting build system changes across 4.04 and 4.05 is also proving slow work (GPR#1101 / GPR#1023) but at least that's only for this release cycle!</p>
<h4 id="week-13-for-david-allsopp">Week 13 for David Allsopp</h4>
<h2 id="ocaml-7">OCaml</h2>
<ul>
<li>Lost quite a bit of time chasing down a non-existent platform bug :o( Issue was in fact a different OCaml being (incorrectly) picked up by the testsuite</li>
<li>More test cases for 4.04.1/4.05.0</li>
</ul>
<h4 id="week-14-for-david-allsopp">Week 14 for David Allsopp</h4>
<h2 id="ocaml-8">OCaml</h2>
<ul>
<li>Wrote and used test harness for FlexDLL testing in 4.04.1/4.05.1</li>
<li>Sorted out Cygwin issues with CRLF following on from February update of grep/awk/sed (GPR#1140)</li>
</ul>
<h4 id="week-15-for-david-allsopp">Week 15 for David Allsopp</h4>
<h2 id="misc-1">Misc</h2>
<ul>
<li>While working on something unrelated, found a possible exponential blow-up type-checking GADTs, but need to investigate further (using an older OCaml, so it might have been fixed)</li>
</ul>
<h2 id="ocaml-9">OCaml</h2>
<ul>
<li>Misc reviews and CI tweaks</li>
</ul>
<h4 id="week-16-for-david-allsopp">Week 16 for David Allsopp</h4>
<h2 id="opam-5">opam</h2>
<ul>
<li>Working through rebase of features in windows branch onto beta2</li>
<li>Upstreaming PR#2912 to fix a rollback problem with failed package installations</li>
</ul>
<h2 id="ocaml-10">OCaml</h2>
<ul>
<li>Git precommit hook and also GPR validation against our syntax rules (WIP - GPR#1148)</li>
<li>Various investigations for future work:</li>
<li>Tweaks to bring coloured output trivially to Windows 10 OCaml users</li>
<li>Windows 10 1703 Creators Update requires some tweaks for the Unix module - for 4.06</li>
</ul>
<h4 id="week-17-for-david-allsopp">Week 17 for David Allsopp</h4>
<h2 id="opam-6">opam</h2>
<ul>
<li>PR#2912 merged</li>
<li>Discussions with Louis on file format features required for Windows</li>
<li>Improved mechanism for detecting undefined variables. Presently, you can use &quot;%{foo}%&quot; which expands to &quot;&quot; if foo is undefined. New proposal adds operator ? so that ?foo returns false if foo is not defined.</li>
<li>Allow variables in ternary operator in string expansion. Presently, you can use &quot;%{foo?bar:baz}%&quot;. New proposal requires strings to be single quoted and interpret the rest as variables. So far, so hacky, but unfortunately you can't use scoped variables e.g. what should &quot;%{foo?bar:path:lib}%&quot; mean? Shelved, as there are other workarounds for this.</li>
<li>Mechanism for initialising switch global variables by extending /etc/opamrc</li>
<li>Upstreaming PR#2915 to fix issues with debugging failed updates</li>
<li>Upstreaming PR#2923 to fix issues with renaming the test and doc variables in opam-repository</li>
<li>Upstreaming PR#2921 to implement the defined operator ? described above</li>
</ul>
<h4 id="week-18-for-david-allsopp">Week 18 for David Allsopp</h4>
<h2 id="opam-7">opam</h2>
<ul>
<li>Teleconference discussing directions for opam 2.0</li>
<li>Roadmap of beta releases to follow (proposed release candidate to be beta3)</li>
<li>Windows hopefully included in beta4</li>
<li>Improvements to the upgrade story required (aim to allow safe side-by-side installation of 1 and 2)</li>
<li>Upstreaming PR#2927 to add &quot;%&lt;...&gt;%&quot; syntax for translating paths from Unix forward-slash style to Windows back-slash style. Lots of discussions ongoing for this...</li>
<li>Upstreamed PR#2928 to ease using Merlin when developing opam (merged)</li>
<li>PR#2915 merged</li>
<li>PR#2921 merged</li>
<li>PR#2923 abandoned (won't be necessary after beta3 is released)</li>
</ul>
<h2 id="ocaml-11">OCaml</h2>
<ul>
<li>Fixing problems with AppVeyor caused by GPR#1127</li>
</ul>
<h4 id="week-19-for-david-allsopp">Week 19 for David Allsopp</h4>
<h2 id="platform-1">Platform</h2>
<ul>
<li>Discussion with Gemma &amp; Anil on roadmap from here to ICFP (and a bit beyond...)</li>
</ul>
<h2 id="ocaml-12">OCaml</h2>
<ul>
<li>Started discussions on changes being made in GPR#1127 and GPR#1168 given nuisance it creates for Windows installations.</li>
</ul>
<h2 id="opam-8">opam</h2>
<ul>
<li>Upstreaming PR#2930 implementing the switch-defaults section for opamrc</li>
<li>Work on a --set option for opam init and opam switch allowing switch global variables to be specified at switch creation time (this builds on PR#2930)</li>
<li>Testing and updating lib-pkg build mechanism ready to transfer to Azure (I keep running out of disk space on my ageing opam development VM...)</li>
<li>Various Slack discussions about OPAM leading to docs change in PR#2941</li>
<li>Upstreaming PR#2935 &amp; PR#2936 containing various minor tweaks and fixes from windows-build</li>
<li>Upstreaming PR#2937 containing developer build options for opam</li>
<li>Upstreaming PR#2938 panellising lib-ext compilation</li>
<li>Upstreaming PR#2939 fixing the configuration and build system for native Windows</li>
<li>Upstreaming PR#2940 fixing the build process itself for native Windows</li>
</ul>
<h4 id="week-20-for-david-allsopp">Week 20 for David Allsopp</h4>
<h2 id="ocaml-13">OCaml</h2>
<ul>
<li>Various exchanges regarding the GPR#1127/GPR#1168/GPR#1172 build system changes</li>
<li>4.05 testing leading to a few tweaks (GPR#1177)</li>
<li>Fixes pushed to trunk and 4.05 fixing Inria CI (MacOS, mingw32/64, ppc32/64)</li>
</ul>
<h2 id="opam-9">opam</h2>
<ul>
<li>Oozing towards being able to run the make win-zips test on Azure.</li>
<li>Various build system tweaks required, especially dealing with Warning 58 (-opaque not used) in third party libs</li>
<li>msvs-tools needs updating for VS2017 and integrating - turns out that's not just a simple meta-data change (there's a new tool called vswhere which needs to be integrated with msvs-detect)</li>
<li>PR#2935 merged; various work rebasing and keeping up with the others</li>
<li>Complete sweep of open opam issues (now subscribed to all changes)</li>
</ul>
<h3 id="author-enguerrand-decorne">Author Enguerrand Decorne</h3>
<h4 id="week-17-for-enguerrand-decorne">Week 17 for Enguerrand Decorne</h4>
<ul>
<li>ocaml-tls binding: Separating handling of IOs from the OCaml code: now the C program must handle all IOs (networking, file reading)…</li>
<li>As of friday this is mostly finished and the handshake from a simple C TLS client is working.</li>
<li>A working prototype of the binding is to expect by the end of next week.</li>
<li>Worked on Canopy: Improved CSS, various bugfixes and PR reviews</li>
</ul>
<h4 id="week-19-for-enguerrand-decorne">Week 19 for Enguerrand Decorne</h4>
<ul>
<li>TLS: Implemented a few simple clients and servers using various C TLS libraries (libtls, mbedtls) to understand their API. Started to implement the binding trying to replicate libtls's interface.</li>
<li>Various things on Canopy (bugfixes)</li>
<li>Spent some time playing with Reason (reading the doc, tried to implement a web toplevel for Reason using js_of_ocaml), tried to debug an issue with ocaml-git</li>
</ul>
<h4 id="week-20-for-enguerrand-decorne">Week 20 for Enguerrand Decorne</h4>
<ul>
<li>TLS: Halfway through the binding implementation, the configuration parsing from libtls is now working for ocaml-tls, only things left is writing and reading on sockets and the binding will be complete.</li>
</ul>
<h4 id="week-23-for-enguerrand-decorne">Week 23 for Enguerrand Decorne</h4>
<ul>
<li>My first step is to take <span class="citation" data-cites="yallop">@yallop</span> script to generate ctypes bindings and make it generate some OCaml parse tree instead of generating OCaml sources so I try to find some ways of integrating it easily in a Reason/OCaml flow. One of the goal would be trying to avoid as much as possible fighting with a build system</li>
<li>I also took some time to finish a Reason js_of_ocaml REPL I started some months ago. We will probably communicate about it soon publicly, but for now it’s available there: https://engil.github.io/reason-web-toplevel/</li>
</ul>
<h4 id="week-31-for-enguerrand-decorne">Week 31 for Enguerrand Decorne</h4>
<ul>
<li>Worked on the ocaml-tls binding: Fixed a few memory leaks problems. Tried to run spacetime against the binding, to no avail Tried to run landmarks against the binding: not much success too.</li>
</ul>
<h3 id="author-gabriel-de-perthuis">Author Gabriel de Perthuis</h3>
<h4 id="week-1-for-gabriel-de-perthuis">Week 1 for Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>Start refactoring the way cache items are addressed. This is a precondition for flush support.</li>
<li>Document many design and implementation decisions.</li>
</ul>
<h4 id="week-2-for-gabriel-de-perthuis">Week 2 for Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>build a free space map from a filesystem scan</li>
<li>flush support</li>
<li>upgrade to mirage 3 interfaces</li>
</ul>
<h4 id="week-3-for-gabriel-de-perthuis">Week 3 for Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>reloading support, testing and bug fixing</li>
<li>indexing child and log structures from disk</li>
<li>freeing replaced nodes from the space map</li>
</ul>
<h4 id="week-4-for-gabriel-de-perthuis">Week 4 for Gabriel de Perthuis</h4>
<p><strong>Mirage Storage</strong></p>
<ul>
<li>Exercising the tree with synthetic data</li>
<li>Node splitting (work in progress)</li>
</ul>
<h4 id="week-5-for-gabriel-de-perthuis">Week 5 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Node splitting</li>
<li>Publish the work done in January to <a href="https://github.com/g2p/mirage-storage" class="uri">https://github.com/g2p/mirage-storage</a></li>
</ul>
<h4 id="week-6-for-gabriel-de-perthuis">Week 6 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Node splitting</li>
<li>Prep for log spilling</li>
<li>Some refactoring of childlinks</li>
</ul>
<h4 id="week-7-for-gabriel-de-perthuis">Week 7 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Anticipate out of space situations and raise an error if necessary</li>
<li>Log spilling: find which child can receive the most data</li>
</ul>
<h4 id="week-8-for-gabriel-de-perthuis">Week 8 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Log spilling</li>
<li>Move testing to ramdisks</li>
</ul>
<h4 id="week-9-for-gabriel-de-perthuis">Week 9 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Refactoring</li>
<li>Child node splitting</li>
<li>Bug fixing</li>
<li>Functoria pull request to switch the block implementation</li>
</ul>
<h4 id="week-10-for-gabriel-de-perthuis">Week 10 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Expanding tests</li>
<li>Bug fixing</li>
<li>Refactoring</li>
<li>Collecting and logging statistics</li>
<li>NeedsFlush signal</li>
<li>LRU pull request</li>
</ul>
<h4 id="week-13-for-gabriel-de-perthuis">Week 13 for Gabriel de Perthuis</h4>
<p><strong>Mirage storage</strong></p>
<ul>
<li>Insert: Fix a spill/split interaction</li>
<li>New LRU peek API</li>
</ul>
<h3 id="author-stephen-dolan">Author Stephen Dolan</h3>
<h4 id="week-4-for-stephen-dolan">Week 4 for Stephen Dolan</h4>
<ul>
<li>off sick monday / tues</li>
<li>progress on memory models! (more soon..)</li>
<li>mpi/multicore debugging with <span class="citation" data-cites="dhil">@dhil</span></li>
</ul>
<h4 id="week-10-for-stephen-dolan">Week 10 for Stephen Dolan</h4>
<p>Many multicore yaks now bald.</p>
<ul>
<li>Atomics module exists! (or part thereof)</li>
<li>Got the multicore test suite running properly, and integrated with Travis. Fixed a bunch of issues with the testsuite and the runtime.</li>
<li>Added GC stats in multicore (functions in <code>Gc</code> now work, and account properly for every word of the shared major heap). Found a bug in trunk OCaml while doing this, now fixed in trunk and 4.05.</li>
<li>Fixed heap verification in multicore (in particular, debug mode now checks at runtime that the GC stats aren't lies)</li>
<li>Got some pull requests to trunk OCaml merged (#1088, #1069, #973)</li>
</ul>
<h4 id="week-17-for-stephen-dolan">Week 17 for Stephen Dolan</h4>
<p>Lots of figuring out the interactions between asynchronous interrupts (e.g. signals, cancellation) and the rest of the system. Stealing a lot from Haskell's well-designed async exceptions.</p>
<h4 id="week-18-for-stephen-dolan">Week 18 for Stephen Dolan</h4>
<ul>
<li><p>Worked out how to do asynchronous syscalls by dynamically adjusting concurrency level with SCHED_IDLE threads. Should get us something like Haskell's safe foreign calls, but with much lower overhead.</p></li>
<li><p>Helped out with a pretty panicked TFP submission on the design of our effectful I/O (blocking syscalls, asynchronous effects, and the likes)</p></li>
</ul>
<h3 id="author-philip-dexter">Author Philip Dexter</h3>
<h4 id="week-23-for-philip-dexter">Week 23 for Philip Dexter</h4>
<p>My work this summer is about providing approximate programming tools for OCaml programmers. There are several different styles of approximate computing; each requires of their users different technical knowledge of the subject.</p>
<p>As one example, loop perforation is an approximate computing technique where iterations of a loop are skipped in the pursuit of reducing resource usage (be it time or energy). A loop perforation build system will generally have a self tuning step where, given test input and a fitness function from the user, the system can automatically deduce an approximation strategy. Further refinement by the user is indeed an option, but this is a good example of a technique which asks little of its user.</p>
<p>Loop perforation's ease of use leads KC and I to believe that adding a loop perforation system in OCaml is a great first step in the broader plan of supplying a goodie bag of approximation tools.</p>
<p>I have written a ppx extension for loop perforation. It is basic. In writing it I have both learned a lot about ppx extensions and expanded my compiler knowledge. The next steps are to decide whether to implement a self tuning system. If yes: the ppx extension and the self tuning system would make for a decent first release of an approximation system for OCaml. If no: there are other techniques for approximate computing that we can play with before we decide where to spend coding efforts.</p>
<p>We have met with a group in the lab which is interested in prolonging the flight time of their drone operations. It is hard to say whether there is a collaboration opportunity; approximate computing is not always the right tool for the job.</p>
<h4 id="week-24-for-philip-dexter">Week 24 for Philip Dexter</h4>
<p>A user cannot zealously apply approximate computing strategies to every line of every program they write. This week I have looked through three OCaml programs which I believe can benefit from approximation: 1. A ray tracer 2. A H.261 video decoder 3. The black--scholes algorithm for option pricing</p>
<p>Not all three programs have explicit for-loops---OCaml programmers tend to favor recursion---but all three have perforation opportunity.</p>
<p>My next step is to implement an interactive system which will guide a user in approximating their programs. It will first identify all potential loops/recursive calls in a program which allow perforation. Given this set it will then attempt to find the /best/ combination of perforation. Testing all possible combinations of loop perforation is unfeasible so some heuristics must be developed.</p>
<p>I also spent some time this week working on multicore OCaml. I wet my feet by writing a recursive lock implementation. The code can be found on [github] along with the [issue] requesting the implementation.</p>
<p><a href="https://github.com/ocamllabs/reagents/compare/master...philipdexter:recursive">github</a></p>
<p><a href="https://github.com/ocamllabs/reagents/issues/2">issue</a></p>
<h4 id="week-25-for-philip-dexter">Week 25 for Philip Dexter</h4>
<p>Our perforation system allows programmers to annotate looping constructs which they believe can benefit from perforation. Compiling an annotated program into an optimized program which uses loop perforation is not straghtforward.</p>
<p>The most difficult task of this system is in finding the optimal perforation configuration. One solution is to profile every possible permutation of configurations. As this is entirely unfeasible the most truly difficult task is finding a heuristic which allows us to prioritize configurations.</p>
<p>After running some subset of all configurations, there will be a smaller subset of optimal configurations which form a time-error tradeoff curve. Our end result would present this graph to the user, allowing them to choose which tradeoff works best for them.</p>
<p>My time this week has been split between converting a black--scholes C implementation to OCaml and a first draft of our perforation program. The perforation program can successfully run different perforation configurations however there are no heuristics involved yet.</p>
<h4 id="week-26-for-philip-dexter">Week 26 for Philip Dexter</h4>
<p>Our perforation system is ready for initial testing so this week I've mostly worked on running experiments. I translated a swaptions program into OCaml. A lot of time was spent fixing bugs in the translation but once everything was set up I ran it through our loop perforation system and have some initial results.</p>
<p>We haven't quite reproduced the results from the C perforation system in the paper I'm referring to. They show results where a 5x speedup is achieved with only a 1% loss in accuracy. Our system can only produce a 1.2x speedup while losing 5% accuracy. We can get to 2x speedup but we have to sacrifice 40% accuracy. We do not perform the same state space searching as the paper version does so when that is all set up we may be able to reproduce the results.</p>
<p>I'm confident that once we perform the same sort of searches as the C version we can gain similar speedups. This will be an immediate goal of next week.</p>
<h4 id="week-27-for-philip-dexter">Week 27 for Philip Dexter</h4>
<p>This week I have generalized the perforation system to the point where I was able to take an off-the-shelf ocaml implementation of kmeans clustering and run it through the perforation system. The program was able to produce nice, readable results for different configurations [attached image]. However when more than 2 loops are perforated, the data starts becoming very hard to visualize. The system is really smooth but it's still lacking: I had to turn one use of List.iter into a for loop. However, I have created a plan to perforate recursive functions which will allow the system to work on programs which don't use for loops.</p>
<p>This week I also worked with the reagents library for ocaml-multicore. In the beginning of the week I parallelized an existing ray tracer written in OCaml. (The ray tracer also is a good candidate for perforation.) Further, KC and I have discussed working on a lock-free hash table implementation to use in the Hack type checker (written in OCaml). Currently hack use a C hash table implementation strapped on the to OCaml code. Writing a competitive implementation in OCaml would be a great way to show of ocaml-multicore.</p>
<h4 id="week-28-for-philip-dexter">Week 28 for Philip Dexter</h4>
<p>This week I split my time under two projects: the continuing of my auto perforator and the datakit project.</p>
<p>The auto perforator is coming along very nicely. There is now a hill climbing algorithm built in which will explore the perforation state space. I have the system working under 3 domains: swaptions, ray tracer, and kmeans. I will give a talk about the system next Tuesday.</p>
<p>The datakit project is under KC's guidance. The idea is to use datakit to power a distributed key-value store. The implementation would be a domain for testing systems which adapt to byzantine errors by changing the strength of their reads into the database.</p>
<h4 id="week-29-for-philip-dexter">Week 29 for Philip Dexter</h4>
<p>Automatic perforation is coming to the point where it could be ready for more users. I have slowly started to focus on providing a good user interface.</p>
<p>This week I ran my auto perforation tool on two sets of inputs for kmeans with the goal of showing that results from a run of the automatic perforation program can be used to approximate further inputs. That is, running kmeans with the automatic perforator gives you a result on how to best perforate your loops. Using this result with future data sets previously unseen gives you just as good results. For this experiment I trained the perforation using 10 inputs with 100,000 points. I then ran the resulting perforated program on 10 other inputs of 1,000,000 points and achieved very similar results (a 5x speedup with only a 10% loss in accuracy).</p>
<p>This week I've written a blog post about the troubles with writing generic approximate computing frameworks (found at: http://phfilip.com/the-difficulty-in-a-general-approximate-computing-framework.html)</p>
<p>This week I've also discussed with KC at lengths about a use-case of approximate computing. The general idea is to add approximate reasoning to programs which work over distributed key-value stores. Programs in this domain are usually already written to handle consistency anomalies. The addition of a dynamic system to track and handle the levels of approximation could be a good fit for my approximate computing work.</p>
<h3 id="author-ciaran-lawlor">Author Ciaran Lawlor</h3>
<h4 id="week-27-for-ciaran-lawlor">Week 27 for Ciaran Lawlor</h4>
<p><strong>Monday</strong><br />
- Background reading. Refreshing how git works in more detail. Looking at irmin, datakit. - Reading articles from Thomas Leonard's blog.</p>
<p><strong>Tuesday</strong></p>
<p>Setting up opam / ocaml. - Installing opam using brew. Following RWO setup guide. Installing core, utop etc via opam. Configuring utop to #require core packages. - Setting up vim. Installing merlin and creating .merlin file. Installing ocp-indent-vim. Sorting out .vimrc. Installed syntastic, setup to use merlin.</p>
<p>Docker tutorial - Installed docker. Followed the basic docker tutorial - the basics of images, containers etc.</p>
<p>OCaml - Reading some more of Thomas Leonard's articles. Reading RWO.</p>
<p><strong>Wednesday</strong><br />
- Finished reading most of part 1 of RWO. Read some of the later chapters as well, but part 1 covers most of the language features.</p>
<p>Dependencies and utop - utop doesn't load the init file (.ocamlinit) when loading an ml file from the command line. Using #use loads the init file. - I expected utop to work with a file that used other modules in the same directory, but it doesn't. It is possible by building first using ocamlbuild and then using #load_rec on the cmo file. Useful for interacting / quickly testing a bit of code split across multiple files.</p>
<p>Lexing and Parsing - Read the chapter about parsing in RWO and managed to get the very basics working.</p>
<p><strong>Thursday</strong></p>
<p>IOCaml and Hydrogen - Setting up Hydrogen for Atom as explained on the website. Working with python (although requires running atom via terminal), need to get working with IOCaml. Installed OCaml support for atom using apm install language-ocaml. - Doesn't work on 4.03 for some reason, requires &lt; 4.03.0. Switching to 4.02.3. (Later on - after updating opam I can install on 4.03) - Trying to opam install IOCaml fails as it depends on gmp, which it isn't installing automatically. Installed manually with homebrew. - Still failing as ctypes won't compile - The compilation of ctypes failed at &quot;make XEN=disable libffi.config&quot;. - Installed libffi manually using brew. opam install IOCaml now works. - IOCaml doesn't work. Jupyter says 0 active kernels. Hydrogen works with python even if jupyter notebook isn't running, so I guess it's using its own instance. IOCaml works by itself from the command line, just not sure how to link with Jupyter or Hydrogen. - Jupyter doesn't have a kernel spec for IOCaml. I have no idea how to add one.</p>
<ul>
<li>There are pages on the IOCaml wiki for adding the kernel spec, but I can't figure it out.</li>
</ul>
<p>Lexing and Parsing<br />
- Messing around with ocamllex and Menhir in the afternoon, trying to create a simple template language. - Decided to try sedlex instead as it supports unicode. - sedlex won't install for 4.03. Latest version does work on 4.03 but opam isn't seeing it. Trying to figure out how to refresh the repo. - Can't find much (Later on - did I actually try opam update?). The latest version listed by opam is 1.99.2, but the opam repository online gives 1.99.3. - Adding PKG sedlex to my .merlin file causes 'Error while running external preprocessor'. Can't figure out what exactly is the problem for now, something to do with the fact sedlex uses ppx?</p>
<p>Sedlex<br />
- Just trying to lex for now, the template language consists of text and logic parts which need to be lexed differently, so the lexer needs some contextual infomation. - Managed to get lexing working pretty well for the template language, by using some mutable state. Don't think there is any other way really.</p>
<p><strong>Friday</strong></p>
<p>Sedlex<br />
- I'm currently testing my lexer by building, then going into utop and doing</p>
<pre><code>    #directory &quot;_build&quot;;;
    #load_rec &quot;_build/lexer.cmo&quot;;;</code></pre>
<p>This lets me quickly test it with different strings without having to rebuild, and lets me see the returned list of tokens.</p>
<ul>
<li><p>Sedlex doesn't let you define regexps using <code>let lid =   let lid1 = [%sedlex.regexp? R] in   [%sedlex.regexp lid1]   as they will be unbound. Currently doing: let lid1 = [%sedlex.regexp? R] let lid = [%sedlex.regexp lid1]</code> They have their own scope anyway.</p></li>
<li><p>Does defining a function within a function that is called often have a significant performance penalty to defining it outside the function?</p></li>
</ul>
<p><strong>Weekend</strong> - Messed around with lexing a bit more, got parsing working as well using Menhir. Requires using MenhirLib.Convert API as Menhir is made to work with ocamllex.</p>
<h4 id="week-28-for-ciaran-lawlor">Week 28 for Ciaran Lawlor</h4>
<p><strong>Monday</strong></p>
<p>IOCaml on 4.03 - Requires ctyptes. ctypes fails due to requiring libffi. There is a message about needing to brew install libffi but I missed it at first. Installed after that. - Forked and cloned iocaml, followed wiki post on iocaml github to create kernelspec for jupyter: <code>{   &quot;display_name&quot;: &quot;OCaml&quot;,   &quot;language&quot;: &quot;ocaml&quot;,   &quot;argv&quot;: [     &quot;&lt;full path to iocaml&gt;/iocaml.top&quot;,     &quot;-object-info&quot;,     &quot;-completion&quot;,     &quot;-connection-file&quot;,     &quot;{connection_file}&quot;   ]   }</code><br />
Had to use the full path to get it to work.<br />
Then run &quot;jupyter kernelspec install --name iocaml-kernel <code>pwd</code>&quot; inside that directory.<br />
And run<br />
<code>DYLD_LIBRARY_PATH= pwd :$DYLD_LIBRARY_PATH &amp;&amp; eval opam config env &amp;&amp; jupyter notebook --Session.key= --notebook-dir=notebooks</code><br />
to get jupyter running (again inside the iocaml directory). - Actually just <code>jupyter notebook --Session.key=</code> seems to work fine? - Hydrogen connects directly to the kernels without going through Jupyter (even though it uses jupyter for the kernelspecs). In atom, trying to use Hydrogen with ocaml code causes it to hang. Running just <code>jupyter notebook without --Session.key=</code> causes the server to repeatedly connect and disconnect to the kernel, so this is probably the issue.</p>
<p><strong>Tuesday</strong></p>
<p>IOCaml<br />
- Used 'apm develop hydrogen' to clone hydrogen as a development plugin, so I can modify it. To use my version I have to start atom with atom --dev. - Trying to figure out where exactly in Hydrogen the key stuff is set. Adding lots of console.log statements. - The connection to a kernel is created in kernel.coffee, which uses the config passed in by kernel-manager.coffee. - KernelManager either generates the config or loads it from ./hydrogen/connection.json in the atom project directory. So you can set key: &quot;&quot; and signature_scheme: &quot;&quot; in the json file, but then every option must be set. This means ports aren't found automatically etc, they must be set manually. * For now, I'm just hardcoding in the key and scheme into kernel.coffee. - Trying to do more with iocaml. Need to #require various things, but #use &quot;topfind&quot; doesn't work. That can be fixed by adding a .iocamlinit file to ~, starting it with</p>
<pre><code>  `let () =
    try Topdirs.dir_directory (Sys.getenv &quot;OCAML_TOPLEVEL_PATH&quot;)
    with Not_found -&gt; ()
  ;;
  #use &quot;topfind&quot;;;
  #thread;;
  #require &quot;iocaml-kernel.notebook&quot;;;</code></pre>
<ul>
<li>The actual ocamlinit doesn't need the above to come before adding other things like #use &quot;topfind&quot;. Shouldn't IOCaml load the toplevel path itself? (Some of Monday and Tuesday is summarised in a gist on github)</li>
</ul>
<p><strong>Wednesday</strong><br />
- Trying to figure out how iocaml displays data but I can't figure it out. There's something about adjustable type definitions. - Trying to figure out how hmac stuff works in zmq, but I don't think I'm going to get anywhere. IOCaml is difficult to figure out. Sockets are opened in sockets.ml, messages are sent and received though message.ml only? - Following datakit quick start. Managed to get the basics working. - Trying to get ocaml 9p working, currently a dependency bug. - Can't connect to the docker container yet, trying to figure out.</p>
<p><strong>Thursday</strong></p>
<p>Datakit<br />
- I can run it in docker but I can't actually connect to it. Trying to connect ocaml-9p just eventually results in a timeout. - Got it connecting, had to expose the port to the host using -p 5640:5640. (Most of Thursday was spent reading about docker networking or looking at datakit or ocaml-9p, so not much to log.)</p>
<p><strong>Friday</strong></p>
<p>Shell for ocaml-9p or datakit<br />
- Writing a quick lexer and parser for the commands so that things like strings and ids are actually handled properly. - Works pretty well, quite resilient. Parses input into an AST of commands with their arguments. Also handles strings properly, plus relatively easy to extend. - I'm writing this in such a way that tab completion should be fairly easy to add. - To interact with Datakit I will need to install it properly rather than through docker so I can use it in my program. But currently it won't make - getting error during linking, undefined symbols for x86_64. - Experimenting with Notty to make the shell interactive, for things like tab completion. - Notty doesn't seem to support applications that aren't full screen terminal when capturing key presses. For example utop allows tab completion while still being scrollable. Notty generally seems to be more for graphics. lambda-term should support this but looks more low level and depends on Camomile. - Notty also doesn't appear to clean up the terminal after ctrl + c, leaves mouse interaction on etc. And ctrl c can't be intercepted.</p>
<h4 id="week-29-for-ciaran-lawlor">Week 29 for Ciaran Lawlor</h4>
<p><strong>Monday</strong> - Experimenting with Notty to make the shell interactive, for things like tab completion. - Notty doesn't seem to support applications that aren't full screen terminal when capturing key presses. For example utop allows tab completion while still being scrollable. Notty generally seems to be more for graphics. lambda-term should support this but also has a lot of stuff that I probably don't need. - Notty also doesn't appear to clean up the terminal after ctrl + c, leaves mouse interaction on etc. And ctrl c can't be intercepted. - Actually it does allow capturing scrolling events and mouse position, so maybe I can implement scrolling manually instead, but not ideal.</p>
<p><strong>Tuesday</strong> - Would be good to handle unterminated input - e.g. if string doesn't have a closing quote or if the line ends in a backslash then go to the next line. Requires some support in the lexer. - Notty assumes unicode throughout so I will too. Supporting unicode by storing input as an int list and using that when lexing and printing back to the terminal. - I'm currently lexing and parsing the entire input on each keystroke, as I need to know the meaning of the input to be able to do prediction. Not really ideal but usually commands are so short that it might not matter. I might have a go at making it more efficient anyway.</p>
<p><strong>Wednesday</strong> - I spent today trying to figure out a better way of supporting completions by trying to only lex the part of the input that changes and swap out the affected tokens. I got it sort of working but it was buggy and had lots of mutable state so I gave up on it, at least for now.</p>
<p><strong>Thursday</strong> - Notty will only capture input events when using a single screen (not scrollable) terminal application, so using print doesn't work as it's quickly overwritten when redrawing the screen. This would be fine as I could just return a string and handle printing elsewhere, but as a lot of the stuff with ocaml-9p is asynchronous I might want to print during executing the command to let the user know what's happening. Which means I might have to take another look at Lambda-term. - In terms of supporting completions, I had a look at Cmdliner as it parses the arguments and automatically checks if an arg is a file or an int etc, which would be useful information for prediction. Would be cool to be able to pass the Cmdliner data to this shell and have prediction done automatically, but unfortunately not really possible. - I can add a small amount of stuff to add prediction to an existing program that uses Cmdliner (or something else). Basically just two functions (one for named args and one for positional args) that map a prefix to a list of possibilities.</p>
<p><strong>Friday</strong> - Got most things working together today, commands now work properly. Still haven't actually got the actual interface working yet though...</p>
<h4 id="week-30-for-ciaran-lawlor">Week 30 for Ciaran Lawlor</h4>
<p><strong>Monday</strong> - Rewrote a lot of the code as I was using quite a bit of mutable state. For example, using an array to store the current input. Now storing it as two int lists (ints as characters are unicode), the first representing the input before the cursor (stored in reverse), and the second representing the input after the cursor. Lots of other changes as well. <strong>Tuesday</strong> - Some more rewriting. Code a lot terser and almost no mutability. - Managed to get Notty working with scrolling etc by disabling canonical mode myself then passing the input from stdin into the notty module to filter escape sequences. A bit of a hack but it means I can use notty and have proper scrolling etc, and don't have to redraw everything each time. - Still a few things that are only half working. For example tab completion is kind of there but not actually 'wired up'. <strong>Wednesday</strong> - Not much to log, just starting to get the shell working with ocaml-9p, rather than just the couple of small examples I've been using so far. - I've written the shell to be synchronous at the moment, which won't work well with things like ocaml-9p, so I'm going to change it to use Lwt throughout.</p>
<h4 id="week-31-for-ciaran-lawlor">Week 31 for Ciaran Lawlor</h4>
<p><strong>Wednesday</strong></p>
<p>Current state of the shell: - Commands work, but I haven't actually added most of the commands. E.g. connecting doesn't actually work as it's asynchronous, so using Lwt throughout is top priority. - Tab completion doesn't really work. It kind of did at one point, but I've changed quite a lot of stuff since then. Should be fairly easy to get working again though. - Parsing the input works mostly fine, handles quotes / strings, allows escaping etc. - Notty interface now works, which means I can continue using Notty, but it isn't perfect.</p>
<h4 id="week-32-for-ciaran-lawlor">Week 32 for Ciaran Lawlor</h4>
<p><strong>Monday + Tuesday</strong></p>
<p>Rewrote the lexer and parser to be able to understand more about the input, i.e. whether it's a positional arg, flag or optional arg etc. This also requires that the parser have access to the commands and their arguments so that required some more rewriting. This information can then be used for both predictions and syntax highlighting. It's also easier to extend. Parsing optional arguments is tricky because it means the next positional value might actually be their value. Quite a few edge cases, and haven't added support for a few widely used conventions like using -- to denote that the next value is a positional value, or using = when specifying values.</p>
<p><strong>Wednesday</strong></p>
<p>Working on making predictions better using the additional information. Quite a lot of cases. Just doing the basic ones for now. Flags only need their name predicted. Non flags need their name predicted but can also predict their value. Positional arguments can be predicted based on their index. Not working yet for optional arguments. Also not working for some other edge cases.</p>
<p><strong>Thursday</strong></p>
<p>Added syntax highlighting by traversing the raw input and the syntax tree together. Some more work on prediction. Refactoring and separating out modules.</p>
<h3 id="author-sander-spies">Author Sander Spies</h3>
<h4 id="week-24-for-sander-spies">Week 24 for Sander Spies</h4>
<ul>
<li>started moving RWO examples from corebuild to jbuilder</li>
</ul>
<h4 id="week-28-for-sander-spies">Week 28 for Sander Spies</h4>
<ul>
<li>Worked on the OCaml-webworker</li>
</ul>
<h4 id="week-30-for-sander-spies">Week 30 for Sander Spies</h4>
<p>gist tool: - autocomplete is now accessible via ctrl+space in the gist tool - moved to promise based communication with the webworker</p>
<h3 id="author-maxime-lesourd">Author Maxime Lesourd</h3>
<h4 id="week-2-for-maxime-lesourd">Week 2 for Maxime Lesourd</h4>
<ul>
<li>Set up a blog hosted on github pages. I plan to do a few posts about my attempts at typing and/or verifying the CPS translation</li>
<li>Made some progress on the Agda formalization of a lambda calculus with simple effects</li>
<li>The syntax and types are done</li>
<li>The small step semantics using substitution is almost done</li>
<li>The abstract machine needs some work</li>
</ul>
<h4 id="week-3-for-maxime-lesourd">Week 3 for Maxime Lesourd</h4>
<ul>
<li>Started writing on the work I've done so far</li>
<li>Finished setting up the blog after some troubles with mathjax over https</li>
<li>Little progress on the Agda developments. Since we still don't have a typed cps translation I'm going to spend less time on this.</li>
<li>The plan for next week is to have a summary our attempts at &quot;verifying&quot; the cps translation either through a type system or a proof that it preserves semantics. Then we can start asking for outside feedback and see what we can do.</li>
</ul>
<h4 id="week-4-for-maxime-lesourd">Week 4 for Maxime Lesourd</h4>
<ul>
<li>Spent most of my time figuring out the application process for my future PhD...</li>
<li>Made some progress on the report, the introduction is almost done.</li>
</ul>
<h4 id="week-5-for-maxime-lesourd">Week 5 for Maxime Lesourd</h4>
<p>I'm trying to figure out all the places in TypedTree which end up as function definitions or applications for the effect analysis.</p>
<p>I also spent some time improving error messages in the fomega tool used for the advanced functional programming course.</p>
<h3 id="author-qi-li">Author Qi Li</h3>
<h4 id="week-44-for-qi-li">Week 44 for Qi Li</h4>
<ol type="1">
<li><p>Measure the performance of PIH-gatekeeper(infrastructure within UCN), mainly the operation latency when serving clients' requests. As there are different branches based on the validity of client certificate and/or the right to access a data holding unikernel, accordingly there are different scenarios where the PIH-gatekeeper need to be measured against.</p></li>
<li><p>As mort successfully updated the dom0 OS from Debian-based to Alpine earlier last week, I started to port the system to the new platform. The out-of-box SDcard image has insufficient storage space assigned for dom0, I can't install required tools/libraries in it, then I started to rebuild one image which has larger persistent storage space.</p></li>
</ol>
<h4 id="week-45-for-qi-li">Week 45 for Qi Li</h4>
<ol type="1">
<li><p>Working with sys-admin to set up the PIH service to our external collaborators.</p></li>
<li><p>Bumping into some bug in the MirageOS TCP/IP stack, only until yesterday did I be able to locate it , will try to fix it and issue a PR on github later</p></li>
<li><p>Continuing porting some services to Alpine based system. For now, the service accessible to the partners are running on a Debian based system. The binaries for unikernels were easy to deal with, but there are some parts need some dynamically linked libraries, I tried different ways: statically link these libraries; porting these parts together with the libraries; altering the unikernel's implementation to get rid of these parts. For now, I'm settling with the last solution, but I think I would try the <code>porting with libraries</code> later, case the bug in &quot;2&quot; made me think that solution wouldn't work initially. Since I'm not very familiar with the building tools (especially with the linking phase), I think the first solution will cause me more time.</p></li>
</ol>
<h4 id="week-46-for-qi-li">Week 46 for Qi Li</h4>
<ul>
<li><p>Finished porting to the Alpine system, now our PIH system is running on Alpine based cubeietruck full time. This involved putting the data persistence service and web interface for the end user into a debian-based domU.</p></li>
<li><p>Figured out and fixed various bug (well, at least temporarily), mainly about PIH-bridge. This part works like a Network Address Translation device, which is doing traffic relays between clients and data holding unikernels. It will keep using up its own port numbers on its network interfaces if there is no proper &quot;garbage collection&quot; for the port numbers. This bit became a problem when our collaborators started testing there demos against our PIH, where lots of connections would be involved. Indeed, to make it more robust, we have to address this problem. For the time being, each translation rule has its own lifetime(5 min for now), and a queue is maintained in memory to hold these rules, once the number of rules reaches a threshold(30_000 for now), a function will be invoked to clear out all expired rules.</p></li>
</ul>
<h4 id="week-47-for-qi-li">Week 47 for Qi Li</h4>
<p><em>Magnus is interesting in spending a day a week contributing to the MirageOS and DataBox efforts, specifically around the work he has already done on Jitsu, ARM and networking. He will spend Wednesdays in the Lab around the standup time and work with Qi on the new Alpine xen-arm-builder distribution, to get it up to speed. He is also working on mirage-vnetif and testing of the network stack.</em></p>
<ul>
<li><p>before Wednesday, run the system prepared for UCN final review to make sure it works, worked out the serial output from cubie so that without a vga screen we could still have a prompt to do the work, made SD card copies</p></li>
<li><p>from Wednesday on, in Portugal, for the UCN final review, discovered that both the original card and the copy were corrupted because of some last second invalid writes crossing partition boundaries on the card, panicked, put up something mimicking the behaviour of PIH to make sure our partners' demos could still run, since in the schedule, we wouldn't demo anything, it's just our collaborators using our platforms, then the review seemed going well...</p></li>
</ul>
<h4 id="week-49-for-qi-li">Week 49 for Qi Li</h4>
<ul>
<li><p>talked with mort about the next project/direction to work on, for now, there are two possibilities: about PIH-store, develop a model-based compression engine inside of it, so that the data could take up much less storage space, yet with tolerant divergence from their real values; another one is about developing some temporal logic(together with buffer management) to extend the expressibility of packet capturing of network traffic</p></li>
<li><p>talked with Magnus about work within MirageOS tcp/ip stack testing, at the moment there are testing about different parts of a protocol (say for TCP, we have tests for options and window management), Magnus is working on more different vnetif backends (to simulate different network traffic failure modes), I think there may be something missing in between, like tests when different parts of a protocol working together as a whole under various scenarios, or a test for layers in the stack working together with different packets traces, there are some parts in test_rfc5961.ml and test_iperf.ml, but I think there should be a easier way to express these and a higher level interface to create packets and traces instead of manually created cstruct(s), I'd like to develop something like `packetdrill', probably together with a test environment and I've already started to look into this.</p></li>
</ul>
<h4 id="week-3-for-qi-li">Week 3 for Qi Li</h4>
<ul>
<li><p>Read literatures about model-based data compression. Found two algorights that might be apt to integrate into pih-store, Adaptive Piecewise Constant Approximation and Slider Filter. They are both online processing algorights. The idea is to cut the stream of data into appropriate segments, and fit the data in each segment to a specific linear function. Next week, may try to implement the first version of this.</p></li>
<li><p>Continued learning about the design and structure of <code>packetdrill</code>. Still not clear about what shoud the statck test framwork should look like.</p></li>
<li><p>Browsed some repos that use <code>topkg</code> from <a href="http://erratique.ch/software/topkg/doc/Topkg.html#menagerie">doc page</a>, finished learning how to use it.</p></li>
</ul>
<h4 id="week-4-for-qi-li">Week 4 for Qi Li</h4>
<ul>
<li>work done for Databox</li>
<li>meeting with mort and Liang to clarify the functionalities/patterns of interactions for the new system components to be developped: storage and bridge.</li>
<li>for storage, it will provide tamper-proof, append-only logging of each store operations, and it will support different data types: Json, Timeseries, Blob, etc. Later, we could be more high-level features like model based compression on this</li>
<li><p>for bridge, still needs more discussion and thinking, for the first step, we could build it with &quot;redirect point&quot; style, which allows third parties to register/update their services, look up the others' services, and also allows internal components to insert/delete their own plug-in functions.</p></li>
<li>supervision</li>
<li><p>IB course CompNet</p></li>
</ul>
<h4 id="week-5-for-qi-li">Week 5 for Qi Li</h4>
<ul>
<li>storage component of Databox</li>
<li>implemented tamper-proof logging feature of the store</li>
<li>implemented store engine, providing support for json and blob(by Cstruct.t) data types</li>
<li>browsed repo <a href="https://github.com/me-box/databox-export-service.git">ocaml-macaroon</a> and <a href="https://github.com/sevenEng/databox-bridge">opium</a>, for the purpose of integration into the store</li>
</ul>
<h4 id="week-6-for-qi-li">Week 6 for Qi Li</h4>
<ul>
<li>implementation of <a href="https://github.com/me-box/databox-export-service.git">databox-storage</a></li>
<li>design and implementation of <a href="https://github.com/sevenEng/databox-bridge">databox-bridge</a></li>
</ul>
<h4 id="week-7-for-qi-li">Week 7 for Qi Li</h4>
<ul>
<li>implementation of <a href="https://github.com/me-box/databox-export-service.git">databox-bridge</a></li>
<li>using ocaml-macaroons to do the access right control of API</li>
<li>allow local driver/app to submit export request to a queue</li>
<li>worker thread (single one for now) extracts a request from the queue and processes it</li>
<li><p>driver/app polling the same API to get update on its request (may support websocket notification)</p></li>
<li><p>next week may spend some time to test the basic working flow, add logging operations, ws support maybe</p></li>
</ul>
<h4 id="week-9-for-qi-li">Week 9 for Qi Li</h4>
<ul>
<li><a href="https://github.com/me-box/databox-export-service.git">databox-export-service</a> (<em>we renamed the repo from 'databox-bridge' to this</em>)</li>
<li>Dockerised this repo, added docker hub autobuild, added opam file to use opam to install the service</li>
<li>Supported https by wrapping <code>cert</code> and <code>key</code> environment varialbles into local files, and passing them to the <code>opium</code> interface</li>
<li>Refactored <a href="../blob/master/test/test.ml">test.ml</a> to make it easier to write more tests from client side rather the monolithic single test before this</li>
<li>Added some new tests to test against scenarios where we would have invalide id or macaroons etc.</li>
<li><p>Tried out some new libraries to make days easier: <code>depyt</code>, <code>rresult</code>, <code>bos</code> etc.</p></li>
<li>databox-bridge:</li>
<li>Discussed the functionalities and interactions with other components, should be able to see the very first version next week</li>
<li><p>Step one: assuming bridge has connected to the right network and so do other components, it should recognize DNS requests, give right responses and then forwarding ethernet packets to the right interfaces</p></li>
</ul>
<p><em>Only realized forgot to add the weekly 8 while in the middle of this week, so this log actually covered work done for the past two weeks</em></p>
<h4 id="week-10-for-qi-li">Week 10 for Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>implemented a long-polling version endpoint, temporarily with the route <code>/lp/export</code></li>
<li><p>added a test case against this endpoint</p></li>
<li>databox-bridge:</li>
<li>decided to try to implement at first with docker bridge, equivalent to use <code>docker network create ...</code> and <code>docker network connect ...</code> to connect pairs that need communications</li>
<li>implemented this <a href="https://github.com/me-box/databox/pull/50">link</a>, waiting for more polishing and testing before merged</li>
<li><p>catched up with mirage3, cause later there should be a stand-alone bridge component rather that a patch in databox's container manager</p></li>
</ul>
<h4 id="week-11-for-qi-li">Week 11 for Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>implemented websocket version of the endpoint, kept in a seperate branch for now: <a href="https://github.com/me-box/databox-export-service/tree/ws">ws</a></li>
<li><p>refactored bits of the test part and the export logic part, to ease the integration of ws endpoint</p></li>
<li>databox-bridge:</li>
<li>finished the first implementation, and merged</li>
<li><p>fixed some bugs, opened PRs to opium and upstream js libraries</p></li>
</ul>
<h4 id="week-12-for-qi-li">Week 12 for Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>bug fixes and working arounds to make the demo work for the launch, mainly tied to macaroons-related stuff</li>
<li>disabled the tests on dockerhub autobuild, refer to <a href="https://github.com/me-box/databox-export-service/pull/14">PR</a></li>
<li><p>NB: impression was that the image from autobuild could be corrupted? <em>Output like: Illegal Instruction (core dumped), through gdb found that the binaries tried to disable address space randomization?</em></p></li>
<li>databox-bridge:</li>
<li>such unstable that could make it for the launch event, will keep persuing this end later</li>
<li>should figure out the right timing and order of network creating and connection</li>
<li><p>should provide better failure control within inner libs</p></li>
</ul>
<h4 id="week-13-for-qi-li">Week 13 for Qi Li</h4>
<ul>
<li>made some PRs to upstream macaroons libraries</li>
<li>merged in the websocket endpoint to the service</li>
</ul>
<h4 id="week-16-for-qi-li">Week 16 for Qi Li</h4>
<ul>
<li>databox-export-service</li>
<li>change the inner service model from multiple clients one queue to one client one queue</li>
<li><p>produce basic latency and queueing effect analysis plots</p></li>
<li>databox-irmin-store</li>
<li><p>implement basic kv/ts stores read/write functionalites</p></li>
</ul>
<h4 id="week-17-for-qi-li">Week 17 for Qi Li</h4>
<ul>
<li>databox-irmin-store</li>
<li>write tests for kv/ts stores about r/w and websocket sub/unsub functionlities</li>
<li><p>dockerize this component and shrink the image size</p></li>
<li>databox-bridge</li>
<li><p>browse the repo ocaml-openflow investigating the possibilities of integration</p></li>
</ul>
<h4 id="week-18-for-qi-li">Week 18 for Qi Li</h4>
<h4 id="databox-bridge-2">databox-bridge</h4>
<p>Thes first step is to intercept l2/l3 packets from multiple interfaces and forward them.</p>
<p>All the existed MirageOS network io solutions may not seem to fit:</p>
<ul>
<li>this compoment will be used inside a docker container, so <code>xen</code> is not good</li>
<li><code>unix</code> and <code>ukvm</code>, <code>virtio</code> targets all use tap devices to do the network io, so for each container interface, there will be bridging and NATing, which will filter out the arp traffic and the ip traffic not targeting the same network</li>
</ul>
<p>So for now, looking into the possibility of a new network device for unikernels, which is on unix, and instead of openning tun/tap devices, open raw sockets and output the l2 packets</p>
<p>Maybe could also modify the <a href="https://github.com/mirage/mirage-net-unix/blob/master/src/netif.ml#L58">mirage-net-unix</a>, to use <del><code>opentun</code></del><em>(mixed opentun and opentap here, so this approach doesn't work)</em> inside the <code>connect</code> function call <em>(tried earlier, but resulted in failures, could look further in the <a href="https://github.com/mirage/ocaml-tuntap/blob/master/lib/tuntap_stubs.c#L73">c code</a>)</em></p>
<h4 id="week-19-for-qi-li">Week 19 for Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>trying out a unix-based network device for mirage unikernel</li>
<li>following the idioms from <a href="https://github.com/mirage/ocaml-tuntap/blob/master/lib/tuntap_stubs.c">tuntap_stabs.c</a>, instead of <code>open(&quot;/dev/net/tun&quot;)</code>, get a packet socket by <code>socket(PF_PACKET, SOCK_RAW, ...)</code>, then add housekeeping and io functions around this socket</li>
</ul>
<h4 id="week-20-for-qi-li">Week 20 for Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>developped a mirage network device that could be attached to the host interface directly</li>
<li>used packet socket in c layer, so not a compatible solution for all targets</li>
</ul>
<h4 id="week-21-for-qi-li">Week 21 for Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>investigated the DNS service within docker environment</li>
<li>each container has a local dns server sitting at 127.0.0.11 on not standard <em>(53)</em> port</li>
<li>the default setting for container could be changed to assign a cutomized endpoint for DNS queries</li>
<li>looked for ways to change network gateway for containers</li>
</ul>
<h4 id="week-22-for-qi-li">Week 22 for Qi Li</h4>
<ul>
<li>databox-bridge</li>
<li>started implementing a first version by plumbing through DNS for containers not on the same network</li>
<li>adopted the idea of a forward DNS server, if couldn't resolve, forward to <code>127.0.0.11:&lt;port&gt;</code></li>
</ul>
<h4 id="week-23-for-qi-li">Week 23 for Qi Li</h4>
<h4 id="databox-bridge-3">databox-bridge</h4>
<ul>
<li>supported dns, containers from different networks that are connected by the bridge could resolve the domain names of each other</li>
<li>looked into <a href="https://github.com/moby/vpnkit">vpnkit</a>, code about de/multiplexing packets from/to multiple tcp/ip stack endpoints could probably reused by the bridge</li>
<li>when started, each stack registerd itself to some central dispatching unit</li>
<li>for input, push packets to the same stream</li>
<li>the central unit drain from the stream, parse packets, distribute packet to corresponding stack</li>
</ul>
<h4 id="week-30-for-qi-li">Week 30 for Qi Li</h4>
<ul>
<li>developping the bridge</li>
<li>adopted the idea of vpnkit: core part listening on a unix socket, unikernels, each responsible for a network interface, forwarding packets back and forth to the core part</li>
<li>provided two preliminary endpoints to configure the bridge: <code>/connect</code> and <code>/disconnect</code>, both accept a pair of container names, the bridge will resolve these names using a system resolver and translate them into ipv4 packets filter based on the resolved ip addresses</li>
<li>the configuration service is using a vnetif-based tcpip stack, pitfall got stuck in and out later after hours of debugging: <code>use_async_readers:true</code>, should've read the <code>README.md</code> : (</li>
<li>control rules also include the limited name resolving rights, only <code>connected</code> components could resolve the name of each other</li>
</ul>
<h3 id="author-frédéric-bour">Author Frédéric Bour</h3>
<h4 id="week-50-for-frédéric-bour">Week 50 for Frédéric Bour</h4>
<ul>
<li>Distributed witnesses, https://github.com/let-def/distwit (with <span class="citation" data-cites="samoht">@samoht</span> )</li>
<li>Solve the problem of marshalling exceptions / extensible type by externalizing the equality.</li>
<li>HyperLogLog, https://github.com/let-def/grenier/blob/master/hll/hll.mli</li>
<li>Cardinality estimation in constant space. I made a p-o-c implementation a while ago, now there is one user.</li>
<li>I added serializability, improved memory representation and fixed a bug causing small biases in estimations</li>
<li>Macho support for Owee, https://github.com/let-def/owee, WIP</li>
<li>Loading Macho would be useful for supporting macOS binaries in spacetime.</li>
<li>This would also a cheap lwt instrumentation tool for monitoring and backtraces. I discussed with <span class="citation" data-cites="antron">@antron</span>, maybe we will look at providing the necessary hooks in the future.</li>
<li>OCaml meeting (monday last week, some notes about stuff I want to look at)</li>
<li>Namespace: Didier Remy worried about specification of build (clumsy, not part of the langage)</li>
<li>Interested by bytecode/native interoperability (mentioned by <span class="citation" data-cites="dim">@dim</span>, <span class="citation" data-cites="stedolan">@stedolan</span>)</li>
<li>About release process: too much GPR, not enough testing &amp; code review, quality not satisfying</li>
<li>Eliom presentation (yesterday) &amp; talk with <span class="citation" data-cites="drup">@drup</span></li>
<li>Seems feasible to add eliom support to Merlin.</li>
</ul>
<h4 id="week-51-for-frédéric-bour">Week 51 for Frédéric Bour</h4>
<p>I haven't progressed much on merlin this week, all my work was reason-related</p>
<h4 id="week-1-for-frédéric-bour">Week 1 for Frédéric Bour</h4>
<ul>
<li><p>OCaml compiler work (that affects Reason and OCaml): migrating the parse tree - with Alain Frisch and Jeremie Diminio - different solution. Useful for JS via ppx and FB via Reason.</p></li>
<li>Merlin:</li>
<li><p>Stateless frontend: Happy with it as it stands, has not optimised performance, but what is currently there works. Planning to spend some time at JS working on integration as it is quite a deep change - after POPL.</p></li>
</ul>
<p>Merlin TODO: - Stateless wrapper for Windows: started, more difficult than expected. The current design is not portable, so needs to work on that and then implement it. Needs Windows box - arriving next week. - Logging: Logging is made possible by the stateless frontend. Has a prototype but doesn't match - will progress quickly once started - likely early January. - Parsing: Meeting Francois to discuss features/direction</p>
<h3 id="author-joel-jakubovic">Author Joel Jakubovic</h3>
<h4 id="week-27-for-joel-jakubovic">Week 27 for Joel Jakubovic</h4>
<p><strong>Tuesday</strong></p>
<p>Tried installing OPAM and OCaml etc on Windows:</p>
<p>Follow the instructions on https://github.com/protz/ocaml-installer/wiki, up to the final Sanity Check <code>Env var OCAMLLIB</code> exists, so I &quot;clean it up&quot; - removing it, I assume, from my environment. However I can only do so for my current cmd session using SET, and it doesn't show up in systemwide environment variables so I assume it must be part of my user account's environment. Unfortunately I cannot change or access those; &quot;edit environment variables for your account&quot; shows no dialog, nothing (this has been a problem on my machine for a while, but I've never needed the feature till now). So I decide to unset OCAMLLIB in my Cygwin terminal, as it will at least persist for that session. I get to running opam install depext-cygwinports, but I get errors and unfortunately the others are not able to fix.</p>
<p>Later I open Cygwin terminal again. I forget to source .bashrc and run opam install depext-cygwinports and to my surprise it works. I then opam install zarith batteries stdint etc. and it also works, although I have to use the &quot;fake install&quot; steps in the Troubleshooting section. I then look at https://github.com/realworldocaml/book/wiki/Installation-Instructions and opam install core utop, but I get: <code>[ERROR] core is not available because your system doesn't comply with os != &quot;win32&quot; &amp; ocaml-version = &quot;4.02.3&quot;</code></p>
<p>I also read at the beginning of the article that Core is unsupported on Windows. So maybe I will have to go through the hassle of installing an Ubuntu VM after all, since my existing one is at home on my external hard drive.</p>
<p>opam install'd core utop on Ubuntu. Initially had some issues with an older version but fixed them.</p>
<p><strong>Wednesday</strong></p>
<p>Begin by installing the next list of packages. During the process I get one</p>
<p><code>Building conf-zlib.1:    pkg-config zlib  [ERROR] The compilation of conf-zlib.1 failed</code></p>
<p>I later end up with detailed error descriptions (as well as one for cohttp) giving &quot;Out of space&quot; errors - I'd given it the default size of 8GB, and I'd used a fixed-size virtual disk so it can't just be resized!</p>
<p>After wasting time grappling with VirtualBox to accept my new 512GB dynamic vdi, I now need to expand the partition or something. But I know nothing about it, and it involves boot-level munging of irreversible operations and I am seriously not interested in reinstalling the VM along with all the OCaml/OPAM stuff that took absolutely ages yesterday (and will probably take even longer, given my new VDI is dynamic). Instead I resolve to see what I can do in OCaml without zlib or cohttp installed in OPAM.</p>
<p>Not a great deal, it seems. For when I type in utop to my terminal (now using the old 8GB disk) all I get is Fatal error: unknown C primitive <code>unix_has_symlink</code></p>
<p>I would be surprised if this had anything to do with the lack of zlib or cohttp, since they were opam packages presumably for development. I google a bit, find similar looking errors, and do eval <code>opam config env</code>, try again and this time I'm finally in.</p>
<p>And it only took two whole days!</p>
<p>Later, we get to Docker, where I continue getting through Real World OCaml and receive a licence key for Windows 10 Professional - thanks Dr. Titmus.</p>
<p><strong>Thursday</strong></p>
<p>I begin the day by attempting the Windows 10 Pro upgrade three times in a row, using the official channels. Frustratingly, each time, after the restart, it appears as if nothing has happened. I'm still on Home. Maybe it would be better after all to just get a computer at Docker and the CL.</p>
<p>I talk to Graham Titmus and download the Win10 Multiple Editions ISO from DreamSpark. It tells me I'll need to burn it to a boot disk, so I go back to Titmus' office to ask - he isn't there, so after a while I go back and e-mail him, continuing with R.W.O in the meantime.</p>
<p>The time comes to run corebuild on my VM. I do so, and I get the &quot;out of memory&quot; error, because I'm still using the 8GB disk. I thought I could get away with it.</p>
<p>Titmus arrives and gives me a disk. I burn the ISO to the disk. I go through the setup process and, after many loooong waits eventually come to the final setup screen. &quot;You have chosen to: install Windows Home&quot; nope, I never chose anything like that, or even had any options. Google told me that the Multiple Editions version contained both Home AND Professional - and that it would ask me which one I would like.</p>
<p><code>C:\WINDOWS\system32&gt;dism /Get-WimInfo /WimFile:D:\sources\install.wim   Deployment Image Servicing and Management tool   Version: 10.0.10586.0</code></p>
<p><code>Details for image : D:\sources\install.wim</code></p>
<p><code>Index : 1   Name : Windows 10 Pro   Description : Windows 10 Pro   Size : 14,516,205,352 bytes</code></p>
<p><code>Index : 2   Name : Windows 10 Home   Description : Windows 10 Home   Size : 14,431,121,717 bytes</code></p>
<p>The operation completed successfully.</p>
<p>So it does contain Pro. Why didn't it acknowledge this? Perhaps I need to boot from the disc instead.</p>
<p>I can't seem to boot from it. Instead I enter in the new code to System &gt; Activation. This time it takes a LOT longer ... but ultimately ends up just like the other attempts.</p>
<p>I give up. I'll use my VM.</p>
<p>Increased primary partition, shouldn't have any (of the same) problems now.</p>
<p><code>$ eval</code>opam config env<code>$ opam install -y async yojson core_extended core_bench cohttp async_graphics cryptokit menhir merlin</code></p>
<p><code>...</code></p>
<pre><code> `#=== ERROR while installing conf-zlib.1 =======================================#
  # opam-version 1.2.0
  # os           linux
  # command      pkg-config zlib
  # path         /home/jdj27/.opam/4.03.0/build/conf-zlib.1
  # compiler     4.03.0
  # exit-code    1
  # env-file     /home/jdj27/.opam/4.03.0/build/conf-zlib.1/conf-zlib-5816-d2c37b.env
  # stdout-file  /home/jdj27/.opam/4.03.0/build/conf-zlib.1/conf-zlib-5816-d2c37b.out
  # stderr-file  /home/jdj27/.opam/4.03.0/build/conf-zlib.1/conf-zlib-5816-d2c37b.err`</code></pre>
<p>Googled, performed some magic, got it to work.</p>
<p>Continuing with RWO, this time much faster and more productively since I now have something to type into.</p>
<p><strong>Friday</strong></p>
<p>Just did RWO today, finally, was nice - got through several chapters, now up to chapter 8 (Imperative programming).</p>
<h4 id="week-28-for-joel-jakubovic">Week 28 for Joel Jakubovic</h4>
<p><strong>Monday</strong></p>
<p>Setting up Angstrom: I follow the readme instructions, ignoring the initial opam install as the package is not yet released.</p>
<p><code>opam pin add -n angstrom .   opam install --deps-only angstrom</code></p>
<p>Which goes fine.</p>
<p>I want to use vim to explore the source but it complains that it doesn't have alcotest, so I fix that:</p>
<pre><code> opam install alcotest
  [...]
  Building fmt.0.8.0:
  ocaml pkg/pkg.ml build --pinned false --with-base-unix true --with-cmdliner true
  Installing fmt.0.8.0.
  [ERROR] &#39;pinned&#39; has type bool, but a env element of type string was expected`</code></pre>
<p>Messing around with versions settles on alcotest.0.4.1 as one that works. I run the config and make commands without incident.</p>
<p>Spent the rest of the day surveying Angstrom, OCaml internals and practising more Vim.</p>
<p><strong>Tuesday</strong></p>
<p>Wrote simple test parser for balanced parentheses using Angstrom. Went surprisingly smoothly - my previous experimentation with parser combinators and monads earlier in the year has clearly paid off.</p>
<p>Wrote initial version of ANSIparse - first test results in out-of-memory from infinite loop somewhere. !!</p>
<p>Rewrote the grammar and the code, still need to rewrite testing code and do the tests.</p>
<p><strong>Wednesday</strong></p>
<p>Continued rewrite a few times. Became apparent during testing that I had misread the format codes and fixed that. Got a working parser from string -&gt; (style list * string) list, eg</p>
<pre><code>`&quot;Hello, \x1b[1mBrave, \x1b[4;31mNew \x1b[0mWorld!&quot;`

to

`[ ( []                    , &quot;Hello, &quot; );
  ( [Bold]                , &quot;Brave, &quot; );
  ( [Underline; Fore Red] , &quot;New &quot;    );
  ( [Reset]               , &quot;World!&quot;  ); ]`</code></pre>
<p>Now I need to work on the structuring, i.e. converting to HTML. There is already implicit structure; (styles, str) :: rest applies styles in order to str AND, implicitly, rest. However, the presence of Reset turns things off. I wonder how useful it would be to try and extract some tree structure from this data by e.g. matching styles and Resets.</p>
<p><strong>Thursday</strong></p>
<p>Today, worked on making the parser incremental, in that it works a line at a time given its intended use. Ran into some more unpleasant infinite-loop bugs; one of which was of the form</p>
<pre><code>`Items --&gt; Item*
Item --&gt; Escape | Text
Text --&gt; char*`</code></pre>
<p>So we can derive &quot;HELLO&quot; as</p>
<pre><code>Items --&gt; Item* --&gt; Text* --&gt; Text --&gt; &quot;HELLO&quot;, or
Items --&gt; Item* --&gt; Text* --&gt; Text Text* --&gt; &quot;HELLO&quot; &quot;&quot;, or &quot;HELLO&quot; &quot;&quot; &quot;&quot;, etc... and never finishing</code></pre>
<p>So I had to add lookahead whereby the parser for Text fails if it will read the empty string (because it's at the end of input).</p>
<p><strong>Friday</strong></p>
<p>Split into concrete (text) and abstract (tree) modules for later use. Had a look at TyXml.</p>
<h4 id="week-30-for-joel-jakubovic">Week 30 for Joel Jakubovic</h4>
<p>Discussed with KC some interesting ideas I've been having related to making GUI programming less painful. Possible direction for Part II research. I need to investigate the existing literature and write up a brief explanation of what I'm looking at. Also, in the context of this summer, need to see if I can integrate it with the work I'm doing at Docker / OCaml Labs. KC suggested working on same as Ciaran: build 9P client, to develop these principles and test them.</p>
<p>Summary:</p>
<ul>
<li>Motivation comes from building games, where the rule is reinventing the GUI wheel every time.</li>
<li>GUIs are systems of lots of interacting components. Difficult to code and organise.</li>
<li>Immediately tied up with graphics and layout: naive, ad-hoc solutions based on fixed, pixel coords and sizes commonplace.</li>
<li>Want graphical systems that automatically adjust to different constraints eg window shape/size.</li>
<li>iOS uses Cassowary constraint solver... potentially solved problem, but need expertise in linear prog / optimisation to implement...</li>
<li>The other broad problem area: specifying interaction.</li>
<li>Java Swing approach: add event listeners to everything. Asynchronous imperative programming: not scalable with complexity.</li>
<li>Reinventing for Game N: take similar approach. Sick of it</li>
<li>My ideas: related to DSLs, formal languages, grammars, parsers.</li>
<li>Fundamental hypothesis: Parser generators convert language specs into parsers - state machines which accept / reject (and, structure) linear sequences of tokens. Usually thought of as text, but my insight is this: the inputs (mouse, keyboard) that the user submits to an interface are a just such a linear sequence; simply in the time dimension. What if: when we write horrible imperative Java Swing ActionListeners, we are actually painstakingly and unwittingly constructing, by hand, the state machine for a parser of the UI's language? And if so, could it be easier to write UIs as formal grammars of some sort, and then automatically generate the parser (application code) from them? Just as you would enlighten a newbie to CS who has not heard of grammars and who writes all their parsing code in an ad-hoc manner. And furthermore - how useful would it be to view ALL programs (of the sort that depends on inputs from the outside world) as parsers - the language-vs-machine view; elaborate on the fact that, when we slog through the imperative state code for Turing machines, we're dually writing parsers for their [recursively enumerable] languages.</li>
<li>In one sense, a command-line utility that adds numbers together doesn't just do that - rather, it takes a bunch of characters from the command line and spits out more characters, which happen to correspond to numbers in a particular way.</li>
<li>Final facet: the principle of compositionality and abstraction. Context-free grammars; their benefits and limitations. Embedding semantics / context-sensitivity into grammars. CFGs let you elaborate in a top-down manner.</li>
</ul>
<h3 id="author-gemma-gordon">Author Gemma Gordon</h3>
<h4 id="week-1-for-gemma-gordon">Week 1 for Gemma Gordon</h4>
<p><strong>General</strong> - Catching up post-Christmas MANY EMAILS<br />
- Exploring using furore for weekly worklogs with a view to everyone adding their weekly logs directly<br />
- Paperwork and administration for visiting researchers to the lab<br />
- Working on our 2016 catch up report: https://ocamllabs.github.io/furore/index.html<br />
- Prepping Oct-Dec short report on activities<br />
- Helping settle David Allsopp in the lab for his first day<br />
- Writing up a blog about the MirageOS feedback<br />
- Working on MirageOS logos</p>
<p><strong>Projects</strong> - Talked with Fred re Merlin progress:<br />
- stateless frontend: working on wrapper for Windows<br />
- logging: working on currently<br />
- parsing: late Jan, needs to talk with Francois first<br />
- Talked with Mark Shinwell (JS) about Merlin use at JS and issues they are facing<br />
- Planning Romain's next project with OCL</p>
<h4 id="week-2-for-gemma-gordon">Week 2 for Gemma Gordon</h4>
<ul>
<li>Completed first draft of MirageOS Feedback blog</li>
<li>Ongoing OCL Oct-Dec report</li>
<li>Admin/management for new visitors</li>
<li>Multicore planning with KC and Stephen - specifically repo organisation</li>
<li>Working on MirageOS 3.0 posts/articles and press details</li>
<li>Submit Slack for Education application</li>
<li>Plan POPL liveblog</li>
<li>Start work on OCL site with updated information</li>
<li>Start planning for Maintainerati</li>
</ul>
<h4 id="week-3-for-gemma-gordon">Week 3 for Gemma Gordon</h4>
<ul>
<li>Finished MirageOS feedback blog: http://reynard.io/2017/01/18/MirageIRCFeedback.html</li>
<li>Ongoing report</li>
<li>MirageOS press details</li>
<li>New OCL site started: https://ocamllabs.github.io/</li>
<li>Funding planning and allocation for next quarter</li>
</ul>
<h4 id="week-4-for-gemma-gordon">Week 4 for Gemma Gordon</h4>
<ul>
<li>Continuing with OCL site: https://ocamllabs.github.io/</li>
<li>Planning for new interns and visitors</li>
<li>Catching up with Platform activity: odoc, odig, topkg</li>
<li>Planning Compiler Hacking: https://ocamllabs.github.io/compiler-hacking/2017/01/24/february-compiler-hacking.html</li>
</ul>
<h4 id="week-5-for-gemma-gordon">Week 5 for Gemma Gordon</h4>
<ul>
<li>Adding more information to new OCL site - getting there!</li>
<li>Need to add projects next, most of the authors now added</li>
<li>Checking into Platform progress: odig, odoc, topkg</li>
<li>Preparing for Maintainerati in SF (15th Feb)</li>
<li>Planning Romain's next project with us</li>
<li>Preparing for Compiler Hacking next Tuesday</li>
</ul>
<h4 id="week-8-for-gemma-gordon">Week 8 for Gemma Gordon</h4>
<ul>
<li>Attended <a href="https://maintainerati.org/">Maintainerati</a> in SF last week (15th Feb)</li>
<li>Working on blog post about conference</li>
<li>Helped schedule OCL Platform blog posts go coincide with Mirage 3.0 release</li>
<li>General blog posts for OCL site</li>
<li>Porting the rest of our older content onto new site</li>
<li>Paperwork for new starter - Nicolas Assouad starting his internship next Monday (27th)</li>
<li>Wrote short blog post on Irmin release: http://ocamllabs.io/releases/2017/02/24/irmin1release.html</li>
<li>Designed and ordered MirageOS Hack t-shirts</li>
<li>Broke Atom on my laptop :(</li>
</ul>
<h4 id="week-9-for-gemma-gordon">Week 9 for Gemma Gordon</h4>
<ul>
<li>Moving a lot of information over from ocaml.io to ocamllabs.io - taking a long time</li>
<li>Still working on maintainerati blog draft...</li>
</ul>
<h4 id="week-10-for-gemma-gordon">Week 10 for Gemma Gordon</h4>
<ul>
<li>Finished the Maintainerati blog post: http://reynard.io/2017/03/07/MaintaineratiWontFix.html</li>
<li>Planning for Databox launch</li>
<li>Paperwork</li>
<li>Proofreading ppx updates from Fred: https://github.com/let-def/ocaml-migrate-parsetree/blob/master/MANUAL.md</li>
<li>Moving more content over to ocamllabs.io</li>
<li>Following MirageOS hack retreat updates on Twitter: http://ocamllabs.io/events/2017/03/06/MirageHackUpdates.html</li>
</ul>
<h4 id="week-12-for-gemma-gordon">Week 12 for Gemma Gordon</h4>
<ul>
<li>Databox launch on the Friday</li>
<li>Paperwork</li>
<li>Preparing contracts</li>
<li>Monthly and quarterly updates</li>
<li>Moving more content over to ocamllabs.io</li>
<li>Collating MirageOS hack retreat trip reports</li>
<li>Starting proposals for interns this summer</li>
</ul>
<h4 id="week-15-for-gemma-gordon">Week 15 for Gemma Gordon</h4>
<ul>
<li>Infrastructure quotes and specs</li>
<li>Attended the PowerSwitch Symposium - notes/blog post to follow</li>
<li>Planning Q3 activities and events</li>
</ul>
<h3 id="author-takayuki-imada">Author Takayuki Imada</h3>
<h4 id="week-43-for-takayuki-imada">Week 43 for Takayuki Imada</h4>
<p>My research topic - Started learning OCaml, and finished installation of OCaml on my laptop. - Completed the chapter 1 of Real World OCaml and now following the chapter 2 - Felt I need to have a flexible mind to understand the OCaml language expression.</p>
<p>Others - Arrived at Cambridge 16th Oct. - Found my long term flat and I will make a contract with a landload in this weekend. - Still setting up IT services (e-mail address, lab network, printer/scanner).</p>
<h4 id="week-45-for-takayuki-imada">Week 45 for Takayuki Imada</h4>
<p>What I have done in the recent weeks is as follows; - Finish reading (and testing codes in) Real World OCaml which will be related to my research topic - Investigated how MirageOS boots up on Xen by reading the MirageOS and mini-os source codes, and understood how OCaml based modules and the mini-os part in MirageOS interact - Started reading papers, documents, and source codes of Netmap and DPDK networking frameworks to consider how I can taking advantages of them in implementing my network acceleration feature on MirageOS</p>
<h4 id="week-46-for-takayuki-imada">Week 46 for Takayuki Imada</h4>
<ul>
<li>Made a list of functionality in existing networking software and hardware for virtualised environments.</li>
<li>both Netmap and DPDK have a similar approach (software-based packet switching, userspace packet processing)<br />
</li>
<li><p>using SR-IOV VFs is difficult to apply to some situations (for example, combined with DPDK on ARM) So I will conduct performance evaluation of the current implementation to understand which part is a bottleneck</p></li>
<li>Preparing for the performance evaluation for the coming MirageOS v3 release</li>
<li>I will be engaged in network related topics.</li>
<li><p>I have started building a MirageOS/Solo5 testbed (in Japan) to easily move to the actual evaluation in a local environment. I will learn and test Mirage-related operations on the testbed in advance</p></li>
</ul>
<h4 id="week-47-for-takayuki-imada">Week 47 for Takayuki Imada</h4>
<ul>
<li>Completed building my MirageOS/Solo5 environments in Japan</li>
<li><p>they are operating perfectly.</p></li>
<li>Investigating and trying to execute existing network programs on MirageOS</li>
<li>found arp and iperf implementation, but found out they cannot use with the latest MirageOS branch (mirage-dev) due to rapidly changing MirageOS APIs</li>
<li>modifying their source codes: arp : modification finished and worked correctly iperf: under modification, network connection and data transfer were OK but a result printing part was wrong</li>
<li><p>I will move to learning of performance profiling on MirageOS after finishing the iperf modification</p></li>
</ul>
<h4 id="week-48-for-takayuki-imada">Week 48 for Takayuki Imada</h4>
<ul>
<li>Preparing for the network performance evaluation</li>
<li>finished the iperf modification, now iperf can be conducted between independent MirageOS VMs</li>
<li>finished investigation of performance profiling schemes for MirageOS/Solo5</li>
<li>tested mirage-trace-viewer and it worked fine</li>
<li>investigated Xen and QEMU/KVM tracing facilities, and confirmed they can provide what I want to know (I will try them later) https://blog.xenproject.org/2012/09/27/tracing-with-xentrace-and-xenalyze/ http://www.linux-kvm.org/page/Perf_events http://vmsplice.net/~stefan/stefanha-tracing-summit-2014.pdf</li>
<li>Started implementing an automation framework of the network performance evaluation</li>
<li>Completed rough implementation design and checking other software required</li>
<li>I will implement it next week</li>
</ul>
<h4 id="week-49-for-takayuki-imada">Week 49 for Takayuki Imada</h4>
<ul>
<li>Preparing for the network performance evaluation</li>
<li>Implementing an automation framework of the network performance evaluation
<ul>
<li>This will be finished in several days</li>
<li>Took long time to solve how to get logs of the MirageOS console (A logging scheme provided by Libvirt could not work, so I investigated and tried other logging frameworks)</li>
</ul></li>
<li>Making a slide deck to introduce my work at OCaml Labs to Hitachi Data systems guys</li>
<li>90% finished
<ul>
<li>I will be able to submit the slide to you for checking next week</li>
<li>I will also check what kind of checking process in Hitachi for the slide is needed.</li>
</ul></li>
</ul>
<h4 id="week-50-for-takayuki-imada">Week 50 for Takayuki Imada</h4>
<ul>
<li>Preparing for the network performance evaluation -&gt; Finished automation framework implementation for the network performance evaluation.</li>
<li>The automation script I implemented worked fine. -&gt; Started building a MirageOS environment on another physical server @ packet.net.</li>
<li>MirageOS/Solo5: mirage-dev</li>
<li>OCaml version: 4.03.0, 4.04.0</li>
<li>Hypervisor: Xen, KVM(virtio) -&gt; But now having a problem in executing MirageOS with OCaml v4.03.0 on Xen, so investigating how to solve it.</li>
<li>This seems a bug in MirageOS. -&gt; Also started and finished the iperf network performance evaluation on Linux Virtual Machines.</li>
<li>on the physical server above.</li>
<li>Observed throughput: 38MB/s(128 bytes buffer length), 290MB/s(1024 bytes buffer length)</li>
</ul>
<h4 id="week-51-for-takayuki-imada">Week 51 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Finished it on MirageOS and Linux VMs.</li>
<li>Observed network throughput on MirageOS VMs is worse than on Linux VMs. We will need to investigate why this happens.</li>
<li>128-byte buffer size:
<ul>
<li>3MB/s on MirageOS-Xen, 24MB/s on MirageOS-virtio</li>
<li>46MB/s on Linux-Xen, 38MB/s on Linux-virtio</li>
</ul></li>
<li>1024-byte buffer size:
<ul>
<li>16MB/s on MirageOS-Xen, 38MB/s on MirageOS-virtio</li>
<li>230MB/s on Linux-Xen, 295MB/s on Linux-virtio</li>
</ul></li>
<li>Also preparing for releasing my source codes on the Github.</li>
<li>this includes only source code sophistication for releasing, and will be finished in several days.</li>
</ul>
<h4 id="week-1-for-takayuki-imada">Week 1 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>started preparing for performance bottleneck investigation.
<ul>
<li>finished building a QEMU/KVM hypervisor with a tracing feature by ftrace, and confirmed it can work.</li>
<li>building my MirageOS environment with the profiling support.<br />
</li>
</ul></li>
<li>Tools for network performance measurement</li>
<li>Finished making them available on the GitHub Website.</li>
<li>(throughput) https://github.com/TImada/mirage_iperf</li>
<li>(latency) https://github.com/TImada/mirage_pingpong</li>
</ul>
<h4 id="week-2-for-takayuki-imada">Week 2 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>finished preparing for performance bottleneck investigation.
<ul>
<li>finished learning and testing how to conduct tracing on Xen as well as on QEMU/KVM.</li>
<li>finished building my MirageOS environment with the profiling support.</li>
</ul></li>
<li>TCP-based iperf tracing
<ul>
<li>Found the vCPU utilization on the receiver side reached 100% though the sender side did not (~30%)</li>
<li>also found it difficult to capture their behavior due to complicated ACK/SYN mechanisms in the TCP stack, so decided to use UDP.</li>
<li>I will resume this after finishing the UDP-based iperf investigation</li>
</ul></li>
<li>UDP-based iperf tracing
<ul>
<li>Finished coding UDP-based iperf based on TCP-based iperf</li>
<li>Tracing in the MirageOS layer and the Xen layer by using the mirage-trace-viewer, xentop and xentrace commandes</li>
</ul></li>
</ul>
<h4 id="week-3-for-takayuki-imada">Week 3 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>iperf tests for tracing done, so I am summarizing findings from the tests</li>
<li>Findings
<ul>
<li>the CPU utilization on the sender side reached 100%</li>
<li>there were waiting (or blocking) periods on the sender side, they are not anticipated and occupy 50% of the total network processing time. (Due to thread scheduling?)</li>
<li>the waiting periods always occurred during a &quot;ring.write&quot; phase</li>
<li>The receiver side had sleeping periods which would correspond to the waiting periods above, so its CPU utilization was not so high.</li>
</ul></li>
<li>I will need to specify what triggers the waiting periods.</li>
</ul>
<h4 id="week-4-for-takayuki-imada">Week 4 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Conducted a test on the unix configuration, and found that the sender and receiver sides behavior was quite simple without any blocking periods. This indicates Xen or the network bridging on the hostOS can affect the blocking periods.</li>
<li>Having additional tests where the sender(receiver) program on a MV and the receiver(sender) program on Dom0 to reduce noise from the virtualization side.<br />
</li>
<li>Had a meeting with Docker members to explain the findings. Comments from them are as follows;
<ul>
<li>To try to put one of the sender or receiver sides on Linux.</li>
<li>To try to have one unikernel VM having both the sender and receiver side using the vnetif module to completely remove noise from network bridging on the hostOS.</li>
<li>Checksum offloading and IP fragmentation offload will help us to improve the network performance.</li>
<li>ukvm rather than Xen would be better and easier for implementing a new network interface layer.</li>
</ul></li>
</ul>
<h4 id="week-5-for-takayuki-imada">Week 5 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Implemented my iperf program using Mirage vnetif as an interconnect, and found there were still unexpected waiting(blocking) periods. So I concluded that somthing in MirageOS triggered this behavior. I will investigate a root cause of it by starting with further tracing schemes in MirageOS.</li>
<li>Conducted further analysis based on the previously obtained results, and found that the host OS side processing(i.e. network bridging) can occupies higher than 65% of the total network processing time without the unexpected waiting periods. This is an expected result, not suprising. The host OS side processing time can be reduced by taking advantage of existing schemes such as Netmap or DPDK.</li>
<li>Prioritized topics to be conducted
<ol type="1">
<li>investigation of the waiting periods not anticipated</li>
<li>implementation design to reduce overhead in the host OS side</li>
<li>implementation design to reduce overhead in the MirageOS network protocol layer</li>
</ol></li>
</ul>
<h4 id="week-6-for-takayuki-imada">Week 6 for Takayuki Imada</h4>
<ul>
<li>Network performance evaluation</li>
<li>Found out that the long waiting periods is a Xen-specific issue, it did not occur under my QEMU/KVM configuration.</li>
<li>Observed waiting periods even under the QEMU/KVM configurations, but they were shorter than under my Xen configuration and their fequency was low.</li>
<li><p>I will not have furuther investigation on this issue if not required, so I will move to designing new software archtecture to achieve higher network perforamnce on MirageOS.</p></li>
<li>FOSDEM2017</li>
<li>Attended the event to get topics realted to network, micro-kernel, micro-service, virtualization.</li>
<li>Several presentations were intersting for me (For example, TCP acceleration by using Intel Transration Layer Development Kit which is based on DPDK).</li>
<li><p>I will have a short presentation to report this topic on 28th Feb.</p></li>
</ul>
<h4 id="week-7-for-takayuki-imada">Week 7 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Conducted investigation to understand which part (MirageOS or the host OS) affects the waiting periods, and found out only MirageOS probably does affect them. I confirmed that network processing on the host OS does not take such long time.</li>
<li>Started reading the source code of Solo5-ukvm to understand the current implementation of it. I found that (i) modular-based implementation in Solo5-ukvm helps me to easily add my new networking feature and (ii) the current Solo5-ukvm does not use vhost-net (= large room for performance improvement)</li>
<li>I will continue to understand the current Solo5-ukvm architecture in more detail next week. I will also start designing my networking feature after that.</li>
</ul>
<h4 id="week-8-for-takayuki-imada">Week 8 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Found that the longer waiting periods under Solo5-virtio were caused due to GC, and that they can be managed by changing the minor heap size. I will not have further investitation on the above because they are not a dominant factor of the current performance bottleneck.</li>
<li>Completed reading the source code of Solo5-ukvm, learned how Solo5-ukvm operates in receiving and sending network packets.</li>
<li>Also found that Solo5-ukvm can have longer waiting periods not anticipated expecially in packet sending (maybe) due to its polling mechanism.</li>
<li>I will need to determine if I should tackle the new issue under Solo5-ukvm, and to start designing new networking archtecture for Solo5.</li>
</ul>
<h4 id="week-9-for-takayuki-imada">Week 9 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Attended MirageOS Hack Retreat on 1st-2nd March, and mainly had discussions on Solo5 with Martin.</li>
<li>Learned the current implementation philosophy of Solo5 and found that it focus on only simplicity and its functionality, not on performance.</li>
<li>Conducted iperf experiments under Solo5-ukvm, and confirmed that longer waiting periods in the sender side actually affets the iperf throughput performance. (Only 7MB/sec throughput due to the waiting periods though I confirmed the receiver side can achieve 70MB/sec throughput)</li>
<li>I will start designing new networking scheme wich consideration of the current Solo5-ukvm.</li>
</ul>
<h4 id="week-10-for-takayuki-imada">Week 10 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Found that the low performance under Solo5-ukvm was caused by a fault in my source code, and confirmed that the UDP iperf performance was 40MB/sec.</li>
<li>However, the receiver side can achieve 70MB/sec. This indicates that a current bottlenec is in the sender side.</li>
<li>Further investigation in the virtualization layer showed that the virtualization layer is a main overhead, and GC handling as shown in the previous experiments is not a performance impact.</li>
<li>I will continue to design new networking scheme wich consideration of the current Solo5-ukvm by the end of this month.</li>
</ul>
<h4 id="week-11-for-takayuki-imada">Week 11 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Started investigation of the current impelementation of Intel DPDK and Netmap to understand what can be a point to be considered.</li>
<li>Findings:
<ul>
<li>DPDK does packet handling in the user space whereas Netmap does it in the kernel layer</li>
<li>DPDK uses busy loop polling for packet arrival detection whereas Netmap uses a NAPI-like scheme (=mix of busy loop polling and interrupts)</li>
<li>Both DPDK and Netmap require a virtualized PCI device and virtualized interrupts for a virtual machine when we try to use the currently available features for virtual machines. However, Solo5-ukvm currently does not have the required functions. So they will ba a challenging point I must tackle.</li>
</ul></li>
<li>learned the current behavior of vhost-net in handling network packets, found that eventfd, irqfd and ioeventfd are used to realize in-kernel network packet processing in vhost-net.</li>
<li>Started creating a pros/cons table of DPDK and Netmap to check i) how many gaps they have and ii) how large the gaps are when I try to integrate them into MirageOS.</li>
</ul>
<h4 id="week-12-for-takayuki-imada">Week 12 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Conducted some experiments to check how long time the MirageOS network stack spends for packet processing. Found that the IP packet frame allocation occupies 30-35% of the total processing time in MirageOS OCaml part, and that the VMExit/Entry cost cannot be negligible.</li>
<li>I will try to reduce the former bottleneck by employing an additional upper layer on Netmap or DPDK, and the latter bottleneck by reduction of context switching.</li>
<li>Still filling out a Pros/Cons table on network acceleration schemes.</li>
</ul>
<h4 id="week-13-for-takayuki-imada">Week 13 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>No advance this week (due to a private trip)</li>
</ul>
<h4 id="week-14-for-takayuki-imada">Week 14 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Finished completing the Pros/Cons table, then I decided to employ Netmap rather than DPDK as a network acceleration scheme as DPDK usually requires a busy loop-based packet handling.</li>
<li>Desingning basic implementation to integrate Netmap into Solo5-ukvm. I will introduce a vhost-net like scheme to reduce the number of VMExit/Entry.</li>
</ul>
<h4 id="week-15-for-takayuki-imada">Week 15 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Learned how to write a user program with Netmap, and investigated vhost-net implementation detail.</li>
<li>Finished designing integration of Netmap into Solo5-ukvm. Decided to employ Netmap in the host user layer to reduce the integration cost. I found that using Netmap in the host kernel layer costs a lot for lack of Netmap APIs.</li>
</ul>
<h4 id="week-16-for-takayuki-imada">Week 16 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>No updates in this week. (attended DockerCon17 @ Austin)</li>
</ul>
<h4 id="week-17-for-takayuki-imada">Week 17 for Takayuki Imada</h4>
<ul>
<li>Network performance</li>
<li>Started implementing a new networking scheme using Netmap on Solo5-ukvm.</li>
<li>The first phase would be replacing a network tap device by a Netmap port, and the second phase would be integration of ioeventfd to reduce the number of VMExits.</li>
<li>Had discussion with Martin(<span class="citation" data-cites="Docker">@Docker</span>) about the scheme above including how I can conduct the implementation.</li>
</ul>
<h4 id="week-18-for-takayuki-imada">Week 18 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Confirmed that device initialization including queue allocation and finalization parts operates correctly.</li>
<li>Finished coding sender and receiver functions. I will check if they can operate correctly the next week.</li>
</ul>
<h4 id="week-19-for-takayuki-imada">Week 19 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Confirmed the first implementation operated correctly for the 1460 bytes MTU size.</li>
<li>But found that it could not operate when I tried larger MTU size such as 9000 bytes due to strange behavior in the Netmap layer(data frame was split into some blocks with the maximum size 2048 bytes). I will not investigate more on this issue.</li>
<li>I will move to performance evaluation in terms of 1) different MTU size smaller than 1460 bytes, and 2) scalability.</li>
</ul>
<h4 id="week-20-for-takayuki-imada">Week 20 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished writing some script files to conduct performance evaluation</li>
<li>Started the performance evaluation as follows:
<ol type="1">
<li>a pair of receiver and sender unikernels on a host physical server</li>
<li>multiple pairs of the unikernels on a host physical server</li>
<li>multiple pairs of the unikernels on two different physical servers(multiple sender unikernels on a physical server, and multiple receiver unikernels on the other physical server)</li>
</ol></li>
</ul>
<h4 id="week-21-for-takayuki-imada">Week 21 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Evaluated the network throughput performance with the first Implementation. But the first implementation does not achieve good performance compared with the original Solo5-ukvm(up to 10% performance degradation).</li>
<li>The main reason of this performance is high overhead in data queue syncing with DMA triggering on a NIC on the sender side. The first implementation does packet sending one by one depending on data write function calls from the GuestOS layer, so highly frequent write function calls can easily lead to performance degradation. This is not anticipated because data queue syncing is managed by Netmap.</li>
<li>Additionally, I also found that softirq RX processing is always triggered when packet sending is done, and the softirq processing is heavy load. This is the specification of the current Netmap implementation. I need to reduce the number of packet sending calls as possible.</li>
<li>However, I will move to the second implementation phase because reduction of the number of packet sending calls is planned in the second phase.</li>
</ul>
<h4 id="week-22-for-takayuki-imada">Week 22 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Started implementation of the second phase.</li>
<li>Finished iothread porting from kvmtool<a href="https://github.com/me-box/databox-export-service.git">1</a>, and confirmed ioeventfd-based trapping worked as expected.</li>
<li>Investigating the current design of the upper layers(mirage-tcpip and mirage-net-solo5) to have a new path between mirage-tcpip in a guest OS and Netmap on its host OS.</li>
</ul>
<p><a href="https://github.com/me-box/databox-export-service.git">1</a> https://git.kernel.org/pub/scm/linux/kernel/git/will/kvmtool.git</p>
<h4 id="week-23-for-takayuki-imada">Week 23 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished implementation of Netmap buffer mapping test functions, and confirmed Netmap buffers on the host OS can be directly accessed from the guest Solo5-ukvm kernel.</li>
<li>The current memory mapping location is designed like MMIO, but tentative. So I will need to consider the best mapping address for Solo5-ukvm.</li>
<li>I will move to the next step, implementation of queue-based packet handling in the guest Solo5-ukvm kernel.</li>
</ul>
<h4 id="week-24-for-takayuki-imada">Week 24 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Designed implemented memory mapping of Netmap ring buffers so that they can be easily handled by the Guest OS layer.</li>
<li>I found the current Netmap implementation does not allow us to reduce the maximum number of slots on a ring buffer in order to reduce the amount of memory size, though I was expecting it allows us to do so. The maximum number depends on a network device I use. Therefore, the prototype will consume larger memory space than expected.</li>
</ul>
<h4 id="week-25-for-takayuki-imada">Week 25 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished implementing the ring buffer manipulation functionality in the guest OS layer. I will start performance evaluation with it.</li>
<li>Tried to reduce the memory size mapped from the host OS layer. It worked fine, but requires a larger number of memory regions in Linux KVM. Memory regions are a concept of physical memory slots in KVM, so we cannot use a limited number of memory regions for a VM.</li>
</ul>
<h4 id="week-26-for-takayuki-imada">Week 26 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Finished performance evaluation with Netmap buffer manipulation in the guest OS side. I confirmed it can achieve 2.0 - 3.3x throughput under 1 sender/receiver pair on a host physical server.</li>
<li>However, its throughput under 6 sender/receiver pairs on two physical servers was similar to that with the original tap device. I found that this was mainly affected by non-Netmap processing. So I will try to identify what does affect the obtained performance.</li>
</ul>
<h4 id="week-27-for-takayuki-imada">Week 27 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Trying to identify what factor affects the performance degradation. I found that GC related statistics under the solo5 with Netmap environment under single/concurrent send-recv pair(s) has not changed.</li>
<li>Started implementing an OCaml module for rdtsc() which is used to measure the execution time of a OCaml function on Solo5/ukvm.</li>
</ul>
<h4 id="week-28-for-takayuki-imada">Week 28 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Conducted serval experiments to understand which part of the code is delayed, and found that udp.write and netif.writev functions on the sender side were delayed.</li>
<li>I will have further investigation on why this happens.</li>
</ul>
<h4 id="week-29-for-takayuki-imada">Week 29 for Takayuki Imada</h4>
<ul>
<li>Implementation (Netmap on Solo5-ukvm)</li>
<li>Found i) that the performance degradation occurs at the Ip.allocates_frame and Cstruct.concat and ii) LLC miss mainly affected it.</li>
<li>This LLC miss is highly related to repeated memory allocation for new packets to be sent. It can be reduced by using pre-allocated memory region provided by Netmap</li>
<li>But ... using the memory region does not have the backward compatibility in the IP layer, and I found it difficult to complete discussion on the compatibility and implement it by the end of my stay in Cambridge.</li>
<li>So I will not look into further performance improvement, and will move to implementation of a MQTT broker application.</li>
</ul>
<h4 id="week-30-for-takayuki-imada">Week 30 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Investigated which MQTT control packet I must implement, and found that I must 14 MQTT control packets to support the lowest QoS level.</li>
<li>Started implementing packet handlers for the 14 MQTT control packets.</li>
</ul>
<h4 id="week-31-for-takayuki-imada">Week 31 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished implementing a packets parser for 9 MQTT control packets.</li>
<li>but need to implement packet forwarding database and a handler for it. I will do that next week.</li>
</ul>
<h4 id="week-32-for-takayuki-imada">Week 32 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished writing code for the packet forwarding database.</li>
<li>I'll start functionality check for the whole application I implemented.</li>
</ul>
<h4 id="week-33-for-takayuki-imada">Week 33 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Found a bug of higher CPU utilization (~90%) in hadling a incoming packet from MQTT publishers, and fixed it.</li>
<li>Confirmed the MQTT broker can operate as expected. Good result.</li>
<li>Started investigation of what kind of performance harness for MQTT brokers I can use to check the performance of the MQTT broker I implemented</li>
<li>Decided to use Gatling + its MQTT-plugin because I can easily modify them to change a workload definition depending on a scenario. I'm now learning and checking how to use it.</li>
</ul>
<h4 id="week-34-for-takayuki-imada">Week 34 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished learning how to use Gatling + its MQTT-plugin for performance harness and confirmed they can issue a bunch of MQTT client requests as I expected (10,000 publishers and 1 subscriber).</li>
<li>Found a bug of my MQTT broker through the performance harness test. I also found out the bug is related to TCP connection close in handling MQTT disconnect requests, so I will fix it next week.</li>
</ul>
<h4 id="week-35-for-takayuki-imada">Week 35 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Have fixed a bug on TCP connection close which I found in the last week.</li>
<li>Resumed performance evaluation of my MQTT broker.</li>
</ul>
<h4 id="week-36-for-takayuki-imada">Week 36 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished performance evaluation of my MQTT broker, and found that my MQTT broker employing Netmap can handle 10,000 clients publishing 10,000 different topics with just 25% CPU utilization whereas a MQTT broker written in C (Mosquitto) indicated over 80% CPU utilization to handle the same clients.</li>
<li>Could not saturate the maximum MQTT broker performance due to the lack of resource shortage in the client side. But I found that my MQTT broker with Netmap can handle 15,000 clients with 43% CPU utilization.</li>
<li>I will write a report document to summarise my research work in OCaml Labs next week.</li>
</ul>
<h4 id="week-37-for-takayuki-imada">Week 37 for Takayuki Imada</h4>
<ul>
<li>Implementation (MQTT broker on MirageOS)</li>
<li>Finished writing a report document to summarise my research work in OCaml Labs.</li>
<li>I will do something needed to close my research at the lab such as termination of using servers.</li>
</ul>
<h3 id="author-kc-sivaramakrishnan">Author KC Sivaramakrishnan</h3>
<h4 id="week-1-for-kc-sivaramakrishnan">Week 1 for KC Sivaramakrishnan</h4>
<ul>
<li>Ezirmin
<ul>
<li>Add <code>Sync</code> module that roughly mirrors <code>Irmin.Sync</code>. Discovered that <code>push</code> is broken. This is tracked in the following issues:
<ul>
<li>https://github.com/mirage/ocaml-git/issues/139</li>
<li>https://github.com/mirage/irmin/issues/379</li>
</ul></li>
<li>Added support for history</li>
<li>Adding features to write a blog post</li>
</ul></li>
<li>Write and submit DaLi paper to <a href="https://github.com/gowthamk/snapl">SNAPL 2017</a></li>
</ul>
<h4 id="week-2-for-kc-sivaramakrishnan">Week 2 for KC Sivaramakrishnan</h4>
<ul>
<li>Investigated the issue of slow compile times on 4.04.0. Reported the bug to mantis: https://caml.inria.fr/mantis/view.php?id=7456</li>
<li>Planning for DaLi research paper. tl;dr is to add language level support for mergeable datatypes. This builds on several pieces of work that has already been done:
<ul>
<li><a href="https://github.com/kayceesrk/ezirmin">ezirmin</a></li>
<li><a href="roscidus.com/blog/blog/2015/04/28/cuekeeper-gitting-things-done-in-the-browser/">Cuekeeper</a></li>
<li><a href="https://github.com/gprano/diff-datatypes">diff-datatypes</a></li>
</ul></li>
<li>Updated CV and website.
<ul>
<li>Updated the timeline :-) http://kcsrk.info/timeline.html</li>
</ul></li>
<li>Submitted OCaml bug report for failing thread initialization: https://caml.inria.fr/mantis/view.php?id=7452.
<ul>
<li>xleroy confirmed the bug and has proposed the fix: https://github.com/ocaml/ocaml/pull/1009</li>
</ul></li>
<li>Multicore planning. Have come up with a laundry list of features.</li>
</ul>
<h4 id="week-3-for-kc-sivaramakrishnan">Week 3 for KC Sivaramakrishnan</h4>
<ul>
<li>Moving more issues to under Multicore issues. Organizing the issues under projects.</li>
<li>Chat with Daniel Hillestrom about progress on default handlers &amp; ICFP papers.</li>
<li>Chat + planning with Gowtham for DaLi paper to ICFP/OOPSLA.</li>
</ul>
<h4 id="week-4-for-kc-sivaramakrishnan">Week 4 for KC Sivaramakrishnan</h4>
<ul>
<li>Discussion with <span class="citation" data-cites="stedolan">@stedolan</span> about mergeable datatypes
<ul>
<li><em>if cons is the basis of functional data structures, what is the basis of mergeable funcational data structures?</em></li>
</ul></li>
<li>Multicore OCaml
<ul>
<li>Submitted PR for OSX compilation: https://github.com/ocamllabs/ocaml-multicore/pull/103</li>
<li>Working on fixing backtraces: https://github.com/ocamllabs/ocaml-multicore/issues/93</li>
<li>Rubber ducking for memory model discussion with <span class="citation" data-cites="stedolan">@stedolan</span>.</li>
</ul></li>
</ul>
<h4 id="week-7-for-kc-sivaramakrishnan">Week 7 for KC Sivaramakrishnan</h4>
<ul>
<li>Wrote blog post on Ezirmin: kcsrk.info/ocaml/irmin/crdt/2017/02/15/an-easy-interface-to-irmin-library/</li>
<li>Added ropes + operation transformation to Ezirmin.</li>
<li>Implemented prefetch instruction for OCaml</li>
<li>Working on the semnatics of DaLi progrmaming model</li>
</ul>
<h4 id="week-10-for-kc-sivaramakrishnan">Week 10 for KC Sivaramakrishnan</h4>
<p>I've been lazy and not writing the report every week. Here are the updates from the last 2 weeks:</p>
<ul>
<li>Submitted the following PRs to Irmin merge functions
<ul>
<li>https://github.com/mirage/irmin/pull/422</li>
<li>https://github.com/mirage/irmin/pull/420</li>
</ul></li>
<li>Released mergeable-vector library: https://github.com/kayceesrk/mergeable-vector</li>
<li>Compiled Multicore OCaml programs to wasm which runs in Firefox!
<ul>
<li>https://github.com/kayceesrk/ocamlrun-wasm/tree/multicore</li>
<li>https://pbs.twimg.com/media/C6ai77CXQAYJAhI.jpg:large</li>
</ul></li>
<li>Wrote a blog post on topkg + carcass: kcsrk.info/ocaml/opam/topkg/carcass/2017/03/05/building-and-publishing-an-OCaml-package/</li>
<li>Submitted a paper on mergeable types</li>
<li>Fixed my homepage for moving from redcarpet to kramdown.</li>
</ul>
<h4 id="week-12-for-kc-sivaramakrishnan">Week 12 for KC Sivaramakrishnan</h4>
<ul>
<li>Developed a CPS translation for L := λ calculus + effect handlers.</li>
<li>Developed a CEK machine for the L.</li>
<li>Working on a type inference for L.</li>
</ul>
<h4 id="week-15-for-kc-sivaramakrishnan">Week 15 for KC Sivaramakrishnan</h4>
<ul>
<li>Submitted a paper with Oleg Kiselyov on embedding eff programming language in OCaml to ML workshop post-proceedings. The draft of the paper is here: http://kcsrk.info/papers/caml-eff17.pdf.</li>
<li>Working on CPS translation of effect handlers with Sam Lindley, Daniel Hillestrom and Bob Atkey.</li>
<li>Working on a Dagstuhl proposal with Matija Pretnar and Tom Schrijvers.</li>
<li>Developing the multicore aarch64 backend.</li>
</ul>
<h4 id="week-17-for-kc-sivaramakrishnan">Week 17 for KC Sivaramakrishnan</h4>
<ul>
<li>Merged ARM64 backend for multicore OCaml: https://github.com/ocamllabs/ocaml-multicore/pull/120</li>
<li>Working on generating tests that would exhibit weak memory behaviours on arm64.</li>
</ul>
<h4 id="week-18-for-kc-sivaramakrishnan">Week 18 for KC Sivaramakrishnan</h4>
<ul>
<li>Submitted a paper on concurrent programming with effect handlers to TFP. Draft is <a href="kcsrk.info/papers/system_effects_may_17.pdf">here</a></li>
<li>As a part of the submission, benchmarked http/af with async and effects and compared it against a Go webserver. The results are included in the paper.</li>
<li>We discovered that effects version was leaking memory, which was down to the program leaking bigstrings due to finalizers not being implemented on Multicore. Finalizers for custom objects should be easy to fix.</li>
</ul>
<h4 id="week-19-for-kc-sivaramakrishnan">Week 19 for KC Sivaramakrishnan</h4>
<ul>
<li>Working on fixing call-frame information (CFI) in native code. This is important not only for debuggers like gdb, but also for any code that needs to unwind the stack (such as profilers). Finished PR#127 https://github.com/ocamllabs/ocaml-multicore/pull/127 which fixes the backtrace in the current branch.</li>
<li>TFP'17 submission on current system programming with effect handlers is accepted.</li>
<li>Working on extending the CFI information to support backtraces across handlers.</li>
</ul>
<h4 id="week-20-for-kc-sivaramakrishnan">Week 20 for KC Sivaramakrishnan</h4>
<ul>
<li>Lots of fixes to DWARF unwinding information: https://github.com/ocamllabs/ocaml-multicore/commit/65b329deb4296ea8fcfba788b9fcad921dbe1a9a.</li>
</ul>
<h4 id="week-21-for-kc-sivaramakrishnan">Week 21 for KC Sivaramakrishnan</h4>
<ul>
<li>Adding support for <a href="https://github.com/ocamllabs/ocaml-multicore/tree/afl">afl-fuzz for multicore</a>. The aim is to fuzz the thread schedules. Progress is slow.</li>
<li>Admin stuff: trip planning, visa applications, paper reviews.</li>
</ul>
<h4 id="week-22-for-kc-sivaramakrishnan">Week 22 for KC Sivaramakrishnan</h4>
<ul>
<li>Submitted 3 papers to ICFP workshops</li>
<li>Mergeable Types: kcsrk.info/papers/mergeable_types_draft.pdf</li>
<li>Effectively Tackling the Awkward Squad: http://kcsrk.info/papers/awkward_effects_ml17.pdf</li>
<li>A Memory Model for Multicore OCaml: http://kcsrk.info/papers/memory_model_ocaml17.pdf</li>
</ul>
<h4 id="week-23-for-kc-sivaramakrishnan">Week 23 for KC Sivaramakrishnan</h4>
<ul>
<li>Planning for migrating Lwt and Async to direct-style effect-based I/O.</li>
<li>Experimenting with reify reflect for transforming monadic IO to direct-style. Experiments are here: https://github.com/kayceesrk/reify_reflect_concurrency</li>
</ul>
<h4 id="week-27-for-kc-sivaramakrishnan">Week 27 for KC Sivaramakrishnan</h4>
<ul>
<li>Published a new blog post: kcsrk.info/multicore/gc/2017/07/06/multicore-ocaml-gc/ which was discussed on HN: https://news.ycombinator.com/item?id=14780159</li>
<li>Submitted a grant proposal with Martin Kleppman et al. on set based CRDTs. Working on a Irmin based backend for this.</li>
<li>Multicore OCaml debugging.</li>
<li>Preparing for an SRG seminar on Multicore OCaml GC.</li>
<li>Preparations for ICFP talks / workshops / events / tutorials.</li>
</ul>
<h4 id="week-30-for-kc-sivaramakrishnan">Week 30 for KC Sivaramakrishnan</h4>
<ul>
<li>working on the multicore barriers to optimise the stop-the-world phase. Aiming to stay aligned with OCaml's current barrier model to ease upstreaming.</li>
<li>submitted end-of-year report for 1851 fellowship with Alan Mycroft's approval</li>
<li>submitted paper with Oleg about features of Eff using delimcc, and KC has one with multicore</li>
<li>discussion with Daniel Hillerstrom about ICFP tutorial for algebraic effects</li>
<li>this week: working on amd64 %r14 register usage for exception handling in multicore ocaml. Hard to measure these microbenchmarks on a macro scale, so need an opam-bench-repo for realistic use.</li>
</ul>
</body>
</html>
